{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl3N5NN2-gKn"
   },
   "source": [
    "# Machine learning models to predict demographic parameters\n",
    "\n",
    "*Demographic history* of populations is the history of population development that includes such events as changes of population size, split time, migration rates and so on. Such history leaves traces in the genomes of individuals and it is possible to reconstruct this record from genetic data using different statistical and algorithmic approaches. The reconstruction of demographic history is called *demographic inference*.\n",
    "\n",
    "There are several methods for demographic inference, for example, dadi and moments to name some of them. Those tools are very popular and are based on the same statistic of the genetic data - *allele frequency spectrum*. Demographic inference for the whole genome data is a computationally complex problem. Therefore, different statistics are built from it and used for the inference. Allele frequency spectrum is one of the most popular among such statistics. It is a histogram of mutation frequencies. For two populations it is a two dimensional matrix $A$, where entry $A[i, j]$ corresponds to the number of positions where the mutation occurred in $i$ individuals of the first population and in $j$ individuals of the second population. Allele frequency spectrum of two populations is usually pictured as a heatmap.\n",
    "\n",
    "Tools for demographic inference like dadi and moments usually have two components: simulation and optimization. Simulation component provides an opportunity to simulate a statistic under the proposed demographic history and measure a value of similarity, namely likelihood, between simulation and real data. Optimization component takes a parameterized model of demographic history as input and searches for the parameters of this model that will give the best value likelihood with the data. Unfortunately, optimization implemented in dadi and moments sometimes is not efficient in practice.\n",
    "\n",
    "GADMA was presented as a new tool for efficient unsupervised demographic inference. It uses the simulation components of existing tools for demographic inference and proposes new optimization based on the genetic algorithm. It also avoids model specification by the researcher. Instead the researcher could choose the *structure* of the demographic history - number of time epochs before and between split events. For two populations it is a list of two numbers: number of epochs before the ancestral population divergence and number of epochs after it. GADMA infers all possible parameters for the given structure using a global search genetic algorithm. It avoids human bias in model construction.\n",
    "\n",
    "\n",
    "We decided to **speed up the genetic algorithm** by using prediction models from machine learning. We will do it in the most common case: demographic inference of **two populations**. The **idea** is to train some machine learning models and use them for initial estimations of demographic parameters in GADMA. We are going to train and test two models: **Random Forest regression** and **Convolutional Neural Networks**.\n",
    "\n",
    "Some details: as a data for our prediction we will use allele frequency spectrum. We will use dadi and moments. Our models will predict demographic parameters for the structure (2,1) with most diverse set of demographic parameters. It is not recommended to use GADMA with structure more than (2,1). If the actual structure in demographic inference will differ then those parameters will be transformed using GADMA algorithms to fit it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIDZADeVpIkL"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6_6VEQkGe7O",
    "outputId": "b480f4ed-315e-48f0-f18d-2535a2f148c3"
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install dadi\n",
    "!pip install gadma==2.0.0rc18\n",
    "!pip install demes\n",
    "!pip install git+https://bitbucket.org/simongravel/moments.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zfuMi-b239A"
   },
   "source": [
    "## Generate dataset\n",
    "\n",
    "This section generates datasets that will be used for training and validation.\n",
    "Totally we will generate **200,000** allele frequency spectra.\n",
    "\n",
    "We want to train our models to predict parameters for the demographic history with (2,1) structure. we will use simulated allele frequency spectra using moments. The first 100,000 parameters are generated using special distribution from GADMA that provides more close to real values, the latter 100,000 parameters are generated uniformly.\n",
    "\n",
    "![title](model_pictures/model_with_structure_2_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnRXv5XT3B-P"
   },
   "source": [
    "#### 1) Create demographic model with structure 2,1 using GADMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P2LyDfbberyy"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xf",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sts\n",
    "import pylab\n",
    "import moments\n",
    "import gadma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M58WdPE-Npxr"
   },
   "outputs": [],
   "source": [
    "# Create demographic model with structure 2,1 using gadma.\n",
    "\n",
    "model_2_1 = gadma.StructureDemographicModel(\n",
    "    initial_structure=[2,1],\n",
    "    final_structure=[2,1],\n",
    "    has_migs=True,\n",
    "    has_sels=False,\n",
    "    has_dyns=True,\n",
    "    sym_migs=False,\n",
    "    frac_split=True,\n",
    "    migs_mask=None,\n",
    "    )\n",
    "\n",
    "# We also create demographic model with structure 1,1 as we will need it.\n",
    "model_1_1 = gadma.StructureDemographicModel(\n",
    "    initial_structure=[1,1],\n",
    "    final_structure=[1,1],\n",
    "    has_migs=True,\n",
    "    has_sels=False,\n",
    "    has_dyns=True,\n",
    "    sym_migs=False,\n",
    "    frac_split=True,\n",
    "    migs_mask=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ltNOKy6-gKs"
   },
   "source": [
    "#### 2) Choose the size of allele frequency spectrum\n",
    "\n",
    "The size of spectrum should not be too large as we always can project AFS down but we cannot project it up. So we choose it equal to 5 chromosomes per population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QeGaSC4ZSBPd"
   },
   "outputs": [],
   "source": [
    "n_pop = 2\n",
    "pop_labels = [\"Pop 1\", \"Pop 2\"]\n",
    "\n",
    "ns_per_pop = 5\n",
    "ns = [ns_per_pop for _ in range(n_pop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nL_3_TIv3Aye"
   },
   "source": [
    "#### 3) Simulations and creation of file with sample data\n",
    "\n",
    "Here we generate 100,000 sets of parameters and save them in `labels.txt` file. Then for each set of parameters allele frequency spectrum is generated with moments and saved to `data.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YXdfqD1JJtCn"
   },
   "outputs": [],
   "source": [
    "n_samples = 100000\n",
    "y_file = r\"labels.txt\"\n",
    "x_file = \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkD9RmMFKku9",
    "outputId": "9a729232-da0f-468e-9174-db1efa71ad55"
   },
   "outputs": [],
   "source": [
    "# 1. Generate points using distribution from GADMA\n",
    "y_cur = [[var.resample() for var in model_2_1.variables] for _ in range(n_samples)]\n",
    "\n",
    "# 2. For better training we fix values so they match 1,1 structure for the one third\n",
    "inds = np.random.choice(range(n_samples), size=n_samples//3, replace=False)\n",
    "for ind in inds:\n",
    "    y_cur[ind][1] = 1.0  # nu11\n",
    "    #y_cur[ind][2] = \"Sud\"  # dyn11\n",
    "df = pd.DataFrame(y_cur, dtype=object)\n",
    "\n",
    "# 3. Save labels - true predictions\n",
    "np.savetxt(y_file, df.values, fmt=\"%s\")\n",
    "\n",
    "# 4. Simulate AFS for each set of parameters and save it as lines in file\n",
    "engine = gadma.get_engine(\"moments\")\n",
    "engine.model = model_2_1\n",
    "open(x_file, 'w').close()\n",
    "for i, u in tqdm.tqdm(enumerate(y_cur)):\n",
    "    popt = u.tolist()\n",
    "    data = engine.simulate(values=popt, ns=ns, sequence_length=None, population_labels=pop_labels)\n",
    "    data = data.fold()\n",
    "\n",
    "    data.to_file(f'__fs_data.txt')\n",
    "    with open('__fs_data.txt', 'r') as f:\n",
    "        for i in range(1):\n",
    "            f.readline()\n",
    "        x = f.readline()\n",
    "        with open(x_file, 'r+') as f:\n",
    "            f.seek(0, 2) \n",
    "            f.write(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZa3t9qoEOYr"
   },
   "source": [
    "## Train machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIvDs9py3ohN"
   },
   "source": [
    "### Import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hmzgrwOYSY7O"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tr\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn import metrics\n",
    "\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as ticker\n",
    "#from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from scipy.optimize import root\n",
    "from scipy.stats import randint, uniform\n",
    "from math import sqrt, exp, sin\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoFwzSao4kMN"
   },
   "source": [
    "#### Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CRjZu5F_A3KF"
   },
   "outputs": [],
   "source": [
    "def prepare_spectrum_for_input(spectrum):\n",
    "    # We remove zero element and normalize spectrum\n",
    "    spectrum /= np.sum(spectrum)\n",
    "    return spectrum\n",
    "\n",
    "def dynamics2classes(y, back=False):\n",
    "    # change strings to classes\n",
    "    _map = [(\"Sud\", '0'), (\"Lin\", '1'), (\"Exp\", '2')]\n",
    "    dyn2cls = {dyn: cls for dyn, cls in _map}\n",
    "    cls2dyn = {cls: dyn for dyn, cls in _map}\n",
    "    y_fixed = []\n",
    "    for _y in y:\n",
    "        _y = np.array(_y)\n",
    "        if not back:\n",
    "            transf_dict = dyn2cls\n",
    "        else:\n",
    "            transf_dict = cls2dyn\n",
    "        for key in transf_dict:\n",
    "            _y[_y == key] = transf_dict[key]\n",
    "        y_fixed.append(_y)\n",
    "    return y_fixed\n",
    "\n",
    "def read_labels(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        y = []\n",
    "        for line in f:\n",
    "            values = [float(val) if not isinstance(var, gadma.DynamicVariable) else val\n",
    "                  for val,var in zip(line.split(), model_2_1.variables)]\n",
    "            y.append(values)\n",
    "    y = dynamics2classes(y)\n",
    "    y = np.array(y, dtype=object)\n",
    "    return y\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        X = []\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            assert len(line.split()) == (ns_per_pop+1)**2, f\"{i} {line} {len(line.split())}\"\n",
    "            spectrum = np.array(line.split(), dtype=float)\n",
    "            spectrum = prepare_spectrum_for_input(spectrum=spectrum)\n",
    "            X.append(spectrum)\n",
    "            i += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3gK6a_gqVwm",
    "outputId": "0919d465-e2be-4128-bb95-75b5a5d6fd53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of read samples: 100000\n"
     ]
    }
   ],
   "source": [
    "X_total = read_data(x_file)\n",
    "y_total = read_labels(y_file)\n",
    "n_sample = min(len(X_total), len(y_total))\n",
    "print(f\"Number of read samples: {n_sample}\")\n",
    "X_total = X_total[:n_sample]\n",
    "y_total = y_total[:n_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwylZfbi4cxS"
   },
   "source": [
    "### Create train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "miDPtigBBNJ2"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tr(X_total, y_total, train_size = 0.8, random_state=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kocQzqvXceP"
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "#### Project down train dataset\n",
    "\n",
    "As it turned out from our experiments Random Forest performs better with small dataset. It also important that they are from the first half that was generated with special distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MP6yYH2I-gKv"
   },
   "outputs": [],
   "source": [
    "RF_n_sample = 2000\n",
    "\n",
    "X_train_RF = X_train[:RF_n_sample]\n",
    "y_train_RF = y_train[:RF_n_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNjgzDGT-gKv"
   },
   "source": [
    "#### Prepare function to print measure of fitness and load one test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_paN8MFf-gKv"
   },
   "outputs": [],
   "source": [
    "def print_measures(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Returns MSE for all continous parameters and accuracy for all discrete.\n",
    "    \"\"\"\n",
    "    is_cont = np.array([not isinstance(var, gadma.DynamicVariable) for var in model_2_1.variables])\n",
    "    is_disc = np.array([not cont for cont in is_cont])\n",
    "        \n",
    "    cont_y_pred = np.array([np.array(_y)[is_cont] for _y in y_pred], dtype=float)\n",
    "    disc_y_pred = np.array([np.array(_y)[is_disc] for _y in y_pred])\n",
    "        \n",
    "    cont_y_true = np.array([np.array(_y)[is_cont] for _y in y_true], dtype=float)\n",
    "    disc_y_true = np.array([np.array(_y)[is_disc] for _y in y_true])\n",
    "        \n",
    "    mse = metrics.mean_squared_error(y_true=cont_y_true, y_pred=cont_y_pred)\n",
    "        \n",
    "    acc = []\n",
    "    for i in range(disc_y_true.shape[1]):\n",
    "        acc.append(metrics.accuracy_score(y_true=disc_y_true[:, i], y_pred=disc_y_pred[:, i]))\n",
    "        \n",
    "    print(\"Mean squared error:\", mse)\n",
    "    print(\"Mean accuracy score:\", np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S_fbBVpl-gKv"
   },
   "outputs": [],
   "source": [
    "# We have AFS for a special case. We know the best value of likelihood and best parameters.\n",
    "data = moments.Spectrum.from_file(\"fs_data.fs\")\n",
    "best_ll = -1310.931\n",
    "best_params = {\n",
    "    't1': 1.0,\n",
    "    'nu11': 1.0,\n",
    "    'dyn11': 'Sud',\n",
    "    's1': 0.5,\n",
    "    't2': 0.05,\n",
    "    'nu21': 1.0,\n",
    "    'nu22': 0.1,\n",
    "    'dyn21': 'Sud',\n",
    "    'dyn22': 'Sud',\n",
    "    'm2_12': 5.0,\n",
    "    'm2_21': 2.5,\n",
    "}\n",
    "engine = gadma.get_engine(\"moments\")\n",
    "engine.model = model_2_1\n",
    "engine.data = data\n",
    "best_ll = engine.evaluate(best_params)\n",
    "\n",
    "# we need to prepare data as input to ML model\n",
    "test_x = data.project(ns).fold()\n",
    "test_x = np.array(test_x).flatten()\n",
    "test_x /= np.sum(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnK7IhXu-gKv"
   },
   "source": [
    "### Model 1. Independent parameter prediction\n",
    "\n",
    "We will start with simple Random forest with independent predictions for each demographic parameter.\n",
    "\n",
    "![title](model_pictures/model_1_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JYJxDTsAW6Kb"
   },
   "outputs": [],
   "source": [
    "class MyRFFor21ModelIndependent(object):\n",
    "    def __init__(self):\n",
    "        # We create our models\n",
    "        # We have RF regressors for continous variables and Classifiers for dynamics\n",
    "        self.models = {}\n",
    "        for var in model_2_1.variables:\n",
    "            if not isinstance(var, gadma.DynamicVariable):\n",
    "                self.models[var.name] = RandomForestRegressor()\n",
    "            else:\n",
    "                self.models[var.name] = RandomForestClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        name2ind = {var.name: i\n",
    "                    for i, var in enumerate(model_2_1.variables)}\n",
    "        for var in model_2_1.variables:\n",
    "            if not isinstance(var, gadma.DynamicVariable):\n",
    "                self.models[var.name].fit(X, y[:, name2ind[var.name]])\n",
    "            else:\n",
    "                self.models[var.name].fit(X, np.array(y[:, name2ind[var.name]], dtype=str))\n",
    "            \n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = {}\n",
    "        for var in model_2_1.variables:\n",
    "            y_pred[var.name] = self.models[var.name].predict(X)\n",
    "\n",
    "        final_y_pred = []\n",
    "        for _i in range(len(y_pred[\"nu11\"])):\n",
    "            _y = []\n",
    "            for var in model_2_1.variables:\n",
    "                _y.append(y_pred[var.name][_i])\n",
    "            final_y_pred.append(_y)\n",
    "        return final_y_pred\n",
    "\n",
    "    def predict_for_1_1_structure(self, X):\n",
    "        # 1) predict nu11, t1, d11\n",
    "        y_pred = np.array(self.predict(X))\n",
    "        return y_pred[:, 3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jNo5CBP-gKv"
   },
   "source": [
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d297OqsJZHhi"
   },
   "outputs": [],
   "source": [
    "model1 = MyRFFor21ModelIndependent()\n",
    "model1.fit(X_train_RF, y_train_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt7smaol-gKw"
   },
   "source": [
    "- OR load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCvbf1BF-gKw"
   },
   "outputs": [],
   "source": [
    "filename = 'RandomForestIndependent.joblib'\n",
    "model1 = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOpuV8Ye-gKw"
   },
   "source": [
    "- Get measures on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NE4gEoLI-gKw",
    "outputId": "8fc4d673-e183-4300-93f0-72b35993e8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model 1 with independent estimators for each demographic parameter.\n",
      "Mean squared error: 11.76497710965169\n",
      "Mean accuracy score: 0.47080000000000005\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "print(\"Random Forest model 1 with independent estimators for each demographic parameter.\")\n",
    "print_measures(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALTN2dFU-gKw"
   },
   "source": [
    "- Test prediction for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d2f1MazZL0A",
    "outputId": "9e542968-691e-4507-9f70-69b7330eb25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best known parameters:\n",
      "{'t1': 1.0, 'nu11': 1.0, 'dyn11': 'Sud', 's1': 0.5, 't2': 0.05, 'nu21': 1.0, 'nu22': 0.1, 'dyn21': 'Sud', 'dyn22': 'Sud', 'm2_12': 5.0, 'm2_21': 2.5}\n",
      "Best known log-likelihood:\n",
      "-1310.9310340005\n",
      "\n",
      "Predicted parameters:\n",
      "{'t1': 0.36776761929062224, 'nu11': 1.4615867184694744, 'dyn11': 'Sud', 's1': 0.6079165202857019, 't2': 0.272524283820689, 'nu21': 1.747355004224297, 'nu22': 0.30145522192942553, 'dyn21': 'Exp', 'dyn22': 'Exp', 'm2_12': 4.017957245373616, 'm2_21': 1.21407200575233}\n",
      "Log-likelihood:\n",
      "-3688.6917267297677\n"
     ]
    }
   ],
   "source": [
    "y = np.array(model1.predict([test_x]), dtype=object)\n",
    "y = dynamics2classes(y, back=True)[0]\n",
    "\n",
    "print(\"Best known parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best known log-likelihood:\")\n",
    "print(best_ll)\n",
    "\n",
    "print(\"\\nPredicted parameters:\")\n",
    "y_pred = {var.name: value for var, value in zip(model_2_1.variables, y)}\n",
    "print(y_pred)\n",
    "print(\"Log-likelihood:\")\n",
    "print(engine.evaluate(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbLBz9oBCKTk"
   },
   "source": [
    "### Model 2. Dependent parameter prediction\n",
    "\n",
    "Now we add some additional dependency as parameters have them.\n",
    "\n",
    "![title](model_pictures/model_2_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5ikqP3ep7kCB"
   },
   "outputs": [],
   "source": [
    "class MyRFFor21ModelDependent(object):\n",
    "    def __init__(self):\n",
    "        # We create our models\n",
    "        # We have RF regressors for continous variables and Classifiers for dynamics\n",
    "        self.models = {}\n",
    "        for var in model_2_1.variables:\n",
    "            if not isinstance(var, gadma.DynamicVariable):\n",
    "                self.models[var.name] = RandomForestRegressor()\n",
    "            else:\n",
    "                self.models[var.name] = RandomForestClassifier()\n",
    "\n",
    "    def _add_values(self, X, y, var_names):\n",
    "        name2ind = {var.name: i\n",
    "                    for i, var in enumerate(model_2_1.variables)}\n",
    "        new_X = []\n",
    "        for _x, _y in zip(X, y):\n",
    "            new_X.append(_x.tolist())\n",
    "            for name in var_names:\n",
    "                new_X[-1].append(_y[name2ind[name]])\n",
    "        return np.array(new_X, dtype=object)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 0) get indices for var names\n",
    "        name2ind = {var.name: i\n",
    "                    for i, var in enumerate(model_2_1.variables)}\n",
    "        # 1) RF for nu11, t1 and dyn11 are independent\n",
    "        self.models[\"nu11\"].fit(X, y[:, name2ind[\"nu11\"]])\n",
    "        self.models[\"t1\"].fit(X, y[:, name2ind[\"t1\"]])\n",
    "        self.models[\"dyn11\"].fit(X, np.array(y[:, name2ind[\"dyn11\"]], dtype=str))\n",
    "\n",
    "        # 2) Split fraction, times, sizes and dynamics after split depend\n",
    "        # on those before split\n",
    "        X_with_prev_values_1 = self._add_values(\n",
    "            X=X, y=y, var_names=[\"nu11\", \"t1\", \"dyn11\"])\n",
    "        self.models[\"s1\"].fit(X_with_prev_values_1, y[:, name2ind[\"s1\"]])\n",
    "        self.models[\"nu21\"].fit(X_with_prev_values_1, y[:, name2ind[\"nu21\"]])\n",
    "        self.models[\"nu22\"].fit(X_with_prev_values_1, y[:, name2ind[\"nu22\"]])\n",
    "        self.models[\"t2\"].fit(X_with_prev_values_1, y[:, name2ind[\"t2\"]])\n",
    "        self.models[\"dyn21\"].fit(X_with_prev_values_1, np.array(y[:, name2ind[\"dyn21\"]], dtype=str))\n",
    "        self.models[\"dyn22\"].fit(X_with_prev_values_1, np.array(y[:, name2ind[\"dyn22\"]], dtype=str))\n",
    "\n",
    "        # 3) The migrations depends on time, sizes and dynamics\n",
    "        X_with_prev_values_2 = self._add_values(\n",
    "            X=X_with_prev_values_1,\n",
    "            y=y,\n",
    "            var_names=[\"s1\", \"nu21\", \"nu22\", \"t2\", \"dyn21\", \"dyn22\"],\n",
    "        )\n",
    "        self.models[\"m2_21\"].fit(X_with_prev_values_2, y[:, name2ind[\"m2_21\"]])\n",
    "        self.models[\"m2_12\"].fit(X_with_prev_values_2, y[:, name2ind[\"m2_12\"]])\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 1) predict nu11, t1, d11\n",
    "        y_pred = {}\n",
    "        y_pred[\"nu11\"] = self.models[\"nu11\"].predict(X)\n",
    "        y_pred[\"t1\"] = self.models[\"t1\"].predict(X)\n",
    "        y_pred[\"dyn11\"] = self.models[\"dyn11\"].predict(X)\n",
    "        \n",
    "        # 2)\n",
    "        new_X = []\n",
    "        for i, x in enumerate(X):\n",
    "            new_X.append(x.tolist())\n",
    "            new_X[-1].extend([y_pred[\"nu11\"][i], y_pred[\"t1\"][i], y_pred[\"dyn11\"][i]])\n",
    "        new_X = np.array(new_X)\n",
    "        y_pred[\"s1\"] = self.models[\"s1\"].predict(new_X)\n",
    "        y_pred[\"nu21\"] = self.models[\"nu21\"].predict(new_X)\n",
    "        y_pred[\"nu22\"] = self.models[\"nu22\"].predict(new_X)\n",
    "        y_pred[\"t2\"] = self.models[\"t2\"].predict(new_X)\n",
    "        y_pred[\"dyn21\"] = self.models[\"dyn21\"].predict(new_X)\n",
    "        y_pred[\"dyn22\"] = self.models[\"dyn22\"].predict(new_X)\n",
    "\n",
    "        # 3)\n",
    "        new_new_X = []\n",
    "        for i, x in enumerate(new_X):\n",
    "            new_new_X.append(x.tolist())\n",
    "            new_new_X[-1].extend([\n",
    "                y_pred[\"s1\"][i], y_pred[\"nu21\"][i], y_pred[\"nu22\"][i],\n",
    "                y_pred[\"t2\"][i], y_pred[\"dyn21\"][i], y_pred[\"dyn22\"][i]]\n",
    "            )\n",
    "\n",
    "        y_pred[\"m2_21\"] = self.models[\"m2_21\"].predict(new_new_X)\n",
    "        y_pred[\"m2_12\"] = self.models[\"m2_12\"].predict(new_new_X)\n",
    "\n",
    "        final_y_pred = []\n",
    "        for _i in range(len(y_pred[\"nu11\"])):\n",
    "            _y = []\n",
    "            for var in model_2_1.variables:\n",
    "                _y.append(y_pred[var.name][_i])\n",
    "            final_y_pred.append(_y)\n",
    "        return final_y_pred\n",
    "\n",
    "    def predict_for_1_1_structure(self, X):\n",
    "        # 1) predict nu11, t1, d11\n",
    "        y_pred = {}\n",
    "        y_pred[\"nu11\"] = [1.0 for _ in X]\n",
    "        y_pred[\"t1\"] = [model_2_1.variables[0].resample() for _ in X]\n",
    "        y_pred[\"dyn11\"] = [\"0\" for _ in X]\n",
    "        \n",
    "        # 2)\n",
    "        new_X = []\n",
    "        for i, x in enumerate(X):\n",
    "            new_X.append(x.tolist())\n",
    "            new_X[-1].extend([y_pred[\"nu11\"][i], y_pred[\"t1\"][i], y_pred[\"dyn11\"][i]])\n",
    "        new_X = np.array(new_X, dtype=object)\n",
    "        y_pred[\"s1\"] = self.models[\"s1\"].predict(new_X)\n",
    "        y_pred[\"nu21\"] = self.models[\"nu21\"].predict(new_X)\n",
    "        y_pred[\"nu22\"] = self.models[\"nu22\"].predict(new_X)\n",
    "        y_pred[\"t2\"] = self.models[\"t2\"].predict(new_X)\n",
    "        y_pred[\"dyn21\"] = self.models[\"dyn21\"].predict(new_X)\n",
    "        y_pred[\"dyn22\"] = self.models[\"dyn22\"].predict(new_X)\n",
    "\n",
    "        # 3)\n",
    "        new_new_X = []\n",
    "        for i, x in enumerate(new_X):\n",
    "            new_new_X.append(x.tolist())\n",
    "            new_new_X[-1].extend([\n",
    "                y_pred[\"s1\"][i], y_pred[\"nu21\"][i], y_pred[\"nu22\"][i],\n",
    "                y_pred[\"t2\"][i], y_pred[\"dyn21\"][i], y_pred[\"dyn22\"][i]]\n",
    "            )\n",
    "\n",
    "        y_pred[\"m2_21\"] = self.models[\"m2_21\"].predict(new_new_X)\n",
    "        y_pred[\"m2_12\"] = self.models[\"m2_12\"].predict(new_new_X)\n",
    "\n",
    "        final_y_pred = []\n",
    "        for _i in range(len(y_pred[\"nu11\"])):\n",
    "            _y = []\n",
    "            for var in model_2_1.variables[3:]:\n",
    "                _y.append(y_pred[var.name][_i])\n",
    "            final_y_pred.append(_y)\n",
    "        return final_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52xvH6oK-gKx"
   },
   "source": [
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZSZKGSMC--Xz"
   },
   "outputs": [],
   "source": [
    "model2 = MyRFFor21ModelDependent()\n",
    "model2.fit(X_train_RF, y_train_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR87ziuW-gKx"
   },
   "source": [
    "- OR load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgETschp-gKx"
   },
   "outputs": [],
   "source": [
    "filename = 'RandomForestDependent.joblib'\n",
    "model2 = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfcJqSup-gKx"
   },
   "source": [
    "- Get measures on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7a930jG-gKx",
    "outputId": "378c1541-0231-4778-9432-1e41d5ee9bc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model 2 with dependent estimators for demographic parameters.\n",
      "Mean squared error: 11.773198395358822\n",
      "Mean accuracy score: 0.4727333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "print(\"Random Forest model 2 with dependent estimators for demographic parameters.\")\n",
    "print_measures(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YwFkA6U-gKx"
   },
   "source": [
    "- Test prediction for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATlg7YD6-gKx",
    "outputId": "822cea01-f05e-43de-c2ea-7940eef83fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best known parameters:\n",
      "{'t1': 1.0, 'nu11': 1.0, 'dyn11': 'Sud', 's1': 0.5, 't2': 0.05, 'nu21': 1.0, 'nu22': 0.1, 'dyn21': 'Sud', 'dyn22': 'Sud', 'm2_12': 5.0, 'm2_21': 2.5}\n",
      "Best known log-likelihood:\n",
      "-1310.9310340005\n",
      "\n",
      "Predicted parameters:\n",
      "{'t1': 0.3850696776653348, 'nu11': 1.0786090861269844, 'dyn11': 'Sud', 's1': 0.5213370393537992, 't2': 0.18435417793988038, 'nu21': 2.297015285593226, 'nu22': 0.32315403761031564, 'dyn21': 'Exp', 'dyn22': 'Sud', 'm2_12': 2.9904144466727143, 'm2_21': 2.0296450724393207}\n",
      "Log-likelihood:\n",
      "-4310.380208183418\n"
     ]
    }
   ],
   "source": [
    "y = np.array(model2.predict([test_x]), dtype=object)\n",
    "y = dynamics2classes(y, back=True)[0]\n",
    "\n",
    "print(\"Best known parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best known log-likelihood:\")\n",
    "print(best_ll)\n",
    "\n",
    "print(\"\\nPredicted parameters:\")\n",
    "y_pred = {var.name: value for var, value in zip(model_2_1.variables, y)}\n",
    "print(y_pred)\n",
    "print(\"Log-likelihood:\")\n",
    "print(engine.evaluate(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4G781R8-gKx"
   },
   "source": [
    "### Model 3. Random forest with multi-output predictions\n",
    "\n",
    "Random forest itself could predict vectors. So we will separate regression and classification and just ask them to predict several values instead one.\n",
    "\n",
    "![title](model_pictures/model_3_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hvcNK43i-gKx"
   },
   "outputs": [],
   "source": [
    "class MyRFFor21ModelMultiOutput(object):\n",
    "    def __init__(self):\n",
    "        # We create our models\n",
    "        # We have RF regressor for continous variables and Classifier for dynamics\n",
    "        self.models = [\n",
    "            RandomForestRegressor(),\n",
    "            RandomForestClassifier(),\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        is_cont = np.array([not isinstance(var, gadma.DynamicVariable) for var in model_2_1.variables])\n",
    "        is_disc = np.array([not cont for cont in is_cont])\n",
    "        \n",
    "        y_cont = [np.array(_y)[is_cont] for _y in y]\n",
    "        y_disc = [np.array(_y)[is_disc] for _y in y]\n",
    "        \n",
    "        self.models[0].fit(X, y_cont)\n",
    "        self.models[1].fit(X, y_disc)\n",
    "\n",
    "    def predict(self, X):\n",
    "        is_cont = np.array([not isinstance(var, gadma.DynamicVariable) for var in model_2_1.variables])\n",
    "        is_disc = np.array([not cont for cont in is_cont])\n",
    "        \n",
    "        y_pred = np.zeros(shape=(len(X), len(model_2_1.variables)), dtype=object)\n",
    "        \n",
    "        y_pred[:, is_cont] = self.models[0].predict(X)\n",
    "        y_pred[:, is_disc] = self.models[1].predict(X)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_for_1_1_structure(self, X):\n",
    "        # 1) predict nu11, t1, d11\n",
    "        y_pred = np.array(self.predict(X))\n",
    "        return y_pred[:, 3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CCu5MQw-gKx"
   },
   "source": [
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GwoJUDng-gKy"
   },
   "outputs": [],
   "source": [
    "model3 = MyRFFor21ModelMultiOutput()\n",
    "model3.fit(X_train_RF, y_train_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwJnXls_-gKy"
   },
   "source": [
    "- OR load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "879ohcz1-gKy"
   },
   "outputs": [],
   "source": [
    "filename = 'RandomForestMultiOutput.joblib'\n",
    "model3 = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjRQht9L-gKy"
   },
   "source": [
    "- Get measures on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFHcWsm9-gKy",
    "outputId": "c3fe2a1d-34e1-47de-8b9a-8801e7387a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model 3 with multi-output estimators.\n",
      "Mean squared error: 11.898778394692737\n",
      "Mean accuracy score: 0.4753166666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "print(\"Random Forest model 3 with multi-output estimators.\")\n",
    "print_measures(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SI432ZQM-gKy"
   },
   "source": [
    "- Test prediction for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTN9arVS-gKy",
    "outputId": "7066bb2d-dd70-4645-8578-54fdb13b2571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best known parameters:\n",
      "{'t1': 1.0, 'nu11': 1.0, 'dyn11': 'Sud', 's1': 0.5, 't2': 0.05, 'nu21': 1.0, 'nu22': 0.1, 'dyn21': 'Sud', 'dyn22': 'Sud', 'm2_12': 5.0, 'm2_21': 2.5}\n",
      "Best known log-likelihood:\n",
      "-1310.9310340005\n",
      "\n",
      "Predicted parameters:\n",
      "{'t1': 0.26863903612766166, 'nu11': 1.678640535125808, 'dyn11': 'Sud', 's1': 0.6216949404299615, 't2': 0.27383689275649287, 'nu21': 1.7011780079568388, 'nu22': 0.5246284441325718, 'dyn21': 'Exp', 'dyn22': 'Exp', 'm2_12': 3.421735042716503, 'm2_21': 1.1691820428019235}\n",
      "Log-likelihood:\n",
      "-8114.9975080088625\n"
     ]
    }
   ],
   "source": [
    "y = np.array(model3.predict([test_x]), dtype=object)\n",
    "y = dynamics2classes(y, back=True)[0]\n",
    "\n",
    "print(\"Best known parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best known log-likelihood:\")\n",
    "print(best_ll)\n",
    "\n",
    "print(\"\\nPredicted parameters:\")\n",
    "y_pred = {var.name: value for var, value in zip(model_2_1.variables, y)}\n",
    "print(y_pred)\n",
    "print(\"Log-likelihood:\")\n",
    "print(engine.evaluate(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjDj0AEhbRbL"
   },
   "source": [
    "### Save trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VY3k1dB2Zr2k",
    "outputId": "e1500dac-c1e1-4a6d-ea61-ea15db89c8e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestIndependent.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'RandomForestIndependent.joblib'\n",
    "joblib.dump(model1, filename, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YNkWLErbOJy",
    "outputId": "0b3c7ec3-99eb-435d-9dff-e6be7b463117"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestDependent.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'RandomForestDependent.joblib'\n",
    "joblib.dump(model2, filename, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZt3ebHD-gKy",
    "outputId": "f61cb27c-29f0-4a55-ad2e-83603cd0f096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestMultiOutput.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'RandomForestMultiOutput.joblib'\n",
    "joblib.dump(model3, filename, compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pSb-brheqrO"
   },
   "source": [
    "## Convolution Neural Network (CNN)\n",
    "\n",
    "Finally we want to use CNN to predict the same demographic parameters from allele frequency spectrum.\n",
    "\n",
    "CNN require much more examples to train so we will give it all 200,000 samples we have. Usually pictures are much bigger, we have only 6x6 pixels. As we have small picture then we have very simple network. \n",
    "\n",
    "#### Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEzt1rKI-gKz",
    "outputId": "cc1c9527-e98d-4201-d3aa-2e8d0a732380"
   },
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PFGQyEW1cHU3"
   },
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=\"\"\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from gadma.utils.variables import DynamicVariable\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNWoSNMq-gKz"
   },
   "source": [
    "### Model. Independent predictions\n",
    "\n",
    "The CNN model is simple. Each parameter is predicted with its own CNN. The convolutions are small: 2x2 size. Number of filters increases: 16, 32 and 64.The final full-connected layer has 8 neurons. The final layer depends on type pf parameter. If it is continous then there is last fully connected (FC) layer that returns 1 output for sigmoid activation. If it is discrete then the last layer is also fully connected but returns 3 outputs (3 classes) for softmax activation.\n",
    "\n",
    "The common part of CNN for parameters looks like:\n",
    "\n",
    "![title](model_pictures/cnn_common_scheme.png)\n",
    "\n",
    "We set the size of input image and create special custom activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lJHJzF7m-gKz"
   },
   "outputs": [],
   "source": [
    "IM_WIDTH = IM_HEIGHT = ns_per_pop + 1\n",
    "\n",
    "\n",
    "def get_custom_activation(bounds):\n",
    "    def custom_activation(x):\n",
    "        return (K.sigmoid(x) * (bounds[1] - bounds[0])) + bounds[0]\n",
    "    return custom_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUYt-rIg-gKz"
   },
   "source": [
    "Create data generator for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WPJY-an0mKZn"
   },
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \"\"\"\n",
    "    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\n",
    "    \"\"\" \n",
    "    def generate_images(self, X, y, is_training, batch_size=16):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        X_resized = np.array(X)\n",
    "        X_resized = np.array([np.reshape(np.array(x), (-1, 6, 1)) for x in X_resized])\n",
    "\n",
    "        # arrays to store our batched data\n",
    "        images = []\n",
    "        answers = [[] for _ in model_2_1.variables]\n",
    "        while True:\n",
    "            for idx in range(len(X)):\n",
    "                im = X_resized[idx]\n",
    "                for i in range(len(model_2_1.variables)):\n",
    "                    var = model_2_1.variables[i]\n",
    "                    if isinstance(var, gadma.DynamicVariable):\n",
    "                        answers[i].append(to_categorical(int(y[idx][i]), 3))\n",
    "                    else:\n",
    "                        answers[i].append(float(y[idx][i]))\n",
    "                images.append(im)\n",
    "                \n",
    "                # yielding condition\n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images), [np.array(answ) for answ in answers]\n",
    "                    images = []\n",
    "                    answers = [[] for _ in model_2_1.variables]\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "                \n",
    "data_generator = DataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_QD5Blv-gKz"
   },
   "source": [
    "And function to convert CNN output to output of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BpPZoXmd-gKz"
   },
   "outputs": [],
   "source": [
    "def convert_cnn_output_to_rf_output(cnn_output):\n",
    "    rf_output = []\n",
    "    for i in range(len(cnn_output[0])):\n",
    "        out = []\n",
    "        for j, var in enumerate(model_2_1.variables):\n",
    "            if isinstance(var, gadma.DynamicVariable):\n",
    "                argmax = max(list(range(3)), key=lambda t: cnn_output[j][i][t])\n",
    "                out.append(str(argmax))\n",
    "            else:\n",
    "                out.append(cnn_output[j][i][0])\n",
    "        rf_output.append(np.array(out, dtype=object))\n",
    "    return rf_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CHt5EqR-gKz"
   },
   "source": [
    "- Create model with `Keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2D_xzHmN-gKz"
   },
   "outputs": [],
   "source": [
    "class KerasModelIndependent():\n",
    "    def make_default_hidden_layers(self, inputs):\n",
    "        filters = (16, 32, 64)\n",
    "        for (i, f) in enumerate(filters):\n",
    "            if i == 0: x = inputs\n",
    "            x = Conv2D(f, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            if i == (len(filters) - 1):\n",
    "                x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "            x = Dropout(0.25)(x)\n",
    "        return x\n",
    "\n",
    "    def build_float_branch(self, inputs, name, bounds):\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "        # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        # we have regression\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(get_custom_activation(bounds), name=name)(x)\n",
    "        return x\n",
    "\n",
    "    def build_discrete_branch(self, inputs, name):\n",
    "        x = self.make_default_hidden_layers(inputs)\n",
    "        # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        x = Dense(3)(x)\n",
    "        x = Activation(\"softmax\", name=name)(x)\n",
    "        return x\n",
    "\n",
    "    def assemble_full_model(self, width, height):\n",
    "        \"\"\"\n",
    "        Used to assemble our multi-output model CNN.\n",
    "        \"\"\"\n",
    "        input_shape = (height, width, 1)\n",
    "        inputs = Input(shape=input_shape)\n",
    "        branches = []\n",
    "        for var in model_2_1.variables:\n",
    "            if isinstance(var, gadma.DynamicVariable):\n",
    "                branches.append(self.build_discrete_branch(inputs, name=f\"{var.name}_output\"))\n",
    "            else:\n",
    "                branches.append(self.build_float_branch(inputs, name=f\"{var.name}_output\", bounds=var.domain))\n",
    "        model = Model(inputs=inputs,\n",
    "                     outputs = branches,\n",
    "                     name=\"keras_net\")\n",
    "        return model\n",
    "    \n",
    "model = KerasModelIndependent().assemble_full_model(IM_WIDTH, IM_HEIGHT)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzRi0zl7-gKz"
   },
   "source": [
    "#### Create validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "RT52h8ME-gK0"
   },
   "outputs": [],
   "source": [
    "X_train_CNN, X_val_CNN, y_train_CNN, y_val_CNN = tr(\n",
    "    X_train, y_train, train_size = 0.8, random_state=500, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC8eB2IL-gK0"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm-sWryE-gK0"
   },
   "source": [
    "- Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "gIETBEwEk14q",
    "outputId": "056af6db-0be1-4c24-bdc0-33b3df9438b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f472094c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f472094c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 162.4623 - t1_output_loss: 1.1289 - nu11_output_loss: 44.0866 - dyn11_output_loss: 0.9834 - s1_output_loss: 0.0857 - t2_output_loss: 1.2808 - nu21_output_loss: 52.0145 - nu22_output_loss: 52.6293 - dyn21_output_loss: 1.1006 - dyn22_output_loss: 1.1097 - m2_12_output_loss: 4.3464 - m2_21_output_loss: 3.6963 - t1_output_mae: 0.7348 - nu11_output_mae: 2.4305 - dyn11_output_categorical_accuracy: 0.6194 - s1_output_mae: 0.2522 - t2_output_mae: 0.8007 - nu21_output_mae: 2.9695 - nu22_output_mae: 3.0115 - dyn21_output_categorical_accuracy: 0.4354 - dyn22_output_categorical_accuracy: 0.4349 - m2_12_output_mae: 1.4697 - m2_21_output_mae: 1.4002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f4700b2f280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f4700b2f280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f47001f38b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f47001f38b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f47001f39d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f47001f39d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 57s 21ms/step - loss: 162.3972 - t1_output_loss: 1.1292 - nu11_output_loss: 44.0730 - dyn11_output_loss: 0.9834 - s1_output_loss: 0.0857 - t2_output_loss: 1.2811 - nu21_output_loss: 51.9927 - nu22_output_loss: 52.5984 - dyn21_output_loss: 1.1005 - dyn22_output_loss: 1.1097 - m2_12_output_loss: 4.3467 - m2_21_output_loss: 3.6967 - t1_output_mae: 0.7349 - nu11_output_mae: 2.4303 - dyn11_output_categorical_accuracy: 0.6193 - s1_output_mae: 0.2522 - t2_output_mae: 0.8008 - nu21_output_mae: 2.9690 - nu22_output_mae: 3.0106 - dyn21_output_categorical_accuracy: 0.4354 - dyn22_output_categorical_accuracy: 0.4350 - m2_12_output_mae: 1.4697 - m2_21_output_mae: 1.4002 - val_loss: 180.7843 - val_t1_output_loss: 1.0187 - val_nu11_output_loss: 54.9320 - val_dyn11_output_loss: 0.9271 - val_s1_output_loss: 0.0841 - val_t2_output_loss: 1.2112 - val_nu21_output_loss: 58.3945 - val_nu22_output_loss: 49.2908 - val_dyn21_output_loss: 1.0720 - val_dyn22_output_loss: 1.0729 - val_m2_12_output_loss: 7.2234 - val_m2_21_output_loss: 5.5575 - val_t1_output_mae: 0.7563 - val_nu11_output_mae: 5.8911 - val_dyn11_output_categorical_accuracy: 0.6356 - val_s1_output_mae: 0.2513 - val_t2_output_mae: 0.8571 - val_nu21_output_mae: 5.5237 - val_nu22_output_mae: 2.6164 - val_dyn21_output_categorical_accuracy: 0.4410 - val_dyn22_output_categorical_accuracy: 0.4431 - val_m2_12_output_mae: 2.2576 - val_m2_21_output_mae: 1.8481\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 135.9836 - t1_output_loss: 0.9799 - nu11_output_loss: 32.6097 - dyn11_output_loss: 0.9263 - s1_output_loss: 0.0829 - t2_output_loss: 1.0936 - nu21_output_loss: 42.7134 - nu22_output_loss: 48.9365 - dyn21_output_loss: 1.0656 - dyn22_output_loss: 1.0682 - m2_12_output_loss: 3.4273 - m2_21_output_loss: 3.0802 - t1_output_mae: 0.6815 - nu11_output_mae: 2.1547 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2493 - t2_output_mae: 0.7415 - nu21_output_mae: 2.7515 - nu22_output_mae: 2.8788 - dyn21_output_categorical_accuracy: 0.4480 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 1.3533 - m2_21_output_mae: 1.2600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f4700b2fdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f4700b2fdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4700b2f5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4700b2f5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 57s 23ms/step - loss: 135.9836 - t1_output_loss: 0.9799 - nu11_output_loss: 32.6097 - dyn11_output_loss: 0.9263 - s1_output_loss: 0.0829 - t2_output_loss: 1.0936 - nu21_output_loss: 42.7134 - nu22_output_loss: 48.9365 - dyn21_output_loss: 1.0656 - dyn22_output_loss: 1.0682 - m2_12_output_loss: 3.4273 - m2_21_output_loss: 3.0802 - t1_output_mae: 0.6815 - nu11_output_mae: 2.1547 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2493 - t2_output_mae: 0.7415 - nu21_output_mae: 2.7515 - nu22_output_mae: 2.8788 - dyn21_output_categorical_accuracy: 0.4480 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 1.3533 - m2_21_output_mae: 1.2600 - val_loss: 272.6766 - val_t1_output_loss: 0.9593 - val_nu11_output_loss: 157.9620 - val_dyn11_output_loss: 0.9298 - val_s1_output_loss: 0.0832 - val_t2_output_loss: 1.1188 - val_nu21_output_loss: 58.2370 - val_nu22_output_loss: 42.4257 - val_dyn21_output_loss: 1.0649 - val_dyn22_output_loss: 1.0629 - val_m2_12_output_loss: 4.5147 - val_m2_21_output_loss: 4.3183 - val_t1_output_mae: 0.7082 - val_nu11_output_mae: 11.6518 - val_dyn11_output_categorical_accuracy: 0.6303 - val_s1_output_mae: 0.2500 - val_t2_output_mae: 0.7847 - val_nu21_output_mae: 5.7504 - val_nu22_output_mae: 3.8054 - val_dyn21_output_categorical_accuracy: 0.4405 - val_dyn22_output_categorical_accuracy: 0.4449 - val_m2_12_output_mae: 1.6820 - val_m2_21_output_mae: 1.5606\n",
      "Epoch 3/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 123.4203 - t1_output_loss: 0.9469 - nu11_output_loss: 29.8653 - dyn11_output_loss: 0.9148 - s1_output_loss: 0.0824 - t2_output_loss: 1.0534 - nu21_output_loss: 38.4937 - nu22_output_loss: 43.9960 - dyn21_output_loss: 1.0611 - dyn22_output_loss: 1.0625 - m2_12_output_loss: 3.0849 - m2_21_output_loss: 2.8596 - t1_output_mae: 0.6659 - nu11_output_mae: 2.0934 - dyn11_output_categorical_accuracy: 0.6309 - s1_output_mae: 0.2485 - t2_output_mae: 0.7185 - nu21_output_mae: 2.6349 - nu22_output_mae: 2.7548 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 1.2588 - m2_21_output_mae: 1.1927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469e4e8160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469e4e8160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469e4e8040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469e4e8040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 69s 27ms/step - loss: 123.3730 - t1_output_loss: 0.9466 - nu11_output_loss: 29.8526 - dyn11_output_loss: 0.9147 - s1_output_loss: 0.0823 - t2_output_loss: 1.0534 - nu21_output_loss: 38.4748 - nu22_output_loss: 43.9818 - dyn21_output_loss: 1.0611 - dyn22_output_loss: 1.0625 - m2_12_output_loss: 3.0845 - m2_21_output_loss: 2.8586 - t1_output_mae: 0.6658 - nu11_output_mae: 2.0930 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2484 - t2_output_mae: 0.7185 - nu21_output_mae: 2.6344 - nu22_output_mae: 2.7546 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4443 - m2_12_output_mae: 1.2587 - m2_21_output_mae: 1.1925 - val_loss: 269.8051 - val_t1_output_loss: 0.9435 - val_nu11_output_loss: 94.0093 - val_dyn11_output_loss: 0.9222 - val_s1_output_loss: 0.0821 - val_t2_output_loss: 0.9810 - val_nu21_output_loss: 53.1209 - val_nu22_output_loss: 110.5664 - val_dyn21_output_loss: 1.0622 - val_dyn22_output_loss: 1.0601 - val_m2_12_output_loss: 3.9156 - val_m2_21_output_loss: 3.1419 - val_t1_output_mae: 0.7010 - val_nu11_output_mae: 8.5126 - val_dyn11_output_categorical_accuracy: 0.6342 - val_s1_output_mae: 0.2479 - val_t2_output_mae: 0.6786 - val_nu21_output_mae: 5.3072 - val_nu22_output_mae: 8.4441 - val_dyn21_output_categorical_accuracy: 0.4421 - val_dyn22_output_categorical_accuracy: 0.4462 - val_m2_12_output_mae: 1.5222 - val_m2_21_output_mae: 1.3156\n",
      "Epoch 4/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 112.0334 - t1_output_loss: 0.9362 - nu11_output_loss: 28.0850 - dyn11_output_loss: 0.9127 - s1_output_loss: 0.0819 - t2_output_loss: 1.0284 - nu21_output_loss: 35.8341 - nu22_output_loss: 37.5615 - dyn21_output_loss: 1.0602 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 2.8468 - m2_21_output_loss: 2.6249 - t1_output_mae: 0.6622 - nu11_output_mae: 2.0652 - dyn11_output_categorical_accuracy: 0.6307 - s1_output_mae: 0.2473 - t2_output_mae: 0.7070 - nu21_output_mae: 2.5224 - nu22_output_mae: 2.6506 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 1.1931 - m2_21_output_mae: 1.1226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a33560d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a33560d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c87481f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c87481f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 71s 28ms/step - loss: 112.1003 - t1_output_loss: 0.9363 - nu11_output_loss: 28.0903 - dyn11_output_loss: 0.9127 - s1_output_loss: 0.0818 - t2_output_loss: 1.0284 - nu21_output_loss: 35.9022 - nu22_output_loss: 37.5541 - dyn21_output_loss: 1.0602 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 2.8464 - m2_21_output_loss: 2.6259 - t1_output_mae: 0.6622 - nu11_output_mae: 2.0653 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2473 - t2_output_mae: 0.7069 - nu21_output_mae: 2.5229 - nu22_output_mae: 2.6505 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 1.1931 - m2_21_output_mae: 1.1228 - val_loss: 223.5538 - val_t1_output_loss: 0.9033 - val_nu11_output_loss: 70.1851 - val_dyn11_output_loss: 0.9248 - val_s1_output_loss: 0.0821 - val_t2_output_loss: 0.9788 - val_nu21_output_loss: 39.7033 - val_nu22_output_loss: 103.2618 - val_dyn21_output_loss: 1.0616 - val_dyn22_output_loss: 1.0597 - val_m2_12_output_loss: 3.0522 - val_m2_21_output_loss: 2.3411 - val_t1_output_mae: 0.6572 - val_nu11_output_mae: 7.0674 - val_dyn11_output_categorical_accuracy: 0.6334 - val_s1_output_mae: 0.2478 - val_t2_output_mae: 0.7105 - val_nu21_output_mae: 3.8498 - val_nu22_output_mae: 8.0899 - val_dyn21_output_categorical_accuracy: 0.4420 - val_dyn22_output_categorical_accuracy: 0.4444 - val_m2_12_output_mae: 1.3534 - val_m2_21_output_mae: 1.0887\n",
      "Epoch 5/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 107.8961 - t1_output_loss: 0.9127 - nu11_output_loss: 28.3705 - dyn11_output_loss: 0.9105 - s1_output_loss: 0.0814 - t2_output_loss: 0.9963 - nu21_output_loss: 34.7398 - nu22_output_loss: 34.6626 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0613 - m2_12_output_loss: 2.6448 - m2_21_output_loss: 2.4559 - t1_output_mae: 0.6516 - nu11_output_mae: 2.0995 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2466 - t2_output_mae: 0.6916 - nu21_output_mae: 2.4398 - nu22_output_mae: 2.5001 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 1.1346 - m2_21_output_mae: 1.0677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f4700e3e0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f4700e3e0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f47003c9280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f47003c9280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 107.8740 - t1_output_loss: 0.9128 - nu11_output_loss: 28.3681 - dyn11_output_loss: 0.9105 - s1_output_loss: 0.0814 - t2_output_loss: 0.9965 - nu21_output_loss: 34.7302 - nu22_output_loss: 34.6524 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0613 - m2_12_output_loss: 2.6449 - m2_21_output_loss: 2.4556 - t1_output_mae: 0.6516 - nu11_output_mae: 2.0995 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2466 - t2_output_mae: 0.6917 - nu21_output_mae: 2.4398 - nu22_output_mae: 2.4998 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 1.1346 - m2_21_output_mae: 1.0677 - val_loss: 180.0116 - val_t1_output_loss: 0.8774 - val_nu11_output_loss: 60.1128 - val_dyn11_output_loss: 0.9112 - val_s1_output_loss: 0.0821 - val_t2_output_loss: 0.9455 - val_nu21_output_loss: 36.4465 - val_nu22_output_loss: 74.3893 - val_dyn21_output_loss: 1.0621 - val_dyn22_output_loss: 1.0600 - val_m2_12_output_loss: 2.2174 - val_m2_21_output_loss: 1.9074 - val_t1_output_mae: 0.6374 - val_nu11_output_mae: 6.3875 - val_dyn11_output_categorical_accuracy: 0.6357 - val_s1_output_mae: 0.2475 - val_t2_output_mae: 0.6862 - val_nu21_output_mae: 3.7355 - val_nu22_output_mae: 6.3343 - val_dyn21_output_categorical_accuracy: 0.4408 - val_dyn22_output_categorical_accuracy: 0.4433 - val_m2_12_output_mae: 1.0565 - val_m2_21_output_mae: 0.9075\n",
      "Epoch 6/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 102.8103 - t1_output_loss: 0.9148 - nu11_output_loss: 27.0569 - dyn11_output_loss: 0.9107 - s1_output_loss: 0.0813 - t2_output_loss: 0.9759 - nu21_output_loss: 33.2804 - nu22_output_loss: 32.6970 - dyn21_output_loss: 1.0598 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 2.5152 - m2_21_output_loss: 2.2565 - t1_output_mae: 0.6518 - nu11_output_mae: 2.0874 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2464 - t2_output_mae: 0.6835 - nu21_output_mae: 2.3915 - nu22_output_mae: 2.3943 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 1.0926 - m2_21_output_mae: 1.0060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbfdb160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbfdb160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0237310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0237310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 58s 23ms/step - loss: 102.8368 - t1_output_loss: 0.9150 - nu11_output_loss: 27.0368 - dyn11_output_loss: 0.9108 - s1_output_loss: 0.0813 - t2_output_loss: 0.9758 - nu21_output_loss: 33.2665 - nu22_output_loss: 32.7570 - dyn21_output_loss: 1.0598 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 2.5157 - m2_21_output_loss: 2.2562 - t1_output_mae: 0.6518 - nu11_output_mae: 2.0871 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2464 - t2_output_mae: 0.6835 - nu21_output_mae: 2.3911 - nu22_output_mae: 2.3953 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 1.0926 - m2_21_output_mae: 1.0059 - val_loss: 152.8062 - val_t1_output_loss: 0.8788 - val_nu11_output_loss: 51.9681 - val_dyn11_output_loss: 0.9240 - val_s1_output_loss: 0.0817 - val_t2_output_loss: 1.0378 - val_nu21_output_loss: 37.3010 - val_nu22_output_loss: 54.4237 - val_dyn21_output_loss: 1.0635 - val_dyn22_output_loss: 1.0600 - val_m2_12_output_loss: 1.9842 - val_m2_21_output_loss: 2.0835 - val_t1_output_mae: 0.6422 - val_nu11_output_mae: 5.8021 - val_dyn11_output_categorical_accuracy: 0.6302 - val_s1_output_mae: 0.2470 - val_t2_output_mae: 0.6360 - val_nu21_output_mae: 3.8411 - val_nu22_output_mae: 4.9304 - val_dyn21_output_categorical_accuracy: 0.4404 - val_dyn22_output_categorical_accuracy: 0.4444 - val_m2_12_output_mae: 0.9926 - val_m2_21_output_mae: 1.0261\n",
      "Epoch 7/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 101.0814 - t1_output_loss: 0.9017 - nu11_output_loss: 26.4717 - dyn11_output_loss: 0.9096 - s1_output_loss: 0.0812 - t2_output_loss: 0.9637 - nu21_output_loss: 32.9450 - nu22_output_loss: 32.1892 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 2.3724 - m2_21_output_loss: 2.1259 - t1_output_mae: 0.6461 - nu11_output_mae: 2.0672 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2463 - t2_output_mae: 0.6768 - nu21_output_mae: 2.3654 - nu22_output_mae: 2.3532 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 1.0459 - m2_21_output_mae: 0.9582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d822c1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d822c1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c98f98b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c98f98b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 66s 26ms/step - loss: 101.0298 - t1_output_loss: 0.9014 - nu11_output_loss: 26.4527 - dyn11_output_loss: 0.9095 - s1_output_loss: 0.0812 - t2_output_loss: 0.9637 - nu21_output_loss: 32.9260 - nu22_output_loss: 32.1771 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 2.3717 - m2_21_output_loss: 2.1254 - t1_output_mae: 0.6460 - nu11_output_mae: 2.0665 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2463 - t2_output_mae: 0.6769 - nu21_output_mae: 2.3650 - nu22_output_mae: 2.3530 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 1.0457 - m2_21_output_mae: 0.9581 - val_loss: 163.1547 - val_t1_output_loss: 0.8911 - val_nu11_output_loss: 63.7749 - val_dyn11_output_loss: 0.9191 - val_s1_output_loss: 0.0812 - val_t2_output_loss: 1.0069 - val_nu21_output_loss: 37.0362 - val_nu22_output_loss: 53.3631 - val_dyn21_output_loss: 1.0616 - val_dyn22_output_loss: 1.0591 - val_m2_12_output_loss: 1.9158 - val_m2_21_output_loss: 2.0456 - val_t1_output_mae: 0.6601 - val_nu11_output_mae: 6.6585 - val_dyn11_output_categorical_accuracy: 0.6334 - val_s1_output_mae: 0.2462 - val_t2_output_mae: 0.6273 - val_nu21_output_mae: 3.5802 - val_nu22_output_mae: 4.9844 - val_dyn21_output_categorical_accuracy: 0.4419 - val_dyn22_output_categorical_accuracy: 0.4470 - val_m2_12_output_mae: 0.8842 - val_m2_21_output_mae: 1.0367\n",
      "Epoch 8/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 97.7052 - t1_output_loss: 0.9031 - nu11_output_loss: 25.9778 - dyn11_output_loss: 0.9097 - s1_output_loss: 0.0812 - t2_output_loss: 0.9543 - nu21_output_loss: 31.8498 - nu22_output_loss: 30.6220 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 2.2619 - m2_21_output_loss: 2.0241 - t1_output_mae: 0.6459 - nu11_output_mae: 2.0511 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2460 - t2_output_mae: 0.6732 - nu21_output_mae: 2.2963 - nu22_output_mae: 2.3176 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4437 - m2_12_output_mae: 1.0076 - m2_21_output_mae: 0.9198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d822c5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d822c5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8bcfdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8bcfdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 69s 28ms/step - loss: 97.7328 - t1_output_loss: 0.9031 - nu11_output_loss: 25.9620 - dyn11_output_loss: 0.9096 - s1_output_loss: 0.0812 - t2_output_loss: 0.9544 - nu21_output_loss: 31.9047 - nu22_output_loss: 30.6107 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 2.2617 - m2_21_output_loss: 2.0238 - t1_output_mae: 0.6459 - nu11_output_mae: 2.0503 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2460 - t2_output_mae: 0.6732 - nu21_output_mae: 2.2965 - nu22_output_mae: 2.3171 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 1.0076 - m2_21_output_mae: 0.9197 - val_loss: 127.8012 - val_t1_output_loss: 0.8660 - val_nu11_output_loss: 46.4551 - val_dyn11_output_loss: 0.9210 - val_s1_output_loss: 0.0818 - val_t2_output_loss: 0.9592 - val_nu21_output_loss: 32.4509 - val_nu22_output_loss: 39.7984 - val_dyn21_output_loss: 1.0614 - val_dyn22_output_loss: 1.0600 - val_m2_12_output_loss: 1.8061 - val_m2_21_output_loss: 2.3411 - val_t1_output_mae: 0.6296 - val_nu11_output_mae: 5.2567 - val_dyn11_output_categorical_accuracy: 0.6344 - val_s1_output_mae: 0.2470 - val_t2_output_mae: 0.7203 - val_nu21_output_mae: 3.1695 - val_nu22_output_mae: 3.8884 - val_dyn21_output_categorical_accuracy: 0.4426 - val_dyn22_output_categorical_accuracy: 0.4437 - val_m2_12_output_mae: 0.9672 - val_m2_21_output_mae: 1.1682\n",
      "Epoch 9/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 97.1433 - t1_output_loss: 0.8879 - nu11_output_loss: 26.9266 - dyn11_output_loss: 0.9089 - s1_output_loss: 0.0808 - t2_output_loss: 0.9383 - nu21_output_loss: 31.2757 - nu22_output_loss: 29.8984 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0613 - m2_12_output_loss: 2.1738 - m2_21_output_loss: 1.9313 - t1_output_mae: 0.6396 - nu11_output_mae: 2.0808 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2456 - t2_output_mae: 0.6666 - nu21_output_mae: 2.2768 - nu22_output_mae: 2.2920 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.9786 - m2_21_output_mae: 0.8883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f470058b040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f470058b040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8a15430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8a15430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 68s 27ms/step - loss: 97.1065 - t1_output_loss: 0.8882 - nu11_output_loss: 26.9217 - dyn11_output_loss: 0.9089 - s1_output_loss: 0.0808 - t2_output_loss: 0.9387 - nu21_output_loss: 31.2625 - nu22_output_loss: 29.8782 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 2.1738 - m2_21_output_loss: 1.9320 - t1_output_mae: 0.6397 - nu11_output_mae: 2.0807 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2456 - t2_output_mae: 0.6668 - nu21_output_mae: 2.2767 - nu22_output_mae: 2.2913 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.9785 - m2_21_output_mae: 0.8884 - val_loss: 117.8874 - val_t1_output_loss: 0.8882 - val_nu11_output_loss: 38.7927 - val_dyn11_output_loss: 0.9194 - val_s1_output_loss: 0.0814 - val_t2_output_loss: 0.9483 - val_nu21_output_loss: 30.7746 - val_nu22_output_loss: 40.0798 - val_dyn21_output_loss: 1.0621 - val_dyn22_output_loss: 1.0597 - val_m2_12_output_loss: 1.6812 - val_m2_21_output_loss: 1.6001 - val_t1_output_mae: 0.6627 - val_nu11_output_mae: 4.5329 - val_dyn11_output_categorical_accuracy: 0.6357 - val_s1_output_mae: 0.2463 - val_t2_output_mae: 0.7127 - val_nu21_output_mae: 2.8661 - val_nu22_output_mae: 4.0428 - val_dyn21_output_categorical_accuracy: 0.4409 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.8220 - val_m2_21_output_mae: 0.8515\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 94.4815 - t1_output_loss: 0.8905 - nu11_output_loss: 25.8988 - dyn11_output_loss: 0.9096 - s1_output_loss: 0.0809 - t2_output_loss: 0.9299 - nu21_output_loss: 30.4672 - nu22_output_loss: 29.2067 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 2.1106 - m2_21_output_loss: 1.8660 - t1_output_mae: 0.6406 - nu11_output_mae: 2.0564 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2456 - t2_output_mae: 0.6612 - nu21_output_mae: 2.2316 - nu22_output_mae: 2.2494 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.9560 - m2_21_output_mae: 0.8640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2b9e310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2b9e310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46cb487430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46cb487430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 69s 27ms/step - loss: 94.4815 - t1_output_loss: 0.8905 - nu11_output_loss: 25.8988 - dyn11_output_loss: 0.9096 - s1_output_loss: 0.0809 - t2_output_loss: 0.9299 - nu21_output_loss: 30.4672 - nu22_output_loss: 29.2067 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 2.1106 - m2_21_output_loss: 1.8660 - t1_output_mae: 0.6406 - nu11_output_mae: 2.0564 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2456 - t2_output_mae: 0.6612 - nu21_output_mae: 2.2316 - nu22_output_mae: 2.2494 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.9560 - m2_21_output_mae: 0.8640 - val_loss: 123.2802 - val_t1_output_loss: 0.8899 - val_nu11_output_loss: 40.1367 - val_dyn11_output_loss: 0.9243 - val_s1_output_loss: 0.0812 - val_t2_output_loss: 0.8698 - val_nu21_output_loss: 29.0465 - val_nu22_output_loss: 45.4734 - val_dyn21_output_loss: 1.0636 - val_dyn22_output_loss: 1.0603 - val_m2_12_output_loss: 1.7023 - val_m2_21_output_loss: 2.0322 - val_t1_output_mae: 0.6627 - val_nu11_output_mae: 4.7828 - val_dyn11_output_categorical_accuracy: 0.6295 - val_s1_output_mae: 0.2462 - val_t2_output_mae: 0.6416 - val_nu21_output_mae: 2.7688 - val_nu22_output_mae: 4.4933 - val_dyn21_output_categorical_accuracy: 0.4403 - val_dyn22_output_categorical_accuracy: 0.4437 - val_m2_12_output_mae: 0.9472 - val_m2_21_output_mae: 0.9807\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 94.0082 - t1_output_loss: 0.8827 - nu11_output_loss: 25.7498 - dyn11_output_loss: 0.9085 - s1_output_loss: 0.0808 - t2_output_loss: 0.9236 - nu21_output_loss: 30.2929 - nu22_output_loss: 29.2106 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 2.0290 - m2_21_output_loss: 1.8093 - t1_output_mae: 0.6365 - nu11_output_mae: 2.0609 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2454 - t2_output_mae: 0.6582 - nu21_output_mae: 2.2268 - nu22_output_mae: 2.2229 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.9277 - m2_21_output_mae: 0.8465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2708310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2708310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d98b94c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d98b94c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 71s 28ms/step - loss: 94.0082 - t1_output_loss: 0.8827 - nu11_output_loss: 25.7498 - dyn11_output_loss: 0.9085 - s1_output_loss: 0.0808 - t2_output_loss: 0.9236 - nu21_output_loss: 30.2929 - nu22_output_loss: 29.2106 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 2.0290 - m2_21_output_loss: 1.8093 - t1_output_mae: 0.6365 - nu11_output_mae: 2.0609 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2454 - t2_output_mae: 0.6582 - nu21_output_mae: 2.2268 - nu22_output_mae: 2.2229 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.9277 - m2_21_output_mae: 0.8465 - val_loss: 123.7695 - val_t1_output_loss: 0.8742 - val_nu11_output_loss: 45.3181 - val_dyn11_output_loss: 0.9161 - val_s1_output_loss: 0.0810 - val_t2_output_loss: 0.8575 - val_nu21_output_loss: 28.7095 - val_nu22_output_loss: 41.4133 - val_dyn21_output_loss: 1.0616 - val_dyn22_output_loss: 1.0591 - val_m2_12_output_loss: 1.9229 - val_m2_21_output_loss: 1.5560 - val_t1_output_mae: 0.6564 - val_nu11_output_mae: 5.2037 - val_dyn11_output_categorical_accuracy: 0.6336 - val_s1_output_mae: 0.2460 - val_t2_output_mae: 0.6540 - val_nu21_output_mae: 2.4649 - val_nu22_output_mae: 4.0897 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4470 - val_m2_12_output_mae: 0.8137 - val_m2_21_output_mae: 0.8176\n",
      "Epoch 12/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 91.8562 - t1_output_loss: 0.8845 - nu11_output_loss: 25.2758 - dyn11_output_loss: 0.9089 - s1_output_loss: 0.0807 - t2_output_loss: 0.9173 - nu21_output_loss: 29.6890 - nu22_output_loss: 28.2311 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.9682 - m2_21_output_loss: 1.7792 - t1_output_mae: 0.6375 - nu11_output_mae: 2.0305 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2452 - t2_output_mae: 0.6553 - nu21_output_mae: 2.1840 - nu22_output_mae: 2.1960 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.9095 - m2_21_output_mae: 0.8328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c9320280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c9320280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c93200d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c93200d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 65s 26ms/step - loss: 91.9289 - t1_output_loss: 0.8847 - nu11_output_loss: 25.2830 - dyn11_output_loss: 0.9090 - s1_output_loss: 0.0807 - t2_output_loss: 0.9173 - nu21_output_loss: 29.7630 - nu22_output_loss: 28.2221 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.9679 - m2_21_output_loss: 1.7798 - t1_output_mae: 0.6375 - nu11_output_mae: 2.0306 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2451 - t2_output_mae: 0.6553 - nu21_output_mae: 2.1847 - nu22_output_mae: 2.1957 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.9095 - m2_21_output_mae: 0.8329 - val_loss: 113.2388 - val_t1_output_loss: 0.8515 - val_nu11_output_loss: 38.9361 - val_dyn11_output_loss: 0.9176 - val_s1_output_loss: 0.0813 - val_t2_output_loss: 0.9125 - val_nu21_output_loss: 29.8151 - val_nu22_output_loss: 35.9556 - val_dyn21_output_loss: 1.0614 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 2.1712 - val_m2_21_output_loss: 1.4767 - val_t1_output_mae: 0.6200 - val_nu11_output_mae: 4.5820 - val_dyn11_output_categorical_accuracy: 0.6346 - val_s1_output_mae: 0.2463 - val_t2_output_mae: 0.6281 - val_nu21_output_mae: 2.7259 - val_nu22_output_mae: 3.5419 - val_dyn21_output_categorical_accuracy: 0.4428 - val_dyn22_output_categorical_accuracy: 0.4435 - val_m2_12_output_mae: 1.0848 - val_m2_21_output_mae: 0.7419\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 92.8901 - t1_output_loss: 0.8728 - nu11_output_loss: 26.4286 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0805 - t2_output_loss: 0.9075 - nu21_output_loss: 29.8450 - nu22_output_loss: 28.0826 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0613 - m2_12_output_loss: 1.9077 - m2_21_output_loss: 1.7351 - t1_output_mae: 0.6330 - nu11_output_mae: 2.0585 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2449 - t2_output_mae: 0.6497 - nu21_output_mae: 2.1807 - nu22_output_mae: 2.1823 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.8927 - m2_21_output_mae: 0.8212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a00560d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a00560d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0056280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0056280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 61s 25ms/step - loss: 92.8901 - t1_output_loss: 0.8728 - nu11_output_loss: 26.4286 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0805 - t2_output_loss: 0.9075 - nu21_output_loss: 29.8450 - nu22_output_loss: 28.0826 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0613 - m2_12_output_loss: 1.9077 - m2_21_output_loss: 1.7351 - t1_output_mae: 0.6330 - nu11_output_mae: 2.0585 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2449 - t2_output_mae: 0.6497 - nu21_output_mae: 2.1807 - nu22_output_mae: 2.1823 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.8927 - m2_21_output_mae: 0.8212 - val_loss: 114.6079 - val_t1_output_loss: 0.8806 - val_nu11_output_loss: 30.7012 - val_dyn11_output_loss: 0.9154 - val_s1_output_loss: 0.0810 - val_t2_output_loss: 0.8588 - val_nu21_output_loss: 28.6811 - val_nu22_output_loss: 47.6634 - val_dyn21_output_loss: 1.0621 - val_dyn22_output_loss: 1.0596 - val_m2_12_output_loss: 1.4831 - val_m2_21_output_loss: 1.2216 - val_t1_output_mae: 0.6647 - val_nu11_output_mae: 3.5471 - val_dyn11_output_categorical_accuracy: 0.6352 - val_s1_output_mae: 0.2457 - val_t2_output_mae: 0.6317 - val_nu21_output_mae: 2.7708 - val_nu22_output_mae: 4.4571 - val_dyn21_output_categorical_accuracy: 0.4409 - val_dyn22_output_categorical_accuracy: 0.4441 - val_m2_12_output_mae: 0.7690 - val_m2_21_output_mae: 0.6842\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 90.4781 - t1_output_loss: 0.8762 - nu11_output_loss: 25.2264 - dyn11_output_loss: 0.9092 - s1_output_loss: 0.0807 - t2_output_loss: 0.9020 - nu21_output_loss: 29.1051 - nu22_output_loss: 27.6667 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.8821 - m2_21_output_loss: 1.7082 - t1_output_mae: 0.6337 - nu11_output_mae: 2.0357 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2451 - t2_output_mae: 0.6466 - nu21_output_mae: 2.1539 - nu22_output_mae: 2.1438 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.8789 - m2_21_output_mae: 0.8109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c83aa040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c83aa040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d92f9dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d92f9dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 58s 23ms/step - loss: 90.4781 - t1_output_loss: 0.8762 - nu11_output_loss: 25.2264 - dyn11_output_loss: 0.9092 - s1_output_loss: 0.0807 - t2_output_loss: 0.9020 - nu21_output_loss: 29.1051 - nu22_output_loss: 27.6667 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.8821 - m2_21_output_loss: 1.7082 - t1_output_mae: 0.6337 - nu11_output_mae: 2.0357 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2451 - t2_output_mae: 0.6466 - nu21_output_mae: 2.1539 - nu22_output_mae: 2.1438 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.8789 - m2_21_output_mae: 0.8109 - val_loss: 123.0647 - val_t1_output_loss: 0.9234 - val_nu11_output_loss: 38.5766 - val_dyn11_output_loss: 0.9228 - val_s1_output_loss: 0.0808 - val_t2_output_loss: 0.8742 - val_nu21_output_loss: 38.1646 - val_nu22_output_loss: 38.5668 - val_dyn21_output_loss: 1.0638 - val_dyn22_output_loss: 1.0603 - val_m2_12_output_loss: 1.5928 - val_m2_21_output_loss: 1.2385 - val_t1_output_mae: 0.7089 - val_nu11_output_mae: 4.5972 - val_dyn11_output_categorical_accuracy: 0.6300 - val_s1_output_mae: 0.2457 - val_t2_output_mae: 0.6626 - val_nu21_output_mae: 3.9881 - val_nu22_output_mae: 3.7269 - val_dyn21_output_categorical_accuracy: 0.4398 - val_dyn22_output_categorical_accuracy: 0.4441 - val_m2_12_output_mae: 0.9036 - val_m2_21_output_mae: 0.6753\n",
      "Epoch 15/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 90.7014 - t1_output_loss: 0.8674 - nu11_output_loss: 25.0552 - dyn11_output_loss: 0.9083 - s1_output_loss: 0.0804 - t2_output_loss: 0.8976 - nu21_output_loss: 29.2967 - nu22_output_loss: 27.9611 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0611 - m2_12_output_loss: 1.8415 - m2_21_output_loss: 1.6722 - t1_output_mae: 0.6287 - nu11_output_mae: 2.0114 - dyn11_output_categorical_accuracy: 0.6309 - s1_output_mae: 0.2447 - t2_output_mae: 0.6448 - nu21_output_mae: 2.1662 - nu22_output_mae: 2.1393 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.8684 - m2_21_output_mae: 0.7995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d996d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d996d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db8ff9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db8ff9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 25ms/step - loss: 90.6649 - t1_output_loss: 0.8671 - nu11_output_loss: 25.0572 - dyn11_output_loss: 0.9082 - s1_output_loss: 0.0804 - t2_output_loss: 0.8978 - nu21_output_loss: 29.2736 - nu22_output_loss: 27.9457 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.8413 - m2_21_output_loss: 1.6727 - t1_output_mae: 0.6286 - nu11_output_mae: 2.0117 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2446 - t2_output_mae: 0.6450 - nu21_output_mae: 2.1655 - nu22_output_mae: 2.1393 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.8683 - m2_21_output_mae: 0.7996 - val_loss: 115.7979 - val_t1_output_loss: 0.8570 - val_nu11_output_loss: 42.3768 - val_dyn11_output_loss: 0.9168 - val_s1_output_loss: 0.0807 - val_t2_output_loss: 1.0839 - val_nu21_output_loss: 29.0176 - val_nu22_output_loss: 35.7298 - val_dyn21_output_loss: 1.0614 - val_dyn22_output_loss: 1.0593 - val_m2_12_output_loss: 2.0445 - val_m2_21_output_loss: 1.5701 - val_t1_output_mae: 0.6464 - val_nu11_output_mae: 4.9395 - val_dyn11_output_categorical_accuracy: 0.6328 - val_s1_output_mae: 0.2455 - val_t2_output_mae: 0.6103 - val_nu21_output_mae: 2.7200 - val_nu22_output_mae: 3.5821 - val_dyn21_output_categorical_accuracy: 0.4426 - val_dyn22_output_categorical_accuracy: 0.4464 - val_m2_12_output_mae: 0.7993 - val_m2_21_output_mae: 0.8375\n",
      "Epoch 16/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 88.8902 - t1_output_loss: 0.8713 - nu11_output_loss: 24.8875 - dyn11_output_loss: 0.9090 - s1_output_loss: 0.0803 - t2_output_loss: 0.8957 - nu21_output_loss: 28.6840 - nu22_output_loss: 26.9901 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.8154 - m2_21_output_loss: 1.6353 - t1_output_mae: 0.6308 - nu11_output_mae: 2.0016 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2445 - t2_output_mae: 0.6428 - nu21_output_mae: 2.1162 - nu22_output_mae: 2.1298 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.8590 - m2_21_output_mae: 0.7905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2ec60d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2ec60d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9b2ee50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9b2ee50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 88.9657 - t1_output_loss: 0.8714 - nu11_output_loss: 24.8956 - dyn11_output_loss: 0.9090 - s1_output_loss: 0.0803 - t2_output_loss: 0.8957 - nu21_output_loss: 28.7593 - nu22_output_loss: 26.9818 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.8153 - m2_21_output_loss: 1.6357 - t1_output_mae: 0.6308 - nu11_output_mae: 2.0017 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2445 - t2_output_mae: 0.6428 - nu21_output_mae: 2.1170 - nu22_output_mae: 2.1295 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.8590 - m2_21_output_mae: 0.7906 - val_loss: 99.6917 - val_t1_output_loss: 0.8744 - val_nu11_output_loss: 31.7553 - val_dyn11_output_loss: 0.9131 - val_s1_output_loss: 0.0807 - val_t2_output_loss: 1.0662 - val_nu21_output_loss: 27.6100 - val_nu22_output_loss: 32.0874 - val_dyn21_output_loss: 1.0615 - val_dyn22_output_loss: 1.0600 - val_m2_12_output_loss: 1.8602 - val_m2_21_output_loss: 1.3228 - val_t1_output_mae: 0.6558 - val_nu11_output_mae: 3.6880 - val_dyn11_output_categorical_accuracy: 0.6348 - val_s1_output_mae: 0.2454 - val_t2_output_mae: 0.7853 - val_nu21_output_mae: 2.4505 - val_nu22_output_mae: 3.1678 - val_dyn21_output_categorical_accuracy: 0.4425 - val_dyn22_output_categorical_accuracy: 0.4435 - val_m2_12_output_mae: 0.9787 - val_m2_21_output_mae: 0.6655\n",
      "Epoch 17/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 89.9834 - t1_output_loss: 0.8600 - nu11_output_loss: 25.8907 - dyn11_output_loss: 0.9083 - s1_output_loss: 0.0801 - t2_output_loss: 0.8859 - nu21_output_loss: 28.7960 - nu22_output_loss: 27.0403 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0613 - m2_12_output_loss: 1.7571 - m2_21_output_loss: 1.6435 - t1_output_mae: 0.6262 - nu11_output_mae: 2.0264 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2442 - t2_output_mae: 0.6367 - nu21_output_mae: 2.1142 - nu22_output_mae: 2.1126 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.8465 - m2_21_output_mae: 0.7913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469dd63af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469dd63af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469dd63f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469dd63f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 55s 22ms/step - loss: 89.9626 - t1_output_loss: 0.8601 - nu11_output_loss: 25.8896 - dyn11_output_loss: 0.9083 - s1_output_loss: 0.0801 - t2_output_loss: 0.8861 - nu21_output_loss: 28.7862 - nu22_output_loss: 27.0305 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.7572 - m2_21_output_loss: 1.6431 - t1_output_mae: 0.6262 - nu11_output_mae: 2.0263 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2442 - t2_output_mae: 0.6369 - nu21_output_mae: 2.1139 - nu22_output_mae: 2.1122 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.8465 - m2_21_output_mae: 0.7912 - val_loss: 105.5590 - val_t1_output_loss: 0.8325 - val_nu11_output_loss: 29.5985 - val_dyn11_output_loss: 0.9118 - val_s1_output_loss: 0.0805 - val_t2_output_loss: 0.8335 - val_nu21_output_loss: 26.9968 - val_nu22_output_loss: 39.0607 - val_dyn21_output_loss: 1.0623 - val_dyn22_output_loss: 1.0595 - val_m2_12_output_loss: 3.4760 - val_m2_21_output_loss: 1.6469 - val_t1_output_mae: 0.6179 - val_nu11_output_mae: 3.3012 - val_dyn11_output_categorical_accuracy: 0.6351 - val_s1_output_mae: 0.2448 - val_t2_output_mae: 0.6068 - val_nu21_output_mae: 2.4000 - val_nu22_output_mae: 3.7903 - val_dyn21_output_categorical_accuracy: 0.4405 - val_dyn22_output_categorical_accuracy: 0.4443 - val_m2_12_output_mae: 1.3837 - val_m2_21_output_mae: 0.8565\n",
      "Epoch 18/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 87.8022 - t1_output_loss: 0.8624 - nu11_output_loss: 24.7024 - dyn11_output_loss: 0.9091 - s1_output_loss: 0.0802 - t2_output_loss: 0.8779 - nu21_output_loss: 28.2453 - nu22_output_loss: 26.6455 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.7454 - m2_21_output_loss: 1.6125 - t1_output_mae: 0.6274 - nu11_output_mae: 1.9915 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2443 - t2_output_mae: 0.6323 - nu21_output_mae: 2.1055 - nu22_output_mae: 2.0783 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.8391 - m2_21_output_mae: 0.7780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469ddaf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469ddaf310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d96d1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d96d1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 61s 25ms/step - loss: 87.8604 - t1_output_loss: 0.8623 - nu11_output_loss: 24.6942 - dyn11_output_loss: 0.9091 - s1_output_loss: 0.0802 - t2_output_loss: 0.8778 - nu21_output_loss: 28.2393 - nu22_output_loss: 26.7184 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0619 - m2_12_output_loss: 1.7451 - m2_21_output_loss: 1.6125 - t1_output_mae: 0.6273 - nu11_output_mae: 1.9912 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2443 - t2_output_mae: 0.6322 - nu21_output_mae: 2.1055 - nu22_output_mae: 2.0793 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.8390 - m2_21_output_mae: 0.7780 - val_loss: 93.6160 - val_t1_output_loss: 0.9424 - val_nu11_output_loss: 30.1947 - val_dyn11_output_loss: 0.9184 - val_s1_output_loss: 0.0800 - val_t2_output_loss: 1.0672 - val_nu21_output_loss: 27.0673 - val_nu22_output_loss: 28.4324 - val_dyn21_output_loss: 1.0637 - val_dyn22_output_loss: 1.0605 - val_m2_12_output_loss: 1.5159 - val_m2_21_output_loss: 1.2733 - val_t1_output_mae: 0.7117 - val_nu11_output_mae: 3.5068 - val_dyn11_output_categorical_accuracy: 0.6307 - val_s1_output_mae: 0.2444 - val_t2_output_mae: 0.6452 - val_nu21_output_mae: 2.5197 - val_nu22_output_mae: 2.6754 - val_dyn21_output_categorical_accuracy: 0.4396 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.8475 - val_m2_21_output_mae: 0.6855\n",
      "Epoch 19/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 88.2326 - t1_output_loss: 0.8544 - nu11_output_loss: 24.7058 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0798 - t2_output_loss: 0.8717 - nu21_output_loss: 28.2303 - nu22_output_loss: 27.1720 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.7031 - m2_21_output_loss: 1.5862 - t1_output_mae: 0.6218 - nu11_output_mae: 1.9873 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2435 - t2_output_mae: 0.6282 - nu21_output_mae: 2.1008 - nu22_output_mae: 2.0870 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 0.8258 - m2_21_output_mae: 0.7725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d919fd30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d919fd30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9cf5040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9cf5040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 88.1854 - t1_output_loss: 0.8541 - nu11_output_loss: 24.6887 - dyn11_output_loss: 0.9083 - s1_output_loss: 0.0798 - t2_output_loss: 0.8716 - nu21_output_loss: 28.2124 - nu22_output_loss: 27.1613 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0611 - m2_12_output_loss: 1.7025 - m2_21_output_loss: 1.5857 - t1_output_mae: 0.6217 - nu11_output_mae: 1.9867 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2435 - t2_output_mae: 0.6283 - nu21_output_mae: 2.1001 - nu22_output_mae: 2.0869 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.8255 - m2_21_output_mae: 0.7724 - val_loss: 109.8098 - val_t1_output_loss: 0.8381 - val_nu11_output_loss: 43.7566 - val_dyn11_output_loss: 0.9148 - val_s1_output_loss: 0.0814 - val_t2_output_loss: 0.9716 - val_nu21_output_loss: 28.0916 - val_nu22_output_loss: 30.5362 - val_dyn21_output_loss: 1.0611 - val_dyn22_output_loss: 1.0589 - val_m2_12_output_loss: 1.3164 - val_m2_21_output_loss: 1.1831 - val_t1_output_mae: 0.6284 - val_nu11_output_mae: 5.0669 - val_dyn11_output_categorical_accuracy: 0.6326 - val_s1_output_mae: 0.2462 - val_t2_output_mae: 0.6072 - val_nu21_output_mae: 2.5680 - val_nu22_output_mae: 2.9775 - val_dyn21_output_categorical_accuracy: 0.4430 - val_dyn22_output_categorical_accuracy: 0.4469 - val_m2_12_output_mae: 0.7836 - val_m2_21_output_mae: 0.6620\n",
      "Epoch 20/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 86.7637 - t1_output_loss: 0.8595 - nu11_output_loss: 24.5280 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0799 - t2_output_loss: 0.8787 - nu21_output_loss: 27.8025 - nu22_output_loss: 26.3394 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.6755 - m2_21_output_loss: 1.5705 - t1_output_mae: 0.6247 - nu11_output_mae: 1.9725 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2436 - t2_output_mae: 0.6317 - nu21_output_mae: 2.0711 - nu22_output_mae: 2.0803 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4437 - m2_12_output_mae: 0.8150 - m2_21_output_mae: 0.7651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46995fe040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46995fe040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dbe1bee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dbe1bee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 86.7911 - t1_output_loss: 0.8596 - nu11_output_loss: 24.5183 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0799 - t2_output_loss: 0.8790 - nu21_output_loss: 27.8589 - nu22_output_loss: 26.3199 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.6752 - m2_21_output_loss: 1.5703 - t1_output_mae: 0.6247 - nu11_output_mae: 1.9719 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2435 - t2_output_mae: 0.6317 - nu21_output_mae: 2.0712 - nu22_output_mae: 2.0800 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.8151 - m2_21_output_mae: 0.7650 - val_loss: 98.8702 - val_t1_output_loss: 0.9544 - val_nu11_output_loss: 28.2524 - val_dyn11_output_loss: 0.9141 - val_s1_output_loss: 0.0799 - val_t2_output_loss: 0.9319 - val_nu21_output_loss: 26.6263 - val_nu22_output_loss: 33.5296 - val_dyn21_output_loss: 1.0615 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 4.0415 - val_m2_21_output_loss: 1.4187 - val_t1_output_mae: 0.7306 - val_nu11_output_mae: 2.9891 - val_dyn11_output_categorical_accuracy: 0.6353 - val_s1_output_mae: 0.2441 - val_t2_output_mae: 0.6986 - val_nu21_output_mae: 2.2169 - val_nu22_output_mae: 3.1462 - val_dyn21_output_categorical_accuracy: 0.4426 - val_dyn22_output_categorical_accuracy: 0.4440 - val_m2_12_output_mae: 1.4741 - val_m2_21_output_mae: 0.7585\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 87.5831 - t1_output_loss: 0.8467 - nu11_output_loss: 25.3269 - dyn11_output_loss: 0.9080 - s1_output_loss: 0.0796 - t2_output_loss: 0.8681 - nu21_output_loss: 27.9511 - nu22_output_loss: 26.2776 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.6478 - m2_21_output_loss: 1.5557 - t1_output_mae: 0.6195 - nu11_output_mae: 1.9971 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2434 - t2_output_mae: 0.6265 - nu21_output_mae: 2.0720 - nu22_output_mae: 2.0564 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.8080 - m2_21_output_mae: 0.7581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d9dea040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d9dea040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9dea3a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9dea3a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 87.5831 - t1_output_loss: 0.8467 - nu11_output_loss: 25.3269 - dyn11_output_loss: 0.9080 - s1_output_loss: 0.0796 - t2_output_loss: 0.8681 - nu21_output_loss: 27.9511 - nu22_output_loss: 26.2776 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.6478 - m2_21_output_loss: 1.5557 - t1_output_mae: 0.6195 - nu11_output_mae: 1.9971 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2434 - t2_output_mae: 0.6265 - nu21_output_mae: 2.0720 - nu22_output_mae: 2.0564 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.8080 - m2_21_output_mae: 0.7581 - val_loss: 108.2670 - val_t1_output_loss: 0.8818 - val_nu11_output_loss: 28.3375 - val_dyn11_output_loss: 0.9100 - val_s1_output_loss: 0.0796 - val_t2_output_loss: 1.1786 - val_nu21_output_loss: 30.4880 - val_nu22_output_loss: 40.8488 - val_dyn21_output_loss: 1.0622 - val_dyn22_output_loss: 1.0596 - val_m2_12_output_loss: 2.2070 - val_m2_21_output_loss: 1.2140 - val_t1_output_mae: 0.6831 - val_nu11_output_mae: 3.1871 - val_dyn11_output_categorical_accuracy: 0.6345 - val_s1_output_mae: 0.2434 - val_t2_output_mae: 0.6754 - val_nu21_output_mae: 2.8194 - val_nu22_output_mae: 3.9295 - val_dyn21_output_categorical_accuracy: 0.4408 - val_dyn22_output_categorical_accuracy: 0.4441 - val_m2_12_output_mae: 1.0171 - val_m2_21_output_mae: 0.6785\n",
      "Epoch 22/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 86.0959 - t1_output_loss: 0.8538 - nu11_output_loss: 24.3134 - dyn11_output_loss: 0.9090 - s1_output_loss: 0.0797 - t2_output_loss: 0.8616 - nu21_output_loss: 27.6171 - nu22_output_loss: 26.1586 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.6404 - m2_21_output_loss: 1.5407 - t1_output_mae: 0.6220 - nu11_output_mae: 1.9760 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2434 - t2_output_mae: 0.6238 - nu21_output_mae: 2.0590 - nu22_output_mae: 2.0418 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.8036 - m2_21_output_mae: 0.7541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d97f6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d97f6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8d41ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8d41ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 66s 26ms/step - loss: 86.1530 - t1_output_loss: 0.8537 - nu11_output_loss: 24.3059 - dyn11_output_loss: 0.9090 - s1_output_loss: 0.0797 - t2_output_loss: 0.8614 - nu21_output_loss: 27.6094 - nu22_output_loss: 26.2315 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.6402 - m2_21_output_loss: 1.5406 - t1_output_mae: 0.6219 - nu11_output_mae: 1.9758 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2434 - t2_output_mae: 0.6237 - nu21_output_mae: 2.0589 - nu22_output_mae: 2.0430 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.8035 - m2_21_output_mae: 0.7540 - val_loss: 86.9363 - val_t1_output_loss: 0.9323 - val_nu11_output_loss: 25.8655 - val_dyn11_output_loss: 0.9169 - val_s1_output_loss: 0.0827 - val_t2_output_loss: 0.7930 - val_nu21_output_loss: 26.3883 - val_nu22_output_loss: 27.0269 - val_dyn21_output_loss: 1.0636 - val_dyn22_output_loss: 1.0607 - val_m2_12_output_loss: 1.6187 - val_m2_21_output_loss: 1.1878 - val_t1_output_mae: 0.7243 - val_nu11_output_mae: 2.6972 - val_dyn11_output_categorical_accuracy: 0.6305 - val_s1_output_mae: 0.2476 - val_t2_output_mae: 0.5750 - val_nu21_output_mae: 2.4413 - val_nu22_output_mae: 2.3371 - val_dyn21_output_categorical_accuracy: 0.4397 - val_dyn22_output_categorical_accuracy: 0.4434 - val_m2_12_output_mae: 0.8919 - val_m2_21_output_mae: 0.6747\n",
      "Epoch 23/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 87.1437 - t1_output_loss: 0.8467 - nu11_output_loss: 24.3526 - dyn11_output_loss: 0.9081 - s1_output_loss: 0.0794 - t2_output_loss: 0.8602 - nu21_output_loss: 28.2355 - nu22_output_loss: 26.6152 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.6045 - m2_21_output_loss: 1.5205 - t1_output_mae: 0.6181 - nu11_output_mae: 1.9706 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2427 - t2_output_mae: 0.6223 - nu21_output_mae: 2.0793 - nu22_output_mae: 2.0468 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 0.7951 - m2_21_output_mae: 0.7457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c9df83a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c9df83a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46cb21eee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46cb21eee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 57s 23ms/step - loss: 87.0983 - t1_output_loss: 0.8465 - nu11_output_loss: 24.3375 - dyn11_output_loss: 0.9080 - s1_output_loss: 0.0794 - t2_output_loss: 0.8602 - nu21_output_loss: 28.2175 - nu22_output_loss: 26.6040 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.6040 - m2_21_output_loss: 1.5202 - t1_output_mae: 0.6181 - nu11_output_mae: 1.9702 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2427 - t2_output_mae: 0.6223 - nu21_output_mae: 2.0788 - nu22_output_mae: 2.0468 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7950 - m2_21_output_mae: 0.7456 - val_loss: 139.9505 - val_t1_output_loss: 0.8956 - val_nu11_output_loss: 28.5604 - val_dyn11_output_loss: 0.9099 - val_s1_output_loss: 0.0798 - val_t2_output_loss: 0.8763 - val_nu21_output_loss: 26.4735 - val_nu22_output_loss: 77.2347 - val_dyn21_output_loss: 1.0616 - val_dyn22_output_loss: 1.0585 - val_m2_12_output_loss: 1.4684 - val_m2_21_output_loss: 1.3318 - val_t1_output_mae: 0.6858 - val_nu11_output_mae: 3.1511 - val_dyn11_output_categorical_accuracy: 0.6332 - val_s1_output_mae: 0.2440 - val_t2_output_mae: 0.6689 - val_nu21_output_mae: 2.3459 - val_nu22_output_mae: 5.6059 - val_dyn21_output_categorical_accuracy: 0.4422 - val_dyn22_output_categorical_accuracy: 0.4476 - val_m2_12_output_mae: 0.6875 - val_m2_21_output_mae: 0.6937\n",
      "Epoch 24/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 85.1789 - t1_output_loss: 0.8503 - nu11_output_loss: 23.9731 - dyn11_output_loss: 0.9086 - s1_output_loss: 0.0794 - t2_output_loss: 0.8622 - nu21_output_loss: 27.4721 - nu22_output_loss: 25.8178 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.5919 - m2_21_output_loss: 1.5019 - t1_output_mae: 0.6196 - nu11_output_mae: 1.9485 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2428 - t2_output_mae: 0.6232 - nu21_output_mae: 2.0453 - nu22_output_mae: 2.0228 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4437 - m2_12_output_mae: 0.7906 - m2_21_output_mae: 0.7400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a0355040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a0355040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46cb68e040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46cb68e040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 56s 22ms/step - loss: 85.2012 - t1_output_loss: 0.8503 - nu11_output_loss: 23.9588 - dyn11_output_loss: 0.9086 - s1_output_loss: 0.0794 - t2_output_loss: 0.8623 - nu21_output_loss: 27.5292 - nu22_output_loss: 25.7976 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.5913 - m2_21_output_loss: 1.5020 - t1_output_mae: 0.6196 - nu11_output_mae: 1.9478 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2428 - t2_output_mae: 0.6232 - nu21_output_mae: 2.0456 - nu22_output_mae: 2.0222 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7906 - m2_21_output_mae: 0.7400 - val_loss: 91.9265 - val_t1_output_loss: 0.9274 - val_nu11_output_loss: 26.9974 - val_dyn11_output_loss: 0.9096 - val_s1_output_loss: 0.0806 - val_t2_output_loss: 0.8673 - val_nu21_output_loss: 25.9721 - val_nu22_output_loss: 30.9663 - val_dyn21_output_loss: 1.0611 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.9533 - val_m2_21_output_loss: 1.1315 - val_t1_output_mae: 0.7126 - val_nu11_output_mae: 2.7588 - val_dyn11_output_categorical_accuracy: 0.6351 - val_s1_output_mae: 0.2444 - val_t2_output_mae: 0.5853 - val_nu21_output_mae: 2.0901 - val_nu22_output_mae: 2.8371 - val_dyn21_output_categorical_accuracy: 0.4432 - val_dyn22_output_categorical_accuracy: 0.4440 - val_m2_12_output_mae: 0.9877 - val_m2_21_output_mae: 0.6149\n",
      "Epoch 25/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 86.7692 - t1_output_loss: 0.8366 - nu11_output_loss: 25.3573 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0792 - t2_output_loss: 0.8526 - nu21_output_loss: 27.6978 - nu22_output_loss: 25.8368 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.5714 - m2_21_output_loss: 1.5083 - t1_output_mae: 0.6139 - nu11_output_mae: 1.9801 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2424 - t2_output_mae: 0.6195 - nu21_output_mae: 2.0469 - nu22_output_mae: 2.0258 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7835 - m2_21_output_mae: 0.7408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca1a9dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca1a9dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d81d7670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d81d7670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 62s 25ms/step - loss: 86.7374 - t1_output_loss: 0.8370 - nu11_output_loss: 25.3515 - dyn11_output_loss: 0.9078 - s1_output_loss: 0.0792 - t2_output_loss: 0.8528 - nu21_output_loss: 27.6873 - nu22_output_loss: 25.8200 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.5713 - m2_21_output_loss: 1.5090 - t1_output_mae: 0.6140 - nu11_output_mae: 1.9800 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2423 - t2_output_mae: 0.6197 - nu21_output_mae: 2.0468 - nu22_output_mae: 2.0251 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7834 - m2_21_output_mae: 0.7410 - val_loss: 89.3540 - val_t1_output_loss: 0.9784 - val_nu11_output_loss: 24.6701 - val_dyn11_output_loss: 0.9094 - val_s1_output_loss: 0.0806 - val_t2_output_loss: 1.1584 - val_nu21_output_loss: 29.6209 - val_nu22_output_loss: 26.5374 - val_dyn21_output_loss: 1.0622 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.7215 - val_m2_21_output_loss: 1.5552 - val_t1_output_mae: 0.7580 - val_nu11_output_mae: 2.2725 - val_dyn11_output_categorical_accuracy: 0.6350 - val_s1_output_mae: 0.2448 - val_t2_output_mae: 0.8297 - val_nu21_output_mae: 2.8248 - val_nu22_output_mae: 2.5138 - val_dyn21_output_categorical_accuracy: 0.4406 - val_dyn22_output_categorical_accuracy: 0.4438 - val_m2_12_output_mae: 0.9227 - val_m2_21_output_mae: 0.6728\n",
      "Epoch 26/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 85.5191 - t1_output_loss: 0.8398 - nu11_output_loss: 24.2818 - dyn11_output_loss: 0.9088 - s1_output_loss: 0.0793 - t2_output_loss: 0.8512 - nu21_output_loss: 27.5624 - nu22_output_loss: 25.8083 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.5746 - m2_21_output_loss: 1.4915 - t1_output_mae: 0.6156 - nu11_output_mae: 1.9639 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2425 - t2_output_mae: 0.6177 - nu21_output_mae: 2.0468 - nu22_output_mae: 2.0126 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7829 - m2_21_output_mae: 0.7335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8d2c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8d2c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da027430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da027430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 85.5739 - t1_output_loss: 0.8397 - nu11_output_loss: 24.2696 - dyn11_output_loss: 0.9088 - s1_output_loss: 0.0793 - t2_output_loss: 0.8510 - nu21_output_loss: 27.5653 - nu22_output_loss: 25.8726 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.5746 - m2_21_output_loss: 1.4914 - t1_output_mae: 0.6156 - nu11_output_mae: 1.9638 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2425 - t2_output_mae: 0.6176 - nu21_output_mae: 2.0470 - nu22_output_mae: 2.0135 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7830 - m2_21_output_mae: 0.7335 - val_loss: 104.8870 - val_t1_output_loss: 0.8695 - val_nu11_output_loss: 27.4196 - val_dyn11_output_loss: 0.9178 - val_s1_output_loss: 0.0789 - val_t2_output_loss: 2.0832 - val_nu21_output_loss: 25.5421 - val_nu22_output_loss: 43.1132 - val_dyn21_output_loss: 1.0636 - val_dyn22_output_loss: 1.0606 - val_m2_12_output_loss: 1.4765 - val_m2_21_output_loss: 1.2621 - val_t1_output_mae: 0.6711 - val_nu11_output_mae: 3.0470 - val_dyn11_output_categorical_accuracy: 0.6298 - val_s1_output_mae: 0.2424 - val_t2_output_mae: 1.1168 - val_nu21_output_mae: 2.2139 - val_nu22_output_mae: 4.0138 - val_dyn21_output_categorical_accuracy: 0.4396 - val_dyn22_output_categorical_accuracy: 0.4434 - val_m2_12_output_mae: 0.9079 - val_m2_21_output_mae: 0.6323\n",
      "Epoch 27/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 85.7690 - t1_output_loss: 0.8395 - nu11_output_loss: 24.2329 - dyn11_output_loss: 0.9076 - s1_output_loss: 0.0791 - t2_output_loss: 0.8469 - nu21_output_loss: 27.6358 - nu22_output_loss: 26.0887 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.5457 - m2_21_output_loss: 1.4719 - t1_output_mae: 0.6152 - nu11_output_mae: 1.9622 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2421 - t2_output_mae: 0.6154 - nu21_output_mae: 2.0605 - nu22_output_mae: 2.0136 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7762 - m2_21_output_mae: 0.7286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c87380d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c87380d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469f7ea430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469f7ea430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 85.7509 - t1_output_loss: 0.8394 - nu11_output_loss: 24.2250 - dyn11_output_loss: 0.9076 - s1_output_loss: 0.0791 - t2_output_loss: 0.8470 - nu21_output_loss: 27.6275 - nu22_output_loss: 26.0872 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.5454 - m2_21_output_loss: 1.4717 - t1_output_mae: 0.6152 - nu11_output_mae: 1.9619 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2420 - t2_output_mae: 0.6155 - nu21_output_mae: 2.0603 - nu22_output_mae: 2.0135 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7762 - m2_21_output_mae: 0.7285 - val_loss: 97.1933 - val_t1_output_loss: 0.9644 - val_nu11_output_loss: 35.9410 - val_dyn11_output_loss: 0.9102 - val_s1_output_loss: 0.0785 - val_t2_output_loss: 1.1493 - val_nu21_output_loss: 25.7862 - val_nu22_output_loss: 27.7834 - val_dyn21_output_loss: 1.0618 - val_dyn22_output_loss: 1.0588 - val_m2_12_output_loss: 1.2865 - val_m2_21_output_loss: 1.1733 - val_t1_output_mae: 0.7441 - val_nu11_output_mae: 4.1789 - val_dyn11_output_categorical_accuracy: 0.6338 - val_s1_output_mae: 0.2414 - val_t2_output_mae: 0.7394 - val_nu21_output_mae: 2.3096 - val_nu22_output_mae: 2.5956 - val_dyn21_output_categorical_accuracy: 0.4419 - val_dyn22_output_categorical_accuracy: 0.4471 - val_m2_12_output_mae: 0.6571 - val_m2_21_output_mae: 0.6075\n",
      "Epoch 28/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 84.5598 - t1_output_loss: 0.8410 - nu11_output_loss: 23.7406 - dyn11_output_loss: 0.9085 - s1_output_loss: 0.0791 - t2_output_loss: 0.8486 - nu21_output_loss: 27.1678 - nu22_output_loss: 25.8773 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.5110 - m2_21_output_loss: 1.4645 - t1_output_mae: 0.6150 - nu11_output_mae: 1.9312 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2419 - t2_output_mae: 0.6170 - nu21_output_mae: 2.0270 - nu22_output_mae: 2.0126 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7650 - m2_21_output_mae: 0.7271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46db7240d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46db7240d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3bf8430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3bf8430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 53s 21ms/step - loss: 84.6355 - t1_output_loss: 0.8410 - nu11_output_loss: 23.7474 - dyn11_output_loss: 0.9085 - s1_output_loss: 0.0791 - t2_output_loss: 0.8487 - nu21_output_loss: 27.2438 - nu22_output_loss: 25.8694 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.5110 - m2_21_output_loss: 1.4651 - t1_output_mae: 0.6150 - nu11_output_mae: 1.9313 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2419 - t2_output_mae: 0.6170 - nu21_output_mae: 2.0276 - nu22_output_mae: 2.0124 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7650 - m2_21_output_mae: 0.7271 - val_loss: 89.3810 - val_t1_output_loss: 0.8216 - val_nu11_output_loss: 25.9847 - val_dyn11_output_loss: 0.9098 - val_s1_output_loss: 0.0787 - val_t2_output_loss: 1.2032 - val_nu21_output_loss: 25.5968 - val_nu22_output_loss: 29.4880 - val_dyn21_output_loss: 1.0611 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.8911 - val_m2_21_output_loss: 1.2861 - val_t1_output_mae: 0.6223 - val_nu11_output_mae: 2.3434 - val_dyn11_output_categorical_accuracy: 0.6352 - val_s1_output_mae: 0.2415 - val_t2_output_mae: 0.8625 - val_nu21_output_mae: 1.9193 - val_nu22_output_mae: 2.8172 - val_dyn21_output_categorical_accuracy: 0.4433 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.9657 - val_m2_21_output_mae: 0.6236\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 85.4015 - t1_output_loss: 0.8296 - nu11_output_loss: 24.8709 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0791 - t2_output_loss: 0.8475 - nu21_output_loss: 27.3793 - nu22_output_loss: 25.3849 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.5114 - m2_21_output_loss: 1.4696 - t1_output_mae: 0.6105 - nu11_output_mae: 1.9551 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2422 - t2_output_mae: 0.6163 - nu21_output_mae: 2.0311 - nu22_output_mae: 1.9943 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7662 - m2_21_output_mae: 0.7279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8daf040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8daf040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8daf1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8daf1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 66s 26ms/step - loss: 85.4015 - t1_output_loss: 0.8296 - nu11_output_loss: 24.8709 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0791 - t2_output_loss: 0.8475 - nu21_output_loss: 27.3793 - nu22_output_loss: 25.3849 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.5114 - m2_21_output_loss: 1.4696 - t1_output_mae: 0.6105 - nu11_output_mae: 1.9551 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2422 - t2_output_mae: 0.6163 - nu21_output_mae: 2.0311 - nu22_output_mae: 1.9943 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7662 - m2_21_output_mae: 0.7279 - val_loss: 90.3034 - val_t1_output_loss: 0.8506 - val_nu11_output_loss: 26.5927 - val_dyn11_output_loss: 0.9111 - val_s1_output_loss: 0.0789 - val_t2_output_loss: 1.0891 - val_nu21_output_loss: 25.4087 - val_nu22_output_loss: 30.1473 - val_dyn21_output_loss: 1.0623 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 1.9349 - val_m2_21_output_loss: 1.1679 - val_t1_output_mae: 0.6576 - val_nu11_output_mae: 2.8594 - val_dyn11_output_categorical_accuracy: 0.6344 - val_s1_output_mae: 0.2428 - val_t2_output_mae: 0.5941 - val_nu21_output_mae: 2.1877 - val_nu22_output_mae: 2.9220 - val_dyn21_output_categorical_accuracy: 0.4405 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.9833 - val_m2_21_output_mae: 0.5942\n",
      "Epoch 30/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 83.7933 - t1_output_loss: 0.8328 - nu11_output_loss: 23.8597 - dyn11_output_loss: 0.9089 - s1_output_loss: 0.0789 - t2_output_loss: 0.8435 - nu21_output_loss: 26.9305 - nu22_output_loss: 25.2602 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.5146 - m2_21_output_loss: 1.4427 - t1_output_mae: 0.6133 - nu11_output_mae: 1.9426 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2417 - t2_output_mae: 0.6143 - nu21_output_mae: 2.0203 - nu22_output_mae: 1.9849 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7656 - m2_21_output_mae: 0.7171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cb4200d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cb4200d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da9b8ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da9b8ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 83.8502 - t1_output_loss: 0.8327 - nu11_output_loss: 23.8512 - dyn11_output_loss: 0.9089 - s1_output_loss: 0.0789 - t2_output_loss: 0.8433 - nu21_output_loss: 26.9238 - nu22_output_loss: 25.3321 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.5147 - m2_21_output_loss: 1.4429 - t1_output_mae: 0.6132 - nu11_output_mae: 1.9423 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2417 - t2_output_mae: 0.6142 - nu21_output_mae: 2.0202 - nu22_output_mae: 1.9860 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7657 - m2_21_output_mae: 0.7172 - val_loss: 95.3741 - val_t1_output_loss: 0.9030 - val_nu11_output_loss: 27.5047 - val_dyn11_output_loss: 0.9164 - val_s1_output_loss: 0.0790 - val_t2_output_loss: 0.7687 - val_nu21_output_loss: 26.0350 - val_nu22_output_loss: 33.2538 - val_dyn21_output_loss: 1.0637 - val_dyn22_output_loss: 1.0600 - val_m2_12_output_loss: 1.4981 - val_m2_21_output_loss: 2.2916 - val_t1_output_mae: 0.6951 - val_nu11_output_mae: 3.0655 - val_dyn11_output_categorical_accuracy: 0.6302 - val_s1_output_mae: 0.2429 - val_t2_output_mae: 0.5725 - val_nu21_output_mae: 2.4146 - val_nu22_output_mae: 3.1671 - val_dyn21_output_categorical_accuracy: 0.4398 - val_dyn22_output_categorical_accuracy: 0.4443 - val_m2_12_output_mae: 0.8588 - val_m2_21_output_mae: 0.8040\n",
      "Epoch 31/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 84.7676 - t1_output_loss: 0.8310 - nu11_output_loss: 24.0942 - dyn11_output_loss: 0.9081 - s1_output_loss: 0.0788 - t2_output_loss: 0.8421 - nu21_output_loss: 27.0315 - nu22_output_loss: 25.9464 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0611 - m2_12_output_loss: 1.4823 - m2_21_output_loss: 1.4324 - t1_output_mae: 0.6103 - nu11_output_mae: 1.9460 - dyn11_output_categorical_accuracy: 0.6309 - s1_output_mae: 0.2416 - t2_output_mae: 0.6135 - nu21_output_mae: 2.0304 - nu22_output_mae: 1.9828 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7558 - m2_21_output_mae: 0.7171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a35b95e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a35b95e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d989c430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d989c430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 53s 21ms/step - loss: 84.7240 - t1_output_loss: 0.8307 - nu11_output_loss: 24.0841 - dyn11_output_loss: 0.9079 - s1_output_loss: 0.0788 - t2_output_loss: 0.8422 - nu21_output_loss: 27.0138 - nu22_output_loss: 25.9321 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.4815 - m2_21_output_loss: 1.4321 - t1_output_mae: 0.6102 - nu11_output_mae: 1.9461 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2416 - t2_output_mae: 0.6136 - nu21_output_mae: 2.0299 - nu22_output_mae: 1.9827 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7555 - m2_21_output_mae: 0.7169 - val_loss: 110.2226 - val_t1_output_loss: 0.8083 - val_nu11_output_loss: 41.7731 - val_dyn11_output_loss: 0.9100 - val_s1_output_loss: 0.0782 - val_t2_output_loss: 0.9202 - val_nu21_output_loss: 26.4611 - val_nu22_output_loss: 33.9656 - val_dyn21_output_loss: 1.0617 - val_dyn22_output_loss: 1.0590 - val_m2_12_output_loss: 1.3398 - val_m2_21_output_loss: 1.8456 - val_t1_output_mae: 0.5904 - val_nu11_output_mae: 4.8292 - val_dyn11_output_categorical_accuracy: 0.6332 - val_s1_output_mae: 0.2411 - val_t2_output_mae: 0.5890 - val_nu21_output_mae: 2.3164 - val_nu22_output_mae: 3.0685 - val_dyn21_output_categorical_accuracy: 0.4421 - val_dyn22_output_categorical_accuracy: 0.4466 - val_m2_12_output_mae: 0.6513 - val_m2_21_output_mae: 0.8921\n",
      "Epoch 32/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 83.3752 - t1_output_loss: 0.8328 - nu11_output_loss: 23.5818 - dyn11_output_loss: 0.9083 - s1_output_loss: 0.0789 - t2_output_loss: 0.8410 - nu21_output_loss: 26.8860 - nu22_output_loss: 25.2175 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.4761 - m2_21_output_loss: 1.4312 - t1_output_mae: 0.6106 - nu11_output_mae: 1.9299 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2415 - t2_output_mae: 0.6126 - nu21_output_mae: 2.0030 - nu22_output_mae: 1.9842 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7547 - m2_21_output_mae: 0.7156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a29a01f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a29a01f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a29a0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a29a0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 65s 26ms/step - loss: 83.4256 - t1_output_loss: 0.8329 - nu11_output_loss: 23.5811 - dyn11_output_loss: 0.9083 - s1_output_loss: 0.0789 - t2_output_loss: 0.8411 - nu21_output_loss: 26.9538 - nu22_output_loss: 25.2002 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.4761 - m2_21_output_loss: 1.4314 - t1_output_mae: 0.6106 - nu11_output_mae: 1.9297 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2415 - t2_output_mae: 0.6126 - nu21_output_mae: 2.0036 - nu22_output_mae: 1.9836 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7548 - m2_21_output_mae: 0.7156 - val_loss: 87.0640 - val_t1_output_loss: 1.0259 - val_nu11_output_loss: 25.1682 - val_dyn11_output_loss: 0.9074 - val_s1_output_loss: 0.0785 - val_t2_output_loss: 1.0082 - val_nu21_output_loss: 25.5705 - val_nu22_output_loss: 27.9311 - val_dyn21_output_loss: 1.0613 - val_dyn22_output_loss: 1.0595 - val_m2_12_output_loss: 1.2114 - val_m2_21_output_loss: 2.0419 - val_t1_output_mae: 0.7774 - val_nu11_output_mae: 2.2110 - val_dyn11_output_categorical_accuracy: 0.6354 - val_s1_output_mae: 0.2409 - val_t2_output_mae: 0.6034 - val_nu21_output_mae: 2.1799 - val_nu22_output_mae: 2.6221 - val_dyn21_output_categorical_accuracy: 0.4432 - val_dyn22_output_categorical_accuracy: 0.4444 - val_m2_12_output_mae: 0.7311 - val_m2_21_output_mae: 0.7647\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 84.6705 - t1_output_loss: 0.8211 - nu11_output_loss: 24.6867 - dyn11_output_loss: 0.9079 - s1_output_loss: 0.0787 - t2_output_loss: 0.8333 - nu21_output_loss: 27.1103 - nu22_output_loss: 25.2335 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.4643 - m2_21_output_loss: 1.4130 - t1_output_mae: 0.6071 - nu11_output_mae: 1.9488 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2415 - t2_output_mae: 0.6080 - nu21_output_mae: 2.0096 - nu22_output_mae: 1.9868 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7495 - m2_21_output_mae: 0.7115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a35b9940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a35b9940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da46c160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da46c160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 59s 24ms/step - loss: 84.6705 - t1_output_loss: 0.8211 - nu11_output_loss: 24.6867 - dyn11_output_loss: 0.9079 - s1_output_loss: 0.0787 - t2_output_loss: 0.8333 - nu21_output_loss: 27.1103 - nu22_output_loss: 25.2335 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.4643 - m2_21_output_loss: 1.4130 - t1_output_mae: 0.6071 - nu11_output_mae: 1.9488 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2415 - t2_output_mae: 0.6080 - nu21_output_mae: 2.0096 - nu22_output_mae: 1.9868 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7495 - m2_21_output_mae: 0.7115 - val_loss: 90.5041 - val_t1_output_loss: 1.4874 - val_nu11_output_loss: 25.0436 - val_dyn11_output_loss: 0.9092 - val_s1_output_loss: 0.0793 - val_t2_output_loss: 0.9697 - val_nu21_output_loss: 27.1394 - val_nu22_output_loss: 29.5119 - val_dyn21_output_loss: 1.0620 - val_dyn22_output_loss: 1.0602 - val_m2_12_output_loss: 1.0379 - val_m2_21_output_loss: 2.2036 - val_t1_output_mae: 1.0258 - val_nu11_output_mae: 2.5386 - val_dyn11_output_categorical_accuracy: 0.6343 - val_s1_output_mae: 0.2426 - val_t2_output_mae: 0.6678 - val_nu21_output_mae: 2.3989 - val_nu22_output_mae: 2.8441 - val_dyn21_output_categorical_accuracy: 0.4408 - val_dyn22_output_categorical_accuracy: 0.4435 - val_m2_12_output_mae: 0.6360 - val_m2_21_output_mae: 1.0060\n",
      "Epoch 34/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 82.9142 - t1_output_loss: 0.8274 - nu11_output_loss: 23.7187 - dyn11_output_loss: 0.9087 - s1_output_loss: 0.0787 - t2_output_loss: 0.8309 - nu21_output_loss: 26.6529 - nu22_output_loss: 24.8903 - dyn21_output_loss: 1.0598 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.4627 - m2_21_output_loss: 1.4225 - t1_output_mae: 0.6095 - nu11_output_mae: 1.9345 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2412 - t2_output_mae: 0.6086 - nu21_output_mae: 1.9955 - nu22_output_mae: 1.9458 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7472 - m2_21_output_mae: 0.7124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbc88040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbc88040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9a0b5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9a0b5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 53s 21ms/step - loss: 82.9502 - t1_output_loss: 0.8277 - nu11_output_loss: 23.7019 - dyn11_output_loss: 0.9087 - s1_output_loss: 0.0787 - t2_output_loss: 0.8306 - nu21_output_loss: 26.6435 - nu22_output_loss: 24.9525 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.4627 - m2_21_output_loss: 1.4224 - t1_output_mae: 0.6096 - nu11_output_mae: 1.9341 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2412 - t2_output_mae: 0.6085 - nu21_output_mae: 1.9954 - nu22_output_mae: 1.9467 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7472 - m2_21_output_mae: 0.7125 - val_loss: 86.1532 - val_t1_output_loss: 0.8281 - val_nu11_output_loss: 24.7444 - val_dyn11_output_loss: 0.9151 - val_s1_output_loss: 0.0806 - val_t2_output_loss: 0.7462 - val_nu21_output_loss: 25.9191 - val_nu22_output_loss: 28.7018 - val_dyn21_output_loss: 1.0636 - val_dyn22_output_loss: 1.0603 - val_m2_12_output_loss: 1.0140 - val_m2_21_output_loss: 1.0800 - val_t1_output_mae: 0.6334 - val_nu11_output_mae: 2.3521 - val_dyn11_output_categorical_accuracy: 0.6302 - val_s1_output_mae: 0.2447 - val_t2_output_mae: 0.5596 - val_nu21_output_mae: 2.3643 - val_nu22_output_mae: 2.6187 - val_dyn21_output_categorical_accuracy: 0.4398 - val_dyn22_output_categorical_accuracy: 0.4437 - val_m2_12_output_mae: 0.6434 - val_m2_21_output_mae: 0.6113\n",
      "Epoch 35/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 83.5775 - t1_output_loss: 0.8230 - nu11_output_loss: 23.7069 - dyn11_output_loss: 0.9078 - s1_output_loss: 0.0786 - t2_output_loss: 0.8304 - nu21_output_loss: 26.8179 - nu22_output_loss: 25.4459 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.4498 - m2_21_output_loss: 1.3961 - t1_output_mae: 0.6072 - nu11_output_mae: 1.9263 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2411 - t2_output_mae: 0.6086 - nu21_output_mae: 2.0094 - nu22_output_mae: 1.9629 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7434 - m2_21_output_mae: 0.7048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca640040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca640040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8272e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d8272e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 25ms/step - loss: 83.5607 - t1_output_loss: 0.8229 - nu11_output_loss: 23.7006 - dyn11_output_loss: 0.9078 - s1_output_loss: 0.0786 - t2_output_loss: 0.8305 - nu21_output_loss: 26.8097 - nu22_output_loss: 25.4440 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.4495 - m2_21_output_loss: 1.3959 - t1_output_mae: 0.6072 - nu11_output_mae: 1.9263 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2411 - t2_output_mae: 0.6086 - nu21_output_mae: 2.0092 - nu22_output_mae: 1.9630 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7433 - m2_21_output_mae: 0.7047 - val_loss: 103.6798 - val_t1_output_loss: 0.8585 - val_nu11_output_loss: 35.9571 - val_dyn11_output_loss: 0.9133 - val_s1_output_loss: 0.0778 - val_t2_output_loss: 2.6361 - val_nu21_output_loss: 26.3847 - val_nu22_output_loss: 31.0485 - val_dyn21_output_loss: 1.0618 - val_dyn22_output_loss: 1.0590 - val_m2_12_output_loss: 2.5640 - val_m2_21_output_loss: 1.1190 - val_t1_output_mae: 0.6719 - val_nu11_output_mae: 4.2085 - val_dyn11_output_categorical_accuracy: 0.6337 - val_s1_output_mae: 0.2402 - val_t2_output_mae: 1.3150 - val_nu21_output_mae: 2.5269 - val_nu22_output_mae: 2.9530 - val_dyn21_output_categorical_accuracy: 0.4421 - val_dyn22_output_categorical_accuracy: 0.4467 - val_m2_12_output_mae: 0.8795 - val_m2_21_output_mae: 0.6177\n",
      "Epoch 36/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 82.6151 - t1_output_loss: 0.8260 - nu11_output_loss: 23.5398 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0785 - t2_output_loss: 0.8315 - nu21_output_loss: 26.6310 - nu22_output_loss: 24.8432 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.4292 - m2_21_output_loss: 1.4058 - t1_output_mae: 0.6082 - nu11_output_mae: 1.9216 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2407 - t2_output_mae: 0.6080 - nu21_output_mae: 1.9917 - nu22_output_mae: 1.9623 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7370 - m2_21_output_mae: 0.7092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c915be50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c915be50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46ca333160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46ca333160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 82.6875 - t1_output_loss: 0.8262 - nu11_output_loss: 23.5429 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0785 - t2_output_loss: 0.8315 - nu21_output_loss: 26.7083 - nu22_output_loss: 24.8349 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.4289 - m2_21_output_loss: 1.4062 - t1_output_mae: 0.6082 - nu11_output_mae: 1.9216 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2407 - t2_output_mae: 0.6080 - nu21_output_mae: 1.9924 - nu22_output_mae: 1.9620 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7369 - m2_21_output_mae: 0.7093 - val_loss: 85.8436 - val_t1_output_loss: 0.7943 - val_nu11_output_loss: 26.2356 - val_dyn11_output_loss: 0.9063 - val_s1_output_loss: 0.0892 - val_t2_output_loss: 0.8608 - val_nu21_output_loss: 24.8825 - val_nu22_output_loss: 27.6118 - val_dyn21_output_loss: 1.0611 - val_dyn22_output_loss: 1.0596 - val_m2_12_output_loss: 1.1052 - val_m2_21_output_loss: 1.2371 - val_t1_output_mae: 0.5874 - val_nu11_output_mae: 2.7321 - val_dyn11_output_categorical_accuracy: 0.6354 - val_s1_output_mae: 0.2527 - val_t2_output_mae: 0.5529 - val_nu21_output_mae: 1.8841 - val_nu22_output_mae: 2.5390 - val_dyn21_output_categorical_accuracy: 0.4432 - val_dyn22_output_categorical_accuracy: 0.4442 - val_m2_12_output_mae: 0.6606 - val_m2_21_output_mae: 0.6079\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 83.6578 - t1_output_loss: 0.8150 - nu11_output_loss: 24.6103 - dyn11_output_loss: 0.9073 - s1_output_loss: 0.0783 - t2_output_loss: 0.8251 - nu21_output_loss: 26.6937 - nu22_output_loss: 24.8024 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.4068 - m2_21_output_loss: 1.3973 - t1_output_mae: 0.6028 - nu11_output_mae: 1.9443 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2406 - t2_output_mae: 0.6049 - nu21_output_mae: 1.9825 - nu22_output_mae: 1.9564 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7328 - m2_21_output_mae: 0.7060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46db1345e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46db1345e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da511040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da511040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 83.6578 - t1_output_loss: 0.8150 - nu11_output_loss: 24.6103 - dyn11_output_loss: 0.9073 - s1_output_loss: 0.0783 - t2_output_loss: 0.8251 - nu21_output_loss: 26.6937 - nu22_output_loss: 24.8024 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.4068 - m2_21_output_loss: 1.3973 - t1_output_mae: 0.6028 - nu11_output_mae: 1.9443 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2406 - t2_output_mae: 0.6049 - nu21_output_mae: 1.9825 - nu22_output_mae: 1.9564 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7328 - m2_21_output_mae: 0.7060 - val_loss: 85.3505 - val_t1_output_loss: 0.7883 - val_nu11_output_loss: 27.3592 - val_dyn11_output_loss: 0.9060 - val_s1_output_loss: 0.0815 - val_t2_output_loss: 0.9376 - val_nu21_output_loss: 25.2835 - val_nu22_output_loss: 25.4335 - val_dyn21_output_loss: 1.0622 - val_dyn22_output_loss: 1.0600 - val_m2_12_output_loss: 1.3608 - val_m2_21_output_loss: 1.0778 - val_t1_output_mae: 0.5939 - val_nu11_output_mae: 2.9968 - val_dyn11_output_categorical_accuracy: 0.6338 - val_s1_output_mae: 0.2447 - val_t2_output_mae: 0.5701 - val_nu21_output_mae: 2.1421 - val_nu22_output_mae: 1.8010 - val_dyn21_output_categorical_accuracy: 0.4405 - val_dyn22_output_categorical_accuracy: 0.4436 - val_m2_12_output_mae: 0.7921 - val_m2_21_output_mae: 0.5749\n",
      "Epoch 38/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 82.2750 - t1_output_loss: 0.8206 - nu11_output_loss: 23.4684 - dyn11_output_loss: 0.9085 - s1_output_loss: 0.0784 - t2_output_loss: 0.8218 - nu21_output_loss: 26.6176 - nu22_output_loss: 24.6354 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.4216 - m2_21_output_loss: 1.3813 - t1_output_mae: 0.6057 - nu11_output_mae: 1.9292 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2406 - t2_output_mae: 0.6025 - nu21_output_mae: 1.9892 - nu22_output_mae: 1.9375 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7345 - m2_21_output_mae: 0.6975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca2c0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca2c0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46daa02430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46daa02430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 82.3346 - t1_output_loss: 0.8205 - nu11_output_loss: 23.4608 - dyn11_output_loss: 0.9084 - s1_output_loss: 0.0784 - t2_output_loss: 0.8216 - nu21_output_loss: 26.6113 - nu22_output_loss: 24.7093 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.4215 - m2_21_output_loss: 1.3812 - t1_output_mae: 0.6056 - nu11_output_mae: 1.9290 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2406 - t2_output_mae: 0.6024 - nu21_output_mae: 1.9892 - nu22_output_mae: 1.9387 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7345 - m2_21_output_mae: 0.6975 - val_loss: 86.3271 - val_t1_output_loss: 0.8483 - val_nu11_output_loss: 25.7077 - val_dyn11_output_loss: 0.9110 - val_s1_output_loss: 0.0789 - val_t2_output_loss: 1.3223 - val_nu21_output_loss: 24.7171 - val_nu22_output_loss: 26.6574 - val_dyn21_output_loss: 1.0633 - val_dyn22_output_loss: 1.0605 - val_m2_12_output_loss: 2.7717 - val_m2_21_output_loss: 1.1888 - val_t1_output_mae: 0.6015 - val_nu11_output_mae: 2.7521 - val_dyn11_output_categorical_accuracy: 0.6303 - val_s1_output_mae: 0.2428 - val_t2_output_mae: 0.9153 - val_nu21_output_mae: 2.0671 - val_nu22_output_mae: 2.4515 - val_dyn21_output_categorical_accuracy: 0.4403 - val_dyn22_output_categorical_accuracy: 0.4435 - val_m2_12_output_mae: 0.9172 - val_m2_21_output_mae: 0.6140\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 82.8822 - t1_output_loss: 0.8144 - nu11_output_loss: 23.4309 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0781 - t2_output_loss: 0.8202 - nu21_output_loss: 26.6857 - nu22_output_loss: 25.2559 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3990 - m2_21_output_loss: 1.3691 - t1_output_mae: 0.6029 - nu11_output_mae: 1.9254 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2401 - t2_output_mae: 0.6022 - nu21_output_mae: 1.9907 - nu22_output_mae: 1.9442 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7290 - m2_21_output_mae: 0.6957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d93c3040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d93c3040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a25f8ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a25f8ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 82.8822 - t1_output_loss: 0.8144 - nu11_output_loss: 23.4309 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0781 - t2_output_loss: 0.8202 - nu21_output_loss: 26.6857 - nu22_output_loss: 25.2559 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3990 - m2_21_output_loss: 1.3691 - t1_output_mae: 0.6029 - nu11_output_mae: 1.9254 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2401 - t2_output_mae: 0.6022 - nu21_output_mae: 1.9907 - nu22_output_mae: 1.9442 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7290 - m2_21_output_mae: 0.6957 - val_loss: 98.4107 - val_t1_output_loss: 0.7672 - val_nu11_output_loss: 37.1096 - val_dyn11_output_loss: 0.9065 - val_s1_output_loss: 0.0775 - val_t2_output_loss: 1.2924 - val_nu21_output_loss: 27.3890 - val_nu22_output_loss: 25.8645 - val_dyn21_output_loss: 1.0622 - val_dyn22_output_loss: 1.0592 - val_m2_12_output_loss: 1.0796 - val_m2_21_output_loss: 1.8030 - val_t1_output_mae: 0.5769 - val_nu11_output_mae: 4.3616 - val_dyn11_output_categorical_accuracy: 0.6335 - val_s1_output_mae: 0.2400 - val_t2_output_mae: 0.7217 - val_nu21_output_mae: 2.6575 - val_nu22_output_mae: 2.2053 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4466 - val_m2_12_output_mae: 0.6110 - val_m2_21_output_mae: 0.7037\n",
      "Epoch 40/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 81.9344 - t1_output_loss: 0.8211 - nu11_output_loss: 23.3660 - dyn11_output_loss: 0.9081 - s1_output_loss: 0.0783 - t2_output_loss: 0.8164 - nu21_output_loss: 26.5489 - nu22_output_loss: 24.4978 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.4052 - m2_21_output_loss: 1.3711 - t1_output_mae: 0.6054 - nu11_output_mae: 1.9078 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2403 - t2_output_mae: 0.6015 - nu21_output_mae: 1.9684 - nu22_output_mae: 1.9379 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7283 - m2_21_output_mae: 0.6933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d97bd0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d97bd0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9c55670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9c55670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 53s 21ms/step - loss: 82.0079 - t1_output_loss: 0.8211 - nu11_output_loss: 23.3711 - dyn11_output_loss: 0.9081 - s1_output_loss: 0.0783 - t2_output_loss: 0.8164 - nu21_output_loss: 26.6259 - nu22_output_loss: 24.4892 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.4050 - m2_21_output_loss: 1.3712 - t1_output_mae: 0.6054 - nu11_output_mae: 1.9078 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2403 - t2_output_mae: 0.6015 - nu21_output_mae: 1.9692 - nu22_output_mae: 1.9376 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7283 - m2_21_output_mae: 0.6933 - val_loss: 85.6363 - val_t1_output_loss: 0.9689 - val_nu11_output_loss: 24.6808 - val_dyn11_output_loss: 0.9107 - val_s1_output_loss: 0.0782 - val_t2_output_loss: 1.3908 - val_nu21_output_loss: 24.9117 - val_nu22_output_loss: 26.8465 - val_dyn21_output_loss: 1.0610 - val_dyn22_output_loss: 1.0592 - val_m2_12_output_loss: 1.1056 - val_m2_21_output_loss: 2.6228 - val_t1_output_mae: 0.7339 - val_nu11_output_mae: 2.0355 - val_dyn11_output_categorical_accuracy: 0.6352 - val_s1_output_mae: 0.2396 - val_t2_output_mae: 0.9231 - val_nu21_output_mae: 1.7916 - val_nu22_output_mae: 2.5038 - val_dyn21_output_categorical_accuracy: 0.4434 - val_dyn22_output_categorical_accuracy: 0.4447 - val_m2_12_output_mae: 0.6873 - val_m2_21_output_mae: 1.0650\n",
      "Epoch 41/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 83.3192 - t1_output_loss: 0.8085 - nu11_output_loss: 24.5326 - dyn11_output_loss: 0.9073 - s1_output_loss: 0.0781 - t2_output_loss: 0.8129 - nu21_output_loss: 26.7275 - nu22_output_loss: 24.5758 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3827 - m2_21_output_loss: 1.3721 - t1_output_mae: 0.6006 - nu11_output_mae: 1.9454 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2401 - t2_output_mae: 0.5994 - nu21_output_mae: 1.9876 - nu22_output_mae: 1.9523 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7241 - m2_21_output_mae: 0.6942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c98a63a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c98a63a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c98a6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c98a6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 83.3031 - t1_output_loss: 0.8085 - nu11_output_loss: 24.5323 - dyn11_output_loss: 0.9073 - s1_output_loss: 0.0781 - t2_output_loss: 0.8132 - nu21_output_loss: 26.7185 - nu22_output_loss: 24.5693 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3827 - m2_21_output_loss: 1.3717 - t1_output_mae: 0.6006 - nu11_output_mae: 1.9454 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2401 - t2_output_mae: 0.5995 - nu21_output_mae: 1.9873 - nu22_output_mae: 1.9522 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7241 - m2_21_output_mae: 0.6941 - val_loss: 82.9805 - val_t1_output_loss: 0.9327 - val_nu11_output_loss: 24.5182 - val_dyn11_output_loss: 0.9084 - val_s1_output_loss: 0.0786 - val_t2_output_loss: 1.0748 - val_nu21_output_loss: 24.0344 - val_nu22_output_loss: 26.8427 - val_dyn21_output_loss: 1.0623 - val_dyn22_output_loss: 1.0602 - val_m2_12_output_loss: 1.3134 - val_m2_21_output_loss: 1.1548 - val_t1_output_mae: 0.7254 - val_nu11_output_mae: 2.3462 - val_dyn11_output_categorical_accuracy: 0.6340 - val_s1_output_mae: 0.2410 - val_t2_output_mae: 0.8054 - val_nu21_output_mae: 1.8922 - val_nu22_output_mae: 2.5105 - val_dyn21_output_categorical_accuracy: 0.4400 - val_dyn22_output_categorical_accuracy: 0.4435 - val_m2_12_output_mae: 0.7694 - val_m2_21_output_mae: 0.6640\n",
      "Epoch 42/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 82.1113 - t1_output_loss: 0.8100 - nu11_output_loss: 23.3696 - dyn11_output_loss: 0.9081 - s1_output_loss: 0.0782 - t2_output_loss: 0.8124 - nu21_output_loss: 26.5506 - nu22_output_loss: 24.7151 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3921 - m2_21_output_loss: 1.3538 - t1_output_mae: 0.6015 - nu11_output_mae: 1.9216 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2401 - t2_output_mae: 0.5982 - nu21_output_mae: 1.9765 - nu22_output_mae: 1.9287 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7258 - m2_21_output_mae: 0.6897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d83cc430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d83cc430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d83cc040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d83cc040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 62s 25ms/step - loss: 82.1708 - t1_output_loss: 0.8099 - nu11_output_loss: 23.3583 - dyn11_output_loss: 0.9081 - s1_output_loss: 0.0782 - t2_output_loss: 0.8121 - nu21_output_loss: 26.5500 - nu22_output_loss: 24.7869 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3918 - m2_21_output_loss: 1.3540 - t1_output_mae: 0.6015 - nu11_output_mae: 1.9214 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2401 - t2_output_mae: 0.5981 - nu21_output_mae: 1.9766 - nu22_output_mae: 1.9298 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7257 - m2_21_output_mae: 0.6898 - val_loss: 106.7576 - val_t1_output_loss: 0.9794 - val_nu11_output_loss: 26.2549 - val_dyn11_output_loss: 0.9108 - val_s1_output_loss: 0.0779 - val_t2_output_loss: 1.0330 - val_nu21_output_loss: 23.9442 - val_nu22_output_loss: 49.1698 - val_dyn21_output_loss: 1.0632 - val_dyn22_output_loss: 1.0602 - val_m2_12_output_loss: 1.1351 - val_m2_21_output_loss: 1.1292 - val_t1_output_mae: 0.7552 - val_nu11_output_mae: 2.8276 - val_dyn11_output_categorical_accuracy: 0.6309 - val_s1_output_mae: 0.2407 - val_t2_output_mae: 0.7526 - val_nu21_output_mae: 1.8870 - val_nu22_output_mae: 4.2342 - val_dyn21_output_categorical_accuracy: 0.4408 - val_dyn22_output_categorical_accuracy: 0.4442 - val_m2_12_output_mae: 0.7202 - val_m2_21_output_mae: 0.6032\n",
      "Epoch 43/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 82.6626 - t1_output_loss: 0.8118 - nu11_output_loss: 23.5344 - dyn11_output_loss: 0.9075 - s1_output_loss: 0.0780 - t2_output_loss: 0.8125 - nu21_output_loss: 26.4345 - nu22_output_loss: 25.2345 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3784 - m2_21_output_loss: 1.3500 - t1_output_mae: 0.6011 - nu11_output_mae: 1.9227 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2400 - t2_output_mae: 0.5980 - nu21_output_mae: 1.9764 - nu22_output_mae: 1.9396 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7234 - m2_21_output_mae: 0.6902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a3286e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a3286e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3286d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3286d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 82.6426 - t1_output_loss: 0.8117 - nu11_output_loss: 23.5276 - dyn11_output_loss: 0.9075 - s1_output_loss: 0.0780 - t2_output_loss: 0.8125 - nu21_output_loss: 26.4273 - nu22_output_loss: 25.2290 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3781 - m2_21_output_loss: 1.3499 - t1_output_mae: 0.6011 - nu11_output_mae: 1.9225 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2400 - t2_output_mae: 0.5980 - nu21_output_mae: 1.9763 - nu22_output_mae: 1.9394 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7233 - m2_21_output_mae: 0.6902 - val_loss: 85.8932 - val_t1_output_loss: 0.8705 - val_nu11_output_loss: 28.4449 - val_dyn11_output_loss: 0.9076 - val_s1_output_loss: 0.0776 - val_t2_output_loss: 1.2687 - val_nu21_output_loss: 24.2591 - val_nu22_output_loss: 25.0577 - val_dyn21_output_loss: 1.0621 - val_dyn22_output_loss: 1.0592 - val_m2_12_output_loss: 1.6633 - val_m2_21_output_loss: 1.2225 - val_t1_output_mae: 0.6739 - val_nu11_output_mae: 3.1273 - val_dyn11_output_categorical_accuracy: 0.6334 - val_s1_output_mae: 0.2400 - val_t2_output_mae: 0.6918 - val_nu21_output_mae: 2.1195 - val_nu22_output_mae: 1.9680 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4464 - val_m2_12_output_mae: 0.7019 - val_m2_21_output_mae: 0.6059\n",
      "Epoch 44/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 81.2962 - t1_output_loss: 0.8144 - nu11_output_loss: 23.4347 - dyn11_output_loss: 0.9079 - s1_output_loss: 0.0782 - t2_output_loss: 0.8110 - nu21_output_loss: 26.2216 - nu22_output_loss: 24.1897 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.3678 - m2_21_output_loss: 1.3495 - t1_output_mae: 0.6018 - nu11_output_mae: 1.9075 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2400 - t2_output_mae: 0.5976 - nu21_output_mae: 1.9581 - nu22_output_mae: 1.9237 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7168 - m2_21_output_mae: 0.6884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d9f35040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d9f35040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2bd4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2bd4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 25ms/step - loss: 81.3487 - t1_output_loss: 0.8145 - nu11_output_loss: 23.4314 - dyn11_output_loss: 0.9079 - s1_output_loss: 0.0782 - t2_output_loss: 0.8111 - nu21_output_loss: 26.2905 - nu22_output_loss: 24.1765 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.3677 - m2_21_output_loss: 1.3495 - t1_output_mae: 0.6018 - nu11_output_mae: 1.9072 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2400 - t2_output_mae: 0.5976 - nu21_output_mae: 1.9586 - nu22_output_mae: 1.9231 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7167 - m2_21_output_mae: 0.6884 - val_loss: 81.1749 - val_t1_output_loss: 0.7756 - val_nu11_output_loss: 24.8885 - val_dyn11_output_loss: 0.9063 - val_s1_output_loss: 0.0774 - val_t2_output_loss: 0.8631 - val_nu21_output_loss: 24.4260 - val_nu22_output_loss: 24.7239 - val_dyn21_output_loss: 1.0609 - val_dyn22_output_loss: 1.0594 - val_m2_12_output_loss: 1.1523 - val_m2_21_output_loss: 1.2415 - val_t1_output_mae: 0.5878 - val_nu11_output_mae: 2.1054 - val_dyn11_output_categorical_accuracy: 0.6349 - val_s1_output_mae: 0.2392 - val_t2_output_mae: 0.6590 - val_nu21_output_mae: 1.8692 - val_nu22_output_mae: 2.0682 - val_dyn21_output_categorical_accuracy: 0.4433 - val_dyn22_output_categorical_accuracy: 0.4446 - val_m2_12_output_mae: 0.7061 - val_m2_21_output_mae: 0.6860\n",
      "Epoch 45/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 82.7792 - t1_output_loss: 0.8012 - nu11_output_loss: 24.3628 - dyn11_output_loss: 0.9072 - s1_output_loss: 0.0780 - t2_output_loss: 0.8041 - nu21_output_loss: 26.7416 - nu22_output_loss: 24.2631 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3545 - m2_21_output_loss: 1.3453 - t1_output_mae: 0.5969 - nu11_output_mae: 1.9397 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2398 - t2_output_mae: 0.5938 - nu21_output_mae: 1.9662 - nu22_output_mae: 1.9190 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7144 - m2_21_output_mae: 0.6879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2bd4d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2bd4d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2bd4dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2bd4dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 82.7483 - t1_output_loss: 0.8017 - nu11_output_loss: 24.3587 - dyn11_output_loss: 0.9072 - s1_output_loss: 0.0779 - t2_output_loss: 0.8043 - nu21_output_loss: 26.7270 - nu22_output_loss: 24.2490 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3548 - m2_21_output_loss: 1.3461 - t1_output_mae: 0.5970 - nu11_output_mae: 1.9395 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2398 - t2_output_mae: 0.5940 - nu21_output_mae: 1.9659 - nu22_output_mae: 1.9187 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7144 - m2_21_output_mae: 0.6881 - val_loss: 87.0081 - val_t1_output_loss: 1.0626 - val_nu11_output_loss: 24.4792 - val_dyn11_output_loss: 0.9074 - val_s1_output_loss: 0.0789 - val_t2_output_loss: 0.8401 - val_nu21_output_loss: 25.0102 - val_nu22_output_loss: 29.4023 - val_dyn21_output_loss: 1.0625 - val_dyn22_output_loss: 1.0606 - val_m2_12_output_loss: 2.0470 - val_m2_21_output_loss: 1.0574 - val_t1_output_mae: 0.7917 - val_nu11_output_mae: 1.7892 - val_dyn11_output_categorical_accuracy: 0.6338 - val_s1_output_mae: 0.2415 - val_t2_output_mae: 0.6531 - val_nu21_output_mae: 2.2133 - val_nu22_output_mae: 2.9181 - val_dyn21_output_categorical_accuracy: 0.4401 - val_dyn22_output_categorical_accuracy: 0.4427 - val_m2_12_output_mae: 1.0176 - val_m2_21_output_mae: 0.5879\n",
      "Epoch 46/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 81.3126 - t1_output_loss: 0.8072 - nu11_output_loss: 23.4043 - dyn11_output_loss: 0.9080 - s1_output_loss: 0.0781 - t2_output_loss: 0.8032 - nu21_output_loss: 26.1509 - nu22_output_loss: 24.3380 - dyn21_output_loss: 1.0598 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3637 - m2_21_output_loss: 1.3373 - t1_output_mae: 0.5991 - nu11_output_mae: 1.9184 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2398 - t2_output_mae: 0.5933 - nu21_output_mae: 1.9598 - nu22_output_mae: 1.9128 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7174 - m2_21_output_mae: 0.6848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a3391040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a3391040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dab1b430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dab1b430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 81.3445 - t1_output_loss: 0.8073 - nu11_output_loss: 23.3872 - dyn11_output_loss: 0.9081 - s1_output_loss: 0.0781 - t2_output_loss: 0.8031 - nu21_output_loss: 26.1423 - nu22_output_loss: 24.3957 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3639 - m2_21_output_loss: 1.3371 - t1_output_mae: 0.5992 - nu11_output_mae: 1.9180 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2398 - t2_output_mae: 0.5932 - nu21_output_mae: 1.9595 - nu22_output_mae: 1.9137 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7174 - m2_21_output_mae: 0.6849 - val_loss: 80.8259 - val_t1_output_loss: 0.8093 - val_nu11_output_loss: 23.7290 - val_dyn11_output_loss: 0.9109 - val_s1_output_loss: 0.0800 - val_t2_output_loss: 0.9172 - val_nu21_output_loss: 24.3136 - val_nu22_output_loss: 25.0294 - val_dyn21_output_loss: 1.0631 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.0097 - val_m2_21_output_loss: 1.9038 - val_t1_output_mae: 0.5843 - val_nu11_output_mae: 2.3619 - val_dyn11_output_categorical_accuracy: 0.6310 - val_s1_output_mae: 0.2437 - val_t2_output_mae: 0.5691 - val_nu21_output_mae: 1.9237 - val_nu22_output_mae: 2.1339 - val_dyn21_output_categorical_accuracy: 0.4408 - val_dyn22_output_categorical_accuracy: 0.4448 - val_m2_12_output_mae: 0.5897 - val_m2_21_output_mae: 0.7242\n",
      "Epoch 47/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 81.9064 - t1_output_loss: 0.8051 - nu11_output_loss: 23.1502 - dyn11_output_loss: 0.9073 - s1_output_loss: 0.0778 - t2_output_loss: 0.8047 - nu21_output_loss: 26.5295 - nu22_output_loss: 24.8271 - dyn21_output_loss: 1.0600 - dyn22_output_loss: 1.0611 - m2_12_output_loss: 1.3480 - m2_21_output_loss: 1.3358 - t1_output_mae: 0.5968 - nu11_output_mae: 1.9105 - dyn11_output_categorical_accuracy: 0.6309 - s1_output_mae: 0.2394 - t2_output_mae: 0.5936 - nu21_output_mae: 1.9636 - nu22_output_mae: 1.9275 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7132 - m2_21_output_mae: 0.6843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2ace1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2ace1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2ace040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2ace040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 62s 25ms/step - loss: 81.8678 - t1_output_loss: 0.8048 - nu11_output_loss: 23.1540 - dyn11_output_loss: 0.9072 - s1_output_loss: 0.0778 - t2_output_loss: 0.8047 - nu21_output_loss: 26.5033 - nu22_output_loss: 24.8117 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3479 - m2_21_output_loss: 1.3357 - t1_output_mae: 0.5967 - nu11_output_mae: 1.9109 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2394 - t2_output_mae: 0.5936 - nu21_output_mae: 1.9628 - nu22_output_mae: 1.9275 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7131 - m2_21_output_mae: 0.6843 - val_loss: 129.0345 - val_t1_output_loss: 0.7748 - val_nu11_output_loss: 34.9480 - val_dyn11_output_loss: 0.9063 - val_s1_output_loss: 0.0767 - val_t2_output_loss: 0.9494 - val_nu21_output_loss: 24.2649 - val_nu22_output_loss: 62.7154 - val_dyn21_output_loss: 1.0621 - val_dyn22_output_loss: 1.0592 - val_m2_12_output_loss: 1.2005 - val_m2_21_output_loss: 1.0771 - val_t1_output_mae: 0.6026 - val_nu11_output_mae: 4.0499 - val_dyn11_output_categorical_accuracy: 0.6339 - val_s1_output_mae: 0.2387 - val_t2_output_mae: 0.6072 - val_nu21_output_mae: 2.0785 - val_nu22_output_mae: 5.4334 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4464 - val_m2_12_output_mae: 0.7412 - val_m2_21_output_mae: 0.6244\n",
      "Epoch 48/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 81.0606 - t1_output_loss: 0.8080 - nu11_output_loss: 23.1357 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0782 - t2_output_loss: 0.8066 - nu21_output_loss: 25.9819 - nu22_output_loss: 24.5462 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.3451 - m2_21_output_loss: 1.3298 - t1_output_mae: 0.5985 - nu11_output_mae: 1.8985 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2400 - t2_output_mae: 0.5947 - nu21_output_mae: 1.9441 - nu22_output_mae: 1.9252 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7100 - m2_21_output_mae: 0.6838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469a966040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469a966040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8c53430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8c53430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 81.1353 - t1_output_loss: 0.8081 - nu11_output_loss: 23.1419 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0782 - t2_output_loss: 0.8067 - nu21_output_loss: 26.0584 - nu22_output_loss: 24.5378 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.3450 - m2_21_output_loss: 1.3301 - t1_output_mae: 0.5985 - nu11_output_mae: 1.8986 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2400 - t2_output_mae: 0.5947 - nu21_output_mae: 1.9450 - nu22_output_mae: 1.9249 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7099 - m2_21_output_mae: 0.6839 - val_loss: 83.2361 - val_t1_output_loss: 0.8120 - val_nu11_output_loss: 24.7147 - val_dyn11_output_loss: 0.9050 - val_s1_output_loss: 0.0826 - val_t2_output_loss: 1.7675 - val_nu21_output_loss: 25.0880 - val_nu22_output_loss: 24.8028 - val_dyn21_output_loss: 1.0610 - val_dyn22_output_loss: 1.0594 - val_m2_12_output_loss: 1.5559 - val_m2_21_output_loss: 1.3871 - val_t1_output_mae: 0.6363 - val_nu11_output_mae: 2.1679 - val_dyn11_output_categorical_accuracy: 0.6352 - val_s1_output_mae: 0.2447 - val_t2_output_mae: 1.0370 - val_nu21_output_mae: 2.3164 - val_nu22_output_mae: 1.8252 - val_dyn21_output_categorical_accuracy: 0.4426 - val_dyn22_output_categorical_accuracy: 0.4446 - val_m2_12_output_mae: 0.8412 - val_m2_21_output_mae: 0.6343\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 81.9530 - t1_output_loss: 0.7980 - nu11_output_loss: 24.2268 - dyn11_output_loss: 0.9071 - s1_output_loss: 0.0778 - t2_output_loss: 0.7968 - nu21_output_loss: 26.2215 - nu22_output_loss: 24.1482 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3280 - m2_21_output_loss: 1.3273 - t1_output_mae: 0.5954 - nu11_output_mae: 1.9366 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2396 - t2_output_mae: 0.5898 - nu21_output_mae: 1.9556 - nu22_output_mae: 1.9105 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7053 - m2_21_output_mae: 0.6833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cb2241f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cb2241f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3756ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3756ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 53s 21ms/step - loss: 81.9530 - t1_output_loss: 0.7980 - nu11_output_loss: 24.2268 - dyn11_output_loss: 0.9071 - s1_output_loss: 0.0778 - t2_output_loss: 0.7968 - nu21_output_loss: 26.2215 - nu22_output_loss: 24.1482 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3280 - m2_21_output_loss: 1.3273 - t1_output_mae: 0.5954 - nu11_output_mae: 1.9366 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2396 - t2_output_mae: 0.5898 - nu21_output_mae: 1.9556 - nu22_output_mae: 1.9105 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7053 - m2_21_output_mae: 0.6833 - val_loss: 86.8688 - val_t1_output_loss: 0.7628 - val_nu11_output_loss: 24.6930 - val_dyn11_output_loss: 0.9059 - val_s1_output_loss: 0.0789 - val_t2_output_loss: 1.0637 - val_nu21_output_loss: 25.8107 - val_nu22_output_loss: 27.0122 - val_dyn21_output_loss: 1.0626 - val_dyn22_output_loss: 1.0605 - val_m2_12_output_loss: 1.1672 - val_m2_21_output_loss: 3.2513 - val_t1_output_mae: 0.5925 - val_nu11_output_mae: 2.3314 - val_dyn11_output_categorical_accuracy: 0.6338 - val_s1_output_mae: 0.2402 - val_t2_output_mae: 0.7696 - val_nu21_output_mae: 2.2385 - val_nu22_output_mae: 2.5657 - val_dyn21_output_categorical_accuracy: 0.4402 - val_dyn22_output_categorical_accuracy: 0.4428 - val_m2_12_output_mae: 0.6988 - val_m2_21_output_mae: 1.1107\n",
      "Epoch 50/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 80.8679 - t1_output_loss: 0.8044 - nu11_output_loss: 23.2671 - dyn11_output_loss: 0.9078 - s1_output_loss: 0.0779 - t2_output_loss: 0.7932 - nu21_output_loss: 26.0457 - nu22_output_loss: 24.1912 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3423 - m2_21_output_loss: 1.3167 - t1_output_mae: 0.5972 - nu11_output_mae: 1.9135 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2396 - t2_output_mae: 0.5881 - nu21_output_mae: 1.9442 - nu22_output_mae: 1.8982 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7089 - m2_21_output_mae: 0.6800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da1790d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da1790d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f47009215e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f47009215e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 80.9249 - t1_output_loss: 0.8043 - nu11_output_loss: 23.2552 - dyn11_output_loss: 0.9078 - s1_output_loss: 0.0779 - t2_output_loss: 0.7929 - nu21_output_loss: 26.0495 - nu22_output_loss: 24.2566 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3422 - m2_21_output_loss: 1.3170 - t1_output_mae: 0.5971 - nu11_output_mae: 1.9132 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2396 - t2_output_mae: 0.5880 - nu21_output_mae: 1.9445 - nu22_output_mae: 1.8992 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7089 - m2_21_output_mae: 0.6801 - val_loss: 81.1382 - val_t1_output_loss: 0.7712 - val_nu11_output_loss: 22.9153 - val_dyn11_output_loss: 0.9091 - val_s1_output_loss: 0.0780 - val_t2_output_loss: 0.7413 - val_nu21_output_loss: 25.4359 - val_nu22_output_loss: 25.7580 - val_dyn21_output_loss: 1.0629 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.1595 - val_m2_21_output_loss: 1.2471 - val_t1_output_mae: 0.5689 - val_nu11_output_mae: 1.9784 - val_dyn11_output_categorical_accuracy: 0.6313 - val_s1_output_mae: 0.2413 - val_t2_output_mae: 0.5881 - val_nu21_output_mae: 2.1993 - val_nu22_output_mae: 2.3170 - val_dyn21_output_categorical_accuracy: 0.4413 - val_dyn22_output_categorical_accuracy: 0.4450 - val_m2_12_output_mae: 0.7259 - val_m2_21_output_mae: 0.6843\n",
      "Epoch 51/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 81.5285 - t1_output_loss: 0.8003 - nu11_output_loss: 23.1442 - dyn11_output_loss: 0.9067 - s1_output_loss: 0.0778 - t2_output_loss: 0.7948 - nu21_output_loss: 26.2577 - nu22_output_loss: 24.7726 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3432 - m2_21_output_loss: 1.3103 - t1_output_mae: 0.5952 - nu11_output_mae: 1.9038 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2393 - t2_output_mae: 0.5890 - nu21_output_mae: 1.9608 - nu22_output_mae: 1.9011 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7088 - m2_21_output_mae: 0.6795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbb65f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbb65f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db66b160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db66b160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 62s 25ms/step - loss: 81.5104 - t1_output_loss: 0.8002 - nu11_output_loss: 23.1386 - dyn11_output_loss: 0.9067 - s1_output_loss: 0.0777 - t2_output_loss: 0.7948 - nu21_output_loss: 26.2505 - nu22_output_loss: 24.7679 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3429 - m2_21_output_loss: 1.3101 - t1_output_mae: 0.5952 - nu11_output_mae: 1.9037 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2393 - t2_output_mae: 0.5890 - nu21_output_mae: 1.9607 - nu22_output_mae: 1.9009 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7087 - m2_21_output_mae: 0.6795 - val_loss: 87.5610 - val_t1_output_loss: 0.8647 - val_nu11_output_loss: 28.0078 - val_dyn11_output_loss: 0.9069 - val_s1_output_loss: 0.0786 - val_t2_output_loss: 0.9728 - val_nu21_output_loss: 24.2098 - val_nu22_output_loss: 27.0867 - val_dyn21_output_loss: 1.0620 - val_dyn22_output_loss: 1.0591 - val_m2_12_output_loss: 0.9913 - val_m2_21_output_loss: 2.3212 - val_t1_output_mae: 0.6685 - val_nu11_output_mae: 3.0710 - val_dyn11_output_categorical_accuracy: 0.6332 - val_s1_output_mae: 0.2399 - val_t2_output_mae: 0.5753 - val_nu21_output_mae: 2.1918 - val_nu22_output_mae: 2.5232 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4462 - val_m2_12_output_mae: 0.6361 - val_m2_21_output_mae: 0.8093\n",
      "Epoch 52/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 80.2964 - t1_output_loss: 0.8019 - nu11_output_loss: 23.1813 - dyn11_output_loss: 0.9074 - s1_output_loss: 0.0777 - t2_output_loss: 0.7973 - nu21_output_loss: 25.7785 - nu22_output_loss: 23.9624 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.3383 - m2_21_output_loss: 1.3301 - t1_output_mae: 0.5964 - nu11_output_mae: 1.9006 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2389 - t2_output_mae: 0.5906 - nu21_output_mae: 1.9275 - nu22_output_mae: 1.9061 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4437 - m2_12_output_mae: 0.7057 - m2_21_output_mae: 0.6851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbfad040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46dbfad040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469dc12ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469dc12ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 80.3270 - t1_output_loss: 0.8020 - nu11_output_loss: 23.1722 - dyn11_output_loss: 0.9073 - s1_output_loss: 0.0777 - t2_output_loss: 0.7974 - nu21_output_loss: 25.8403 - nu22_output_loss: 23.9405 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.3382 - m2_21_output_loss: 1.3298 - t1_output_mae: 0.5963 - nu11_output_mae: 1.8999 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2389 - t2_output_mae: 0.5906 - nu21_output_mae: 1.9278 - nu22_output_mae: 1.9054 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.7057 - m2_21_output_mae: 0.6850 - val_loss: 85.8654 - val_t1_output_loss: 0.8852 - val_nu11_output_loss: 24.8816 - val_dyn11_output_loss: 0.9100 - val_s1_output_loss: 0.0794 - val_t2_output_loss: 1.1956 - val_nu21_output_loss: 24.0988 - val_nu22_output_loss: 26.2442 - val_dyn21_output_loss: 1.0609 - val_dyn22_output_loss: 1.0594 - val_m2_12_output_loss: 2.5029 - val_m2_21_output_loss: 2.9474 - val_t1_output_mae: 0.6653 - val_nu11_output_mae: 2.1307 - val_dyn11_output_categorical_accuracy: 0.6353 - val_s1_output_mae: 0.2402 - val_t2_output_mae: 0.8345 - val_nu21_output_mae: 1.7736 - val_nu22_output_mae: 2.4122 - val_dyn21_output_categorical_accuracy: 0.4430 - val_dyn22_output_categorical_accuracy: 0.4444 - val_m2_12_output_mae: 1.1280 - val_m2_21_output_mae: 0.9871\n",
      "Epoch 53/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 81.7332 - t1_output_loss: 0.7915 - nu11_output_loss: 24.1508 - dyn11_output_loss: 0.9065 - s1_output_loss: 0.0776 - t2_output_loss: 0.7929 - nu21_output_loss: 26.2144 - nu22_output_loss: 24.0545 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3127 - m2_21_output_loss: 1.3107 - t1_output_mae: 0.5921 - nu11_output_mae: 1.9253 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2391 - t2_output_mae: 0.5879 - nu21_output_mae: 1.9393 - nu22_output_mae: 1.9052 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7004 - m2_21_output_mae: 0.6777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469dc12b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469dc12b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4700e4c8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4700e4c8b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 81.7000 - t1_output_loss: 0.7919 - nu11_output_loss: 24.1477 - dyn11_output_loss: 0.9065 - s1_output_loss: 0.0776 - t2_output_loss: 0.7932 - nu21_output_loss: 26.1987 - nu22_output_loss: 24.0386 - dyn21_output_loss: 1.0603 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3129 - m2_21_output_loss: 1.3114 - t1_output_mae: 0.5922 - nu11_output_mae: 1.9253 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2391 - t2_output_mae: 0.5880 - nu21_output_mae: 1.9389 - nu22_output_mae: 1.9046 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.7005 - m2_21_output_mae: 0.6778 - val_loss: 81.0688 - val_t1_output_loss: 0.9017 - val_nu11_output_loss: 24.2257 - val_dyn11_output_loss: 0.9081 - val_s1_output_loss: 0.0773 - val_t2_output_loss: 1.1108 - val_nu21_output_loss: 23.4537 - val_nu22_output_loss: 24.4250 - val_dyn21_output_loss: 1.0629 - val_dyn22_output_loss: 1.0606 - val_m2_12_output_loss: 2.8159 - val_m2_21_output_loss: 1.0272 - val_t1_output_mae: 0.6912 - val_nu11_output_mae: 2.2381 - val_dyn11_output_categorical_accuracy: 0.6337 - val_s1_output_mae: 0.2398 - val_t2_output_mae: 0.7989 - val_nu21_output_mae: 1.8640 - val_nu22_output_mae: 2.0242 - val_dyn21_output_categorical_accuracy: 0.4396 - val_dyn22_output_categorical_accuracy: 0.4427 - val_m2_12_output_mae: 1.1748 - val_m2_21_output_mae: 0.5932\n",
      "Epoch 54/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 80.5713 - t1_output_loss: 0.7977 - nu11_output_loss: 23.2450 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0777 - t2_output_loss: 0.7877 - nu21_output_loss: 25.9435 - nu22_output_loss: 24.0565 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3255 - m2_21_output_loss: 1.3085 - t1_output_mae: 0.5936 - nu11_output_mae: 1.9033 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2390 - t2_output_mae: 0.5850 - nu21_output_mae: 1.9380 - nu22_output_mae: 1.9013 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7026 - m2_21_output_mae: 0.6761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da3e50d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da3e50d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da0e3040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da0e3040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 59s 23ms/step - loss: 80.6266 - t1_output_loss: 0.7975 - nu11_output_loss: 23.2333 - dyn11_output_loss: 0.9077 - s1_output_loss: 0.0777 - t2_output_loss: 0.7874 - nu21_output_loss: 25.9473 - nu22_output_loss: 24.1204 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3251 - m2_21_output_loss: 1.3086 - t1_output_mae: 0.5935 - nu11_output_mae: 1.9031 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2390 - t2_output_mae: 0.5849 - nu21_output_mae: 1.9384 - nu22_output_mae: 1.9021 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.7025 - m2_21_output_mae: 0.6761 - val_loss: 89.9622 - val_t1_output_loss: 0.8016 - val_nu11_output_loss: 23.5589 - val_dyn11_output_loss: 0.9089 - val_s1_output_loss: 0.0774 - val_t2_output_loss: 1.2603 - val_nu21_output_loss: 23.7699 - val_nu22_output_loss: 26.0094 - val_dyn21_output_loss: 1.0627 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 0.9224 - val_m2_21_output_loss: 10.5310 - val_t1_output_mae: 0.5841 - val_nu11_output_mae: 2.3078 - val_dyn11_output_categorical_accuracy: 0.6312 - val_s1_output_mae: 0.2398 - val_t2_output_mae: 0.8602 - val_nu21_output_mae: 1.9211 - val_nu22_output_mae: 2.2596 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4451 - val_m2_12_output_mae: 0.5716 - val_m2_21_output_mae: 2.2540\n",
      "Epoch 55/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 80.9399 - t1_output_loss: 0.7922 - nu11_output_loss: 23.0789 - dyn11_output_loss: 0.9064 - s1_output_loss: 0.0776 - t2_output_loss: 0.7901 - nu21_output_loss: 26.0208 - nu22_output_loss: 24.5282 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3196 - m2_21_output_loss: 1.3050 - t1_output_mae: 0.5918 - nu11_output_mae: 1.9043 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2391 - t2_output_mae: 0.5854 - nu21_output_mae: 1.9468 - nu22_output_mae: 1.8975 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 0.7015 - m2_21_output_mae: 0.6745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da0e3160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da0e3160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da0e30d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da0e30d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 80.8994 - t1_output_loss: 0.7920 - nu11_output_loss: 23.0648 - dyn11_output_loss: 0.9063 - s1_output_loss: 0.0775 - t2_output_loss: 0.7901 - nu21_output_loss: 26.0042 - nu22_output_loss: 24.5195 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.3192 - m2_21_output_loss: 1.3047 - t1_output_mae: 0.5918 - nu11_output_mae: 1.9039 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2390 - t2_output_mae: 0.5854 - nu21_output_mae: 1.9463 - nu22_output_mae: 1.8975 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.7014 - m2_21_output_mae: 0.6743 - val_loss: 89.8598 - val_t1_output_loss: 0.7806 - val_nu11_output_loss: 27.5965 - val_dyn11_output_loss: 0.9057 - val_s1_output_loss: 0.0768 - val_t2_output_loss: 0.6905 - val_nu21_output_loss: 25.1995 - val_nu22_output_loss: 30.0382 - val_dyn21_output_loss: 1.0618 - val_dyn22_output_loss: 1.0590 - val_m2_12_output_loss: 1.3797 - val_m2_21_output_loss: 1.0714 - val_t1_output_mae: 0.5845 - val_nu11_output_mae: 2.9771 - val_dyn11_output_categorical_accuracy: 0.6333 - val_s1_output_mae: 0.2369 - val_t2_output_mae: 0.5380 - val_nu21_output_mae: 2.2443 - val_nu22_output_mae: 2.7425 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4464 - val_m2_12_output_mae: 0.7565 - val_m2_21_output_mae: 0.6212\n",
      "Epoch 56/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 80.1041 - t1_output_loss: 0.7988 - nu11_output_loss: 22.8355 - dyn11_output_loss: 0.9070 - s1_output_loss: 0.0776 - t2_output_loss: 0.7934 - nu21_output_loss: 25.8601 - nu22_output_loss: 24.1220 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2973 - m2_21_output_loss: 1.2909 - t1_output_mae: 0.5945 - nu11_output_mae: 1.8773 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2389 - t2_output_mae: 0.5876 - nu21_output_mae: 1.9370 - nu22_output_mae: 1.9029 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6952 - m2_21_output_mae: 0.6715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca33f040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca33f040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a06f9ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a06f9ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 65s 26ms/step - loss: 80.1567 - t1_output_loss: 0.7990 - nu11_output_loss: 22.8310 - dyn11_output_loss: 0.9070 - s1_output_loss: 0.0776 - t2_output_loss: 0.7936 - nu21_output_loss: 25.9299 - nu22_output_loss: 24.1087 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2976 - m2_21_output_loss: 1.2908 - t1_output_mae: 0.5945 - nu11_output_mae: 1.8769 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2389 - t2_output_mae: 0.5876 - nu21_output_mae: 1.9376 - nu22_output_mae: 1.9026 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6952 - m2_21_output_mae: 0.6715 - val_loss: 81.8116 - val_t1_output_loss: 0.8459 - val_nu11_output_loss: 24.4545 - val_dyn11_output_loss: 0.9043 - val_s1_output_loss: 0.0804 - val_t2_output_loss: 1.0388 - val_nu21_output_loss: 24.4525 - val_nu22_output_loss: 25.4191 - val_dyn21_output_loss: 1.0613 - val_dyn22_output_loss: 1.0595 - val_m2_12_output_loss: 1.0323 - val_m2_21_output_loss: 1.4630 - val_t1_output_mae: 0.5807 - val_nu11_output_mae: 1.9306 - val_dyn11_output_categorical_accuracy: 0.6352 - val_s1_output_mae: 0.2415 - val_t2_output_mae: 0.7552 - val_nu21_output_mae: 1.9859 - val_nu22_output_mae: 2.3808 - val_dyn21_output_categorical_accuracy: 0.4426 - val_dyn22_output_categorical_accuracy: 0.4445 - val_m2_12_output_mae: 0.6608 - val_m2_21_output_mae: 0.7132\n",
      "Epoch 57/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 80.9151 - t1_output_loss: 0.7868 - nu11_output_loss: 23.9028 - dyn11_output_loss: 0.9060 - s1_output_loss: 0.0775 - t2_output_loss: 0.7849 - nu21_output_loss: 26.0008 - nu22_output_loss: 23.7363 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3093 - m2_21_output_loss: 1.2890 - t1_output_mae: 0.5896 - nu11_output_mae: 1.9196 - dyn11_output_categorical_accuracy: 0.6312 - s1_output_mae: 0.2389 - t2_output_mae: 0.5839 - nu21_output_mae: 1.9330 - nu22_output_mae: 1.8964 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6983 - m2_21_output_mae: 0.6714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c8b230d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c8b230d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8b23040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8b23040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 55s 22ms/step - loss: 80.8928 - t1_output_loss: 0.7875 - nu11_output_loss: 23.9233 - dyn11_output_loss: 0.9061 - s1_output_loss: 0.0775 - t2_output_loss: 0.7852 - nu21_output_loss: 25.9788 - nu22_output_loss: 23.7137 - dyn21_output_loss: 1.0604 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.3097 - m2_21_output_loss: 1.2895 - t1_output_mae: 0.5898 - nu11_output_mae: 1.9206 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2389 - t2_output_mae: 0.5840 - nu21_output_mae: 1.9323 - nu22_output_mae: 1.8957 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6984 - m2_21_output_mae: 0.6715 - val_loss: 81.9292 - val_t1_output_loss: 0.9188 - val_nu11_output_loss: 24.2356 - val_dyn11_output_loss: 0.9072 - val_s1_output_loss: 0.0771 - val_t2_output_loss: 1.1377 - val_nu21_output_loss: 23.4525 - val_nu22_output_loss: 25.1044 - val_dyn21_output_loss: 1.0632 - val_dyn22_output_loss: 1.0608 - val_m2_12_output_loss: 1.0907 - val_m2_21_output_loss: 2.8811 - val_t1_output_mae: 0.7079 - val_nu11_output_mae: 2.2727 - val_dyn11_output_categorical_accuracy: 0.6335 - val_s1_output_mae: 0.2396 - val_t2_output_mae: 0.6873 - val_nu21_output_mae: 1.8933 - val_nu22_output_mae: 2.1741 - val_dyn21_output_categorical_accuracy: 0.4392 - val_dyn22_output_categorical_accuracy: 0.4424 - val_m2_12_output_mae: 0.6440 - val_m2_21_output_mae: 1.0723\n",
      "Epoch 58/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 80.1265 - t1_output_loss: 0.7911 - nu11_output_loss: 23.0478 - dyn11_output_loss: 0.9070 - s1_output_loss: 0.0776 - t2_output_loss: 0.7850 - nu21_output_loss: 25.8889 - nu22_output_loss: 23.9034 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3176 - m2_21_output_loss: 1.2863 - t1_output_mae: 0.5907 - nu11_output_mae: 1.8980 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2390 - t2_output_mae: 0.5835 - nu21_output_mae: 1.9259 - nu22_output_mae: 1.8800 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.7000 - m2_21_output_mae: 0.6698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a362e040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a362e040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0865ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0865ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 80.1852 - t1_output_loss: 0.7910 - nu11_output_loss: 23.0406 - dyn11_output_loss: 0.9070 - s1_output_loss: 0.0776 - t2_output_loss: 0.7849 - nu21_output_loss: 25.8834 - nu22_output_loss: 23.9752 - dyn21_output_loss: 1.0597 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.3176 - m2_21_output_loss: 1.2862 - t1_output_mae: 0.5906 - nu11_output_mae: 1.8978 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2390 - t2_output_mae: 0.5834 - nu21_output_mae: 1.9258 - nu22_output_mae: 1.8811 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6999 - m2_21_output_mae: 0.6698 - val_loss: 81.5701 - val_t1_output_loss: 0.7643 - val_nu11_output_loss: 23.4671 - val_dyn11_output_loss: 0.9078 - val_s1_output_loss: 0.0787 - val_t2_output_loss: 0.8056 - val_nu21_output_loss: 23.8459 - val_nu22_output_loss: 27.4340 - val_dyn21_output_loss: 1.0627 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.0894 - val_m2_21_output_loss: 1.0549 - val_t1_output_mae: 0.5672 - val_nu11_output_mae: 2.0344 - val_dyn11_output_categorical_accuracy: 0.6309 - val_s1_output_mae: 0.2423 - val_t2_output_mae: 0.6385 - val_nu21_output_mae: 1.9982 - val_nu22_output_mae: 2.5802 - val_dyn21_output_categorical_accuracy: 0.4414 - val_dyn22_output_categorical_accuracy: 0.4451 - val_m2_12_output_mae: 0.6643 - val_m2_21_output_mae: 0.5998\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 80.4824 - t1_output_loss: 0.7865 - nu11_output_loss: 22.9981 - dyn11_output_loss: 0.9060 - s1_output_loss: 0.0774 - t2_output_loss: 0.7836 - nu21_output_loss: 25.7388 - nu22_output_loss: 24.4808 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2951 - m2_21_output_loss: 1.2951 - t1_output_mae: 0.5882 - nu11_output_mae: 1.8932 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2385 - t2_output_mae: 0.5816 - nu21_output_mae: 1.9342 - nu22_output_mae: 1.8881 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6920 - m2_21_output_mae: 0.6715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a373df70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a373df70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4699579040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4699579040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 61s 25ms/step - loss: 80.4824 - t1_output_loss: 0.7865 - nu11_output_loss: 22.9981 - dyn11_output_loss: 0.9060 - s1_output_loss: 0.0774 - t2_output_loss: 0.7836 - nu21_output_loss: 25.7388 - nu22_output_loss: 24.4808 - dyn21_output_loss: 1.0599 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2951 - m2_21_output_loss: 1.2951 - t1_output_mae: 0.5882 - nu11_output_mae: 1.8932 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2385 - t2_output_mae: 0.5816 - nu21_output_mae: 1.9342 - nu22_output_mae: 1.8881 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6920 - m2_21_output_mae: 0.6715 - val_loss: 86.6753 - val_t1_output_loss: 0.8112 - val_nu11_output_loss: 25.5320 - val_dyn11_output_loss: 0.9057 - val_s1_output_loss: 0.0786 - val_t2_output_loss: 1.2346 - val_nu21_output_loss: 24.7551 - val_nu22_output_loss: 28.9292 - val_dyn21_output_loss: 1.0594 - val_dyn22_output_loss: 1.0588 - val_m2_12_output_loss: 0.8892 - val_m2_21_output_loss: 1.4215 - val_t1_output_mae: 0.5712 - val_nu11_output_mae: 2.4599 - val_dyn11_output_categorical_accuracy: 0.6334 - val_s1_output_mae: 0.2408 - val_t2_output_mae: 0.6698 - val_nu21_output_mae: 2.3559 - val_nu22_output_mae: 2.5164 - val_dyn21_output_categorical_accuracy: 0.4421 - val_dyn22_output_categorical_accuracy: 0.4467 - val_m2_12_output_mae: 0.5735 - val_m2_21_output_mae: 0.6389\n",
      "Epoch 60/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 79.7165 - t1_output_loss: 0.7953 - nu11_output_loss: 22.9500 - dyn11_output_loss: 0.9064 - s1_output_loss: 0.0774 - t2_output_loss: 0.7861 - nu21_output_loss: 25.6267 - nu22_output_loss: 23.8728 - dyn21_output_loss: 1.0596 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.2971 - m2_21_output_loss: 1.2835 - t1_output_mae: 0.5929 - nu11_output_mae: 1.8835 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2384 - t2_output_mae: 0.5841 - nu21_output_mae: 1.9106 - nu22_output_mae: 1.8957 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6912 - m2_21_output_mae: 0.6688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da26a0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46da26a0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9786ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9786ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 21ms/step - loss: 79.7900 - t1_output_loss: 0.7954 - nu11_output_loss: 22.9565 - dyn11_output_loss: 0.9064 - s1_output_loss: 0.0774 - t2_output_loss: 0.7861 - nu21_output_loss: 25.7026 - nu22_output_loss: 23.8637 - dyn21_output_loss: 1.0596 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2971 - m2_21_output_loss: 1.2837 - t1_output_mae: 0.5929 - nu11_output_mae: 1.8836 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2384 - t2_output_mae: 0.5841 - nu21_output_mae: 1.9113 - nu22_output_mae: 1.8953 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6912 - m2_21_output_mae: 0.6688 - val_loss: 83.2451 - val_t1_output_loss: 0.7843 - val_nu11_output_loss: 24.7633 - val_dyn11_output_loss: 0.9045 - val_s1_output_loss: 0.0862 - val_t2_output_loss: 1.1025 - val_nu21_output_loss: 23.7409 - val_nu22_output_loss: 26.4716 - val_dyn21_output_loss: 1.0590 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 2.2951 - val_m2_21_output_loss: 0.9778 - val_t1_output_mae: 0.5755 - val_nu11_output_mae: 1.6801 - val_dyn11_output_categorical_accuracy: 0.6345 - val_s1_output_mae: 0.2477 - val_t2_output_mae: 0.6293 - val_nu21_output_mae: 1.7698 - val_nu22_output_mae: 2.5220 - val_dyn21_output_categorical_accuracy: 0.4430 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 1.0326 - val_m2_21_output_mae: 0.5789\n",
      "Epoch 61/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 80.6582 - t1_output_loss: 0.7811 - nu11_output_loss: 23.8129 - dyn11_output_loss: 0.9058 - s1_output_loss: 0.0773 - t2_output_loss: 0.7845 - nu21_output_loss: 25.7074 - nu22_output_loss: 23.8876 - dyn21_output_loss: 1.0589 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2759 - m2_21_output_loss: 1.3055 - t1_output_mae: 0.5867 - nu11_output_mae: 1.9114 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2385 - t2_output_mae: 0.5836 - nu21_output_mae: 1.9325 - nu22_output_mae: 1.8848 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6873 - m2_21_output_mae: 0.6757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c857cee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c857cee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dae6b670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dae6b670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 80.6273 - t1_output_loss: 0.7815 - nu11_output_loss: 23.8081 - dyn11_output_loss: 0.9058 - s1_output_loss: 0.0773 - t2_output_loss: 0.7847 - nu21_output_loss: 25.6948 - nu22_output_loss: 23.8727 - dyn21_output_loss: 1.0589 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2761 - m2_21_output_loss: 1.3060 - t1_output_mae: 0.5868 - nu11_output_mae: 1.9113 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2384 - t2_output_mae: 0.5837 - nu21_output_mae: 1.9322 - nu22_output_mae: 1.8843 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6874 - m2_21_output_mae: 0.6759 - val_loss: 81.8881 - val_t1_output_loss: 0.8680 - val_nu11_output_loss: 23.9736 - val_dyn11_output_loss: 0.9048 - val_s1_output_loss: 0.0781 - val_t2_output_loss: 1.1993 - val_nu21_output_loss: 25.0725 - val_nu22_output_loss: 24.8594 - val_dyn21_output_loss: 1.0602 - val_dyn22_output_loss: 1.0606 - val_m2_12_output_loss: 1.6705 - val_m2_21_output_loss: 1.1413 - val_t1_output_mae: 0.6680 - val_nu11_output_mae: 2.1107 - val_dyn11_output_categorical_accuracy: 0.6335 - val_s1_output_mae: 0.2406 - val_t2_output_mae: 0.7222 - val_nu21_output_mae: 2.1652 - val_nu22_output_mae: 2.0863 - val_dyn21_output_categorical_accuracy: 0.4396 - val_dyn22_output_categorical_accuracy: 0.4426 - val_m2_12_output_mae: 0.8704 - val_m2_21_output_mae: 0.6330\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 79.5477 - t1_output_loss: 0.7885 - nu11_output_loss: 22.8634 - dyn11_output_loss: 0.9068 - s1_output_loss: 0.0773 - t2_output_loss: 0.7788 - nu21_output_loss: 25.3755 - nu22_output_loss: 24.0532 - dyn21_output_loss: 1.0584 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2989 - m2_21_output_loss: 1.2850 - t1_output_mae: 0.5896 - nu11_output_mae: 1.8924 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2384 - t2_output_mae: 0.5805 - nu21_output_mae: 1.9169 - nu22_output_mae: 1.8802 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6922 - m2_21_output_mae: 0.6682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c81ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c81ea1f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c86f55e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c86f55e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 79.5477 - t1_output_loss: 0.7885 - nu11_output_loss: 22.8634 - dyn11_output_loss: 0.9068 - s1_output_loss: 0.0773 - t2_output_loss: 0.7788 - nu21_output_loss: 25.3755 - nu22_output_loss: 24.0532 - dyn21_output_loss: 1.0584 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2989 - m2_21_output_loss: 1.2850 - t1_output_mae: 0.5896 - nu11_output_mae: 1.8924 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2384 - t2_output_mae: 0.5805 - nu21_output_mae: 1.9169 - nu22_output_mae: 1.8802 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6922 - m2_21_output_mae: 0.6682 - val_loss: 95.7387 - val_t1_output_loss: 0.8915 - val_nu11_output_loss: 23.7495 - val_dyn11_output_loss: 0.9079 - val_s1_output_loss: 0.0772 - val_t2_output_loss: 1.1354 - val_nu21_output_loss: 25.4810 - val_nu22_output_loss: 38.8198 - val_dyn21_output_loss: 1.0596 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 1.1589 - val_m2_21_output_loss: 1.3980 - val_t1_output_mae: 0.6578 - val_nu11_output_mae: 2.2037 - val_dyn11_output_categorical_accuracy: 0.6316 - val_s1_output_mae: 0.2393 - val_t2_output_mae: 0.8315 - val_nu21_output_mae: 2.4165 - val_nu22_output_mae: 3.6305 - val_dyn21_output_categorical_accuracy: 0.4414 - val_dyn22_output_categorical_accuracy: 0.4448 - val_m2_12_output_mae: 0.7144 - val_m2_21_output_mae: 0.6325\n",
      "Epoch 63/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 80.2490 - t1_output_loss: 0.7841 - nu11_output_loss: 23.0703 - dyn11_output_loss: 0.9056 - s1_output_loss: 0.0773 - t2_output_loss: 0.7813 - nu21_output_loss: 25.7351 - nu22_output_loss: 24.2144 - dyn21_output_loss: 1.0577 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2771 - m2_21_output_loss: 1.2849 - t1_output_mae: 0.5876 - nu11_output_mae: 1.8903 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2384 - t2_output_mae: 0.5808 - nu21_output_mae: 1.9392 - nu22_output_mae: 1.8801 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6870 - m2_21_output_mae: 0.6691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c86f5940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c86f5940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9faa160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9faa160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 80.2283 - t1_output_loss: 0.7840 - nu11_output_loss: 23.0634 - dyn11_output_loss: 0.9056 - s1_output_loss: 0.0773 - t2_output_loss: 0.7813 - nu21_output_loss: 25.7274 - nu22_output_loss: 24.2085 - dyn21_output_loss: 1.0577 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2770 - m2_21_output_loss: 1.2849 - t1_output_mae: 0.5876 - nu11_output_mae: 1.8901 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2384 - t2_output_mae: 0.5808 - nu21_output_mae: 1.9390 - nu22_output_mae: 1.8800 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6869 - m2_21_output_mae: 0.6691 - val_loss: 82.8825 - val_t1_output_loss: 0.7747 - val_nu11_output_loss: 25.2350 - val_dyn11_output_loss: 0.9116 - val_s1_output_loss: 0.0758 - val_t2_output_loss: 1.3386 - val_nu21_output_loss: 23.5547 - val_nu22_output_loss: 26.6598 - val_dyn21_output_loss: 1.0575 - val_dyn22_output_loss: 1.0587 - val_m2_12_output_loss: 0.9920 - val_m2_21_output_loss: 1.2241 - val_t1_output_mae: 0.5641 - val_nu11_output_mae: 2.5112 - val_dyn11_output_categorical_accuracy: 0.6342 - val_s1_output_mae: 0.2361 - val_t2_output_mae: 0.7055 - val_nu21_output_mae: 2.0078 - val_nu22_output_mae: 2.4834 - val_dyn21_output_categorical_accuracy: 0.4423 - val_dyn22_output_categorical_accuracy: 0.4470 - val_m2_12_output_mae: 0.5984 - val_m2_21_output_mae: 0.5833\n",
      "Epoch 64/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 79.0494 - t1_output_loss: 0.7915 - nu11_output_loss: 22.6928 - dyn11_output_loss: 0.9063 - s1_output_loss: 0.0775 - t2_output_loss: 0.7789 - nu21_output_loss: 25.5032 - nu22_output_loss: 23.5915 - dyn21_output_loss: 1.0572 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2890 - m2_21_output_loss: 1.2999 - t1_output_mae: 0.5910 - nu11_output_mae: 1.8796 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2386 - t2_output_mae: 0.5810 - nu21_output_mae: 1.8996 - nu22_output_mae: 1.8728 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6886 - m2_21_output_mae: 0.6744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a339d5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a339d5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d904a040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d904a040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 79.0979 - t1_output_loss: 0.7916 - nu11_output_loss: 22.6867 - dyn11_output_loss: 0.9063 - s1_output_loss: 0.0775 - t2_output_loss: 0.7791 - nu21_output_loss: 25.5737 - nu22_output_loss: 23.5751 - dyn21_output_loss: 1.0573 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2886 - m2_21_output_loss: 1.3003 - t1_output_mae: 0.5910 - nu11_output_mae: 1.8794 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2386 - t2_output_mae: 0.5810 - nu21_output_mae: 1.9003 - nu22_output_mae: 1.8722 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6885 - m2_21_output_mae: 0.6745 - val_loss: 80.2754 - val_t1_output_loss: 1.6718 - val_nu11_output_loss: 23.9474 - val_dyn11_output_loss: 0.9034 - val_s1_output_loss: 0.0768 - val_t2_output_loss: 1.2006 - val_nu21_output_loss: 23.7552 - val_nu22_output_loss: 24.3341 - val_dyn21_output_loss: 1.0610 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 1.2617 - val_m2_21_output_loss: 1.0033 - val_t1_output_mae: 1.0499 - val_nu11_output_mae: 1.8099 - val_dyn11_output_categorical_accuracy: 0.6344 - val_s1_output_mae: 0.2379 - val_t2_output_mae: 0.8325 - val_nu21_output_mae: 1.6331 - val_nu22_output_mae: 1.8001 - val_dyn21_output_categorical_accuracy: 0.4428 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.6422 - val_m2_21_output_mae: 0.6127\n",
      "Epoch 65/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 80.8663 - t1_output_loss: 0.7790 - nu11_output_loss: 24.0035 - dyn11_output_loss: 0.9051 - s1_output_loss: 0.0772 - t2_output_loss: 0.7782 - nu21_output_loss: 25.9681 - nu22_output_loss: 23.6931 - dyn21_output_loss: 1.0572 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2692 - m2_21_output_loss: 1.2742 - t1_output_mae: 0.5846 - nu11_output_mae: 1.9100 - dyn11_output_categorical_accuracy: 0.6312 - s1_output_mae: 0.2382 - t2_output_mae: 0.5811 - nu21_output_mae: 1.9195 - nu22_output_mae: 1.8781 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6850 - m2_21_output_mae: 0.6656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469a840ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469a840ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469d97f5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469d97f5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 56s 23ms/step - loss: 80.8423 - t1_output_loss: 0.7795 - nu11_output_loss: 24.0231 - dyn11_output_loss: 0.9052 - s1_output_loss: 0.0772 - t2_output_loss: 0.7786 - nu21_output_loss: 25.9469 - nu22_output_loss: 23.6688 - dyn21_output_loss: 1.0572 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2696 - m2_21_output_loss: 1.2748 - t1_output_mae: 0.5848 - nu11_output_mae: 1.9107 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2382 - t2_output_mae: 0.5812 - nu21_output_mae: 1.9188 - nu22_output_mae: 1.8772 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6851 - m2_21_output_mae: 0.6657 - val_loss: 79.3235 - val_t1_output_loss: 0.7592 - val_nu11_output_loss: 23.9747 - val_dyn11_output_loss: 0.9122 - val_s1_output_loss: 0.0769 - val_t2_output_loss: 0.8146 - val_nu21_output_loss: 23.4648 - val_nu22_output_loss: 24.9948 - val_dyn21_output_loss: 1.0593 - val_dyn22_output_loss: 1.0606 - val_m2_12_output_loss: 1.1869 - val_m2_21_output_loss: 1.0196 - val_t1_output_mae: 0.5693 - val_nu11_output_mae: 1.8008 - val_dyn11_output_categorical_accuracy: 0.6330 - val_s1_output_mae: 0.2391 - val_t2_output_mae: 0.6210 - val_nu21_output_mae: 1.7386 - val_nu22_output_mae: 1.9769 - val_dyn21_output_categorical_accuracy: 0.4394 - val_dyn22_output_categorical_accuracy: 0.4427 - val_m2_12_output_mae: 0.6294 - val_m2_21_output_mae: 0.5518\n",
      "Epoch 66/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 79.2029 - t1_output_loss: 0.7850 - nu11_output_loss: 22.9160 - dyn11_output_loss: 0.9061 - s1_output_loss: 0.0773 - t2_output_loss: 0.7750 - nu21_output_loss: 25.4566 - nu22_output_loss: 23.6274 - dyn21_output_loss: 1.0564 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2715 - m2_21_output_loss: 1.2698 - t1_output_mae: 0.5877 - nu11_output_mae: 1.8990 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2383 - t2_output_mae: 0.5778 - nu21_output_mae: 1.9201 - nu22_output_mae: 1.8666 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6847 - m2_21_output_mae: 0.6648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c8cb61f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c8cb61f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469ee47430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469ee47430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 56s 23ms/step - loss: 79.2638 - t1_output_loss: 0.7849 - nu11_output_loss: 22.9039 - dyn11_output_loss: 0.9061 - s1_output_loss: 0.0773 - t2_output_loss: 0.7748 - nu21_output_loss: 25.4605 - nu22_output_loss: 23.6968 - dyn21_output_loss: 1.0564 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2715 - m2_21_output_loss: 1.2699 - t1_output_mae: 0.5876 - nu11_output_mae: 1.8988 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2383 - t2_output_mae: 0.5777 - nu21_output_mae: 1.9203 - nu22_output_mae: 1.8678 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6847 - m2_21_output_mae: 0.6649 - val_loss: 82.3266 - val_t1_output_loss: 0.7963 - val_nu11_output_loss: 23.0693 - val_dyn11_output_loss: 0.9068 - val_s1_output_loss: 0.0775 - val_t2_output_loss: 0.9129 - val_nu21_output_loss: 23.9995 - val_nu22_output_loss: 24.6128 - val_dyn21_output_loss: 1.0589 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 2.7912 - val_m2_21_output_loss: 3.0417 - val_t1_output_mae: 0.5683 - val_nu11_output_mae: 1.9916 - val_dyn11_output_categorical_accuracy: 0.6319 - val_s1_output_mae: 0.2401 - val_t2_output_mae: 0.5689 - val_nu21_output_mae: 1.8388 - val_nu22_output_mae: 1.9821 - val_dyn21_output_categorical_accuracy: 0.4412 - val_dyn22_output_categorical_accuracy: 0.4451 - val_m2_12_output_mae: 1.1931 - val_m2_21_output_mae: 1.1304\n",
      "Epoch 67/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 80.1598 - t1_output_loss: 0.7801 - nu11_output_loss: 22.8871 - dyn11_output_loss: 0.9051 - s1_output_loss: 0.0771 - t2_output_loss: 0.7810 - nu21_output_loss: 25.8321 - nu22_output_loss: 24.2329 - dyn21_output_loss: 1.0561 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2722 - m2_21_output_loss: 1.2750 - t1_output_mae: 0.5847 - nu11_output_mae: 1.8931 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2379 - t2_output_mae: 0.5795 - nu21_output_mae: 1.9277 - nu22_output_mae: 1.8742 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 0.6844 - m2_21_output_mae: 0.6664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46daaa40d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46daaa40d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c95d6430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c95d6430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 80.1215 - t1_output_loss: 0.7798 - nu11_output_loss: 22.8718 - dyn11_output_loss: 0.9050 - s1_output_loss: 0.0771 - t2_output_loss: 0.7810 - nu21_output_loss: 25.8161 - nu22_output_loss: 24.2266 - dyn21_output_loss: 1.0561 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2720 - m2_21_output_loss: 1.2749 - t1_output_mae: 0.5846 - nu11_output_mae: 1.8926 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2379 - t2_output_mae: 0.5795 - nu21_output_mae: 1.9273 - nu22_output_mae: 1.8743 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6844 - m2_21_output_mae: 0.6663 - val_loss: 135.2791 - val_t1_output_loss: 0.7409 - val_nu11_output_loss: 25.8077 - val_dyn11_output_loss: 0.9029 - val_s1_output_loss: 0.0755 - val_t2_output_loss: 3.8474 - val_nu21_output_loss: 39.0612 - val_nu22_output_loss: 60.5056 - val_dyn21_output_loss: 1.0564 - val_dyn22_output_loss: 1.0589 - val_m2_12_output_loss: 1.1508 - val_m2_21_output_loss: 1.0719 - val_t1_output_mae: 0.5886 - val_nu11_output_mae: 2.5294 - val_dyn11_output_categorical_accuracy: 0.6342 - val_s1_output_mae: 0.2358 - val_t2_output_mae: 1.4718 - val_nu21_output_mae: 3.9797 - val_nu22_output_mae: 4.9951 - val_dyn21_output_categorical_accuracy: 0.4419 - val_dyn22_output_categorical_accuracy: 0.4466 - val_m2_12_output_mae: 0.7047 - val_m2_21_output_mae: 0.6357\n",
      "Epoch 68/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 78.9405 - t1_output_loss: 0.7875 - nu11_output_loss: 22.6931 - dyn11_output_loss: 0.9057 - s1_output_loss: 0.0772 - t2_output_loss: 0.7819 - nu21_output_loss: 25.4456 - nu22_output_loss: 23.5802 - dyn21_output_loss: 1.0554 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2805 - m2_21_output_loss: 1.2719 - t1_output_mae: 0.5880 - nu11_output_mae: 1.8791 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2380 - t2_output_mae: 0.5815 - nu21_output_mae: 1.9106 - nu22_output_mae: 1.8639 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4437 - m2_12_output_mae: 0.6844 - m2_21_output_mae: 0.6661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cae43040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cae43040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dab58670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46dab58670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 78.9713 - t1_output_loss: 0.7876 - nu11_output_loss: 22.6838 - dyn11_output_loss: 0.9056 - s1_output_loss: 0.0772 - t2_output_loss: 0.7821 - nu21_output_loss: 25.5073 - nu22_output_loss: 23.5587 - dyn21_output_loss: 1.0555 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2801 - m2_21_output_loss: 1.2718 - t1_output_mae: 0.5879 - nu11_output_mae: 1.8785 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2380 - t2_output_mae: 0.5815 - nu21_output_mae: 1.9110 - nu22_output_mae: 1.8631 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6843 - m2_21_output_mae: 0.6661 - val_loss: 87.4170 - val_t1_output_loss: 0.7450 - val_nu11_output_loss: 24.8214 - val_dyn11_output_loss: 0.9083 - val_s1_output_loss: 0.0772 - val_t2_output_loss: 0.9974 - val_nu21_output_loss: 23.8986 - val_nu22_output_loss: 31.9171 - val_dyn21_output_loss: 1.0573 - val_dyn22_output_loss: 1.0601 - val_m2_12_output_loss: 0.9927 - val_m2_21_output_loss: 0.9418 - val_t1_output_mae: 0.5860 - val_nu11_output_mae: 2.4142 - val_dyn11_output_categorical_accuracy: 0.6342 - val_s1_output_mae: 0.2389 - val_t2_output_mae: 0.5839 - val_nu21_output_mae: 1.6845 - val_nu22_output_mae: 2.8301 - val_dyn21_output_categorical_accuracy: 0.4428 - val_dyn22_output_categorical_accuracy: 0.4436 - val_m2_12_output_mae: 0.6470 - val_m2_21_output_mae: 0.5469\n",
      "Epoch 69/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 79.6469 - t1_output_loss: 0.7752 - nu11_output_loss: 23.6796 - dyn11_output_loss: 0.9048 - s1_output_loss: 0.0771 - t2_output_loss: 0.7722 - nu21_output_loss: 25.3800 - nu22_output_loss: 23.4181 - dyn21_output_loss: 1.0554 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2639 - m2_21_output_loss: 1.2594 - t1_output_mae: 0.5827 - nu11_output_mae: 1.9042 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2380 - t2_output_mae: 0.5757 - nu21_output_mae: 1.9074 - nu22_output_mae: 1.8580 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6841 - m2_21_output_mae: 0.6631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8ed8280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8ed8280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0c16040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0c16040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 25ms/step - loss: 79.6144 - t1_output_loss: 0.7756 - nu11_output_loss: 23.6757 - dyn11_output_loss: 0.9048 - s1_output_loss: 0.0771 - t2_output_loss: 0.7725 - nu21_output_loss: 25.3649 - nu22_output_loss: 23.4034 - dyn21_output_loss: 1.0554 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2641 - m2_21_output_loss: 1.2596 - t1_output_mae: 0.5828 - nu11_output_mae: 1.9040 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2380 - t2_output_mae: 0.5758 - nu21_output_mae: 1.9072 - nu22_output_mae: 1.8575 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6842 - m2_21_output_mae: 0.6631 - val_loss: 83.2400 - val_t1_output_loss: 0.7691 - val_nu11_output_loss: 23.7432 - val_dyn11_output_loss: 0.9041 - val_s1_output_loss: 0.0760 - val_t2_output_loss: 0.8059 - val_nu21_output_loss: 23.5662 - val_nu22_output_loss: 27.3112 - val_dyn21_output_loss: 1.0577 - val_dyn22_output_loss: 1.0606 - val_m2_12_output_loss: 2.9045 - val_m2_21_output_loss: 1.0415 - val_t1_output_mae: 0.5705 - val_nu11_output_mae: 1.9426 - val_dyn11_output_categorical_accuracy: 0.6331 - val_s1_output_mae: 0.2373 - val_t2_output_mae: 0.6186 - val_nu21_output_mae: 1.9695 - val_nu22_output_mae: 2.4855 - val_dyn21_output_categorical_accuracy: 0.4394 - val_dyn22_output_categorical_accuracy: 0.4429 - val_m2_12_output_mae: 1.2421 - val_m2_21_output_mae: 0.5636\n",
      "Epoch 70/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 78.8388 - t1_output_loss: 0.7797 - nu11_output_loss: 22.8447 - dyn11_output_loss: 0.9060 - s1_output_loss: 0.0770 - t2_output_loss: 0.7703 - nu21_output_loss: 25.2113 - nu22_output_loss: 23.6041 - dyn21_output_loss: 1.0547 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2691 - m2_21_output_loss: 1.2602 - t1_output_mae: 0.5845 - nu11_output_mae: 1.8817 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2379 - t2_output_mae: 0.5761 - nu21_output_mae: 1.8968 - nu22_output_mae: 1.8674 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6843 - m2_21_output_mae: 0.6613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cae4d0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46cae4d0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469fe05ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469fe05ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 78.8926 - t1_output_loss: 0.7796 - nu11_output_loss: 22.8365 - dyn11_output_loss: 0.9059 - s1_output_loss: 0.0770 - t2_output_loss: 0.7702 - nu21_output_loss: 25.2048 - nu22_output_loss: 23.6728 - dyn21_output_loss: 1.0547 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2689 - m2_21_output_loss: 1.2603 - t1_output_mae: 0.5845 - nu11_output_mae: 1.8813 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2379 - t2_output_mae: 0.5760 - nu21_output_mae: 1.8968 - nu22_output_mae: 1.8684 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6843 - m2_21_output_mae: 0.6613 - val_loss: 88.6848 - val_t1_output_loss: 0.9318 - val_nu11_output_loss: 22.8770 - val_dyn11_output_loss: 0.9059 - val_s1_output_loss: 0.0785 - val_t2_output_loss: 0.9245 - val_nu21_output_loss: 32.7879 - val_nu22_output_loss: 25.0107 - val_dyn21_output_loss: 1.0570 - val_dyn22_output_loss: 1.0597 - val_m2_12_output_loss: 1.7347 - val_m2_21_output_loss: 1.3169 - val_t1_output_mae: 0.7070 - val_nu11_output_mae: 2.0274 - val_dyn11_output_categorical_accuracy: 0.6319 - val_s1_output_mae: 0.2405 - val_t2_output_mae: 0.6916 - val_nu21_output_mae: 3.0084 - val_nu22_output_mae: 1.9032 - val_dyn21_output_categorical_accuracy: 0.4416 - val_dyn22_output_categorical_accuracy: 0.4448 - val_m2_12_output_mae: 0.6970 - val_m2_21_output_mae: 0.5977\n",
      "Epoch 71/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 79.4308 - t1_output_loss: 0.7747 - nu11_output_loss: 22.7579 - dyn11_output_loss: 0.9043 - s1_output_loss: 0.0769 - t2_output_loss: 0.7747 - nu21_output_loss: 25.4949 - nu22_output_loss: 24.0098 - dyn21_output_loss: 1.0549 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2641 - m2_21_output_loss: 1.2576 - t1_output_mae: 0.5826 - nu11_output_mae: 1.8807 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2376 - t2_output_mae: 0.5775 - nu21_output_mae: 1.9183 - nu22_output_mae: 1.8648 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 0.6805 - m2_21_output_mae: 0.6588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c87b54c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c87b54c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c87b50d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c87b50d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 22ms/step - loss: 79.3864 - t1_output_loss: 0.7745 - nu11_output_loss: 22.7430 - dyn11_output_loss: 0.9042 - s1_output_loss: 0.0769 - t2_output_loss: 0.7747 - nu21_output_loss: 25.4791 - nu22_output_loss: 23.9969 - dyn21_output_loss: 1.0549 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2638 - m2_21_output_loss: 1.2573 - t1_output_mae: 0.5825 - nu11_output_mae: 1.8802 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2375 - t2_output_mae: 0.5776 - nu21_output_mae: 1.9179 - nu22_output_mae: 1.8647 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6804 - m2_21_output_mae: 0.6587 - val_loss: 97.6279 - val_t1_output_loss: 0.7379 - val_nu11_output_loss: 29.9282 - val_dyn11_output_loss: 0.9027 - val_s1_output_loss: 0.0777 - val_t2_output_loss: 0.9909 - val_nu21_output_loss: 23.9529 - val_nu22_output_loss: 34.9632 - val_dyn21_output_loss: 1.0551 - val_dyn22_output_loss: 1.0584 - val_m2_12_output_loss: 2.3276 - val_m2_21_output_loss: 1.6332 - val_t1_output_mae: 0.5797 - val_nu11_output_mae: 3.3241 - val_dyn11_output_categorical_accuracy: 0.6337 - val_s1_output_mae: 0.2382 - val_t2_output_mae: 0.7272 - val_nu21_output_mae: 2.1122 - val_nu22_output_mae: 3.1394 - val_dyn21_output_categorical_accuracy: 0.4415 - val_dyn22_output_categorical_accuracy: 0.4475 - val_m2_12_output_mae: 0.8325 - val_m2_21_output_mae: 0.7180\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 78.6218 - t1_output_loss: 0.7841 - nu11_output_loss: 22.6449 - dyn11_output_loss: 0.9054 - s1_output_loss: 0.0771 - t2_output_loss: 0.7762 - nu21_output_loss: 25.4426 - nu22_output_loss: 23.3684 - dyn21_output_loss: 1.0544 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2506 - m2_21_output_loss: 1.2568 - t1_output_mae: 0.5857 - nu11_output_mae: 1.8636 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2377 - t2_output_mae: 0.5774 - nu21_output_mae: 1.8967 - nu22_output_mae: 1.8579 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6769 - m2_21_output_mae: 0.6606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469de62700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469de62700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8b41310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8b41310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 62s 25ms/step - loss: 78.6218 - t1_output_loss: 0.7841 - nu11_output_loss: 22.6449 - dyn11_output_loss: 0.9054 - s1_output_loss: 0.0771 - t2_output_loss: 0.7762 - nu21_output_loss: 25.4426 - nu22_output_loss: 23.3684 - dyn21_output_loss: 1.0544 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2506 - m2_21_output_loss: 1.2568 - t1_output_mae: 0.5857 - nu11_output_mae: 1.8636 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2377 - t2_output_mae: 0.5774 - nu21_output_mae: 1.8967 - nu22_output_mae: 1.8579 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6769 - m2_21_output_mae: 0.6606 - val_loss: 84.1170 - val_t1_output_loss: 0.7437 - val_nu11_output_loss: 24.3335 - val_dyn11_output_loss: 0.9022 - val_s1_output_loss: 0.0787 - val_t2_output_loss: 0.8816 - val_nu21_output_loss: 23.7154 - val_nu22_output_loss: 29.1772 - val_dyn21_output_loss: 1.0549 - val_dyn22_output_loss: 1.0601 - val_m2_12_output_loss: 0.9695 - val_m2_21_output_loss: 1.2004 - val_t1_output_mae: 0.5828 - val_nu11_output_mae: 1.6620 - val_dyn11_output_categorical_accuracy: 0.6346 - val_s1_output_mae: 0.2382 - val_t2_output_mae: 0.6713 - val_nu21_output_mae: 1.8684 - val_nu22_output_mae: 2.6205 - val_dyn21_output_categorical_accuracy: 0.4428 - val_dyn22_output_categorical_accuracy: 0.4436 - val_m2_12_output_mae: 0.5946 - val_m2_21_output_mae: 0.7103\n",
      "Epoch 73/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 79.6840 - t1_output_loss: 0.7681 - nu11_output_loss: 23.6773 - dyn11_output_loss: 0.9050 - s1_output_loss: 0.0769 - t2_output_loss: 0.7702 - nu21_output_loss: 25.3871 - nu22_output_loss: 23.4829 - dyn21_output_loss: 1.0545 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2479 - m2_21_output_loss: 1.2528 - t1_output_mae: 0.5803 - nu11_output_mae: 1.9006 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2377 - t2_output_mae: 0.5756 - nu21_output_mae: 1.8963 - nu22_output_mae: 1.8727 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6768 - m2_21_output_mae: 0.6594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f4699c970d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f4699c970d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da74c5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da74c5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 62s 25ms/step - loss: 79.6520 - t1_output_loss: 0.7685 - nu11_output_loss: 23.6729 - dyn11_output_loss: 0.9051 - s1_output_loss: 0.0769 - t2_output_loss: 0.7705 - nu21_output_loss: 25.3728 - nu22_output_loss: 23.4687 - dyn21_output_loss: 1.0545 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2477 - m2_21_output_loss: 1.2533 - t1_output_mae: 0.5804 - nu11_output_mae: 1.9004 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2377 - t2_output_mae: 0.5757 - nu21_output_mae: 1.8959 - nu22_output_mae: 1.8721 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6768 - m2_21_output_mae: 0.6595 - val_loss: 78.7806 - val_t1_output_loss: 0.7737 - val_nu11_output_loss: 24.1521 - val_dyn11_output_loss: 0.9199 - val_s1_output_loss: 0.0777 - val_t2_output_loss: 0.6845 - val_nu21_output_loss: 23.1131 - val_nu22_output_loss: 24.0132 - val_dyn21_output_loss: 1.0567 - val_dyn22_output_loss: 1.0608 - val_m2_12_output_loss: 1.5027 - val_m2_21_output_loss: 1.4264 - val_t1_output_mae: 0.5776 - val_nu11_output_mae: 1.8392 - val_dyn11_output_categorical_accuracy: 0.6327 - val_s1_output_mae: 0.2395 - val_t2_output_mae: 0.5464 - val_nu21_output_mae: 1.9096 - val_nu22_output_mae: 1.7774 - val_dyn21_output_categorical_accuracy: 0.4395 - val_dyn22_output_categorical_accuracy: 0.4424 - val_m2_12_output_mae: 0.8495 - val_m2_21_output_mae: 0.7563\n",
      "Epoch 74/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 78.7585 - t1_output_loss: 0.7757 - nu11_output_loss: 22.8197 - dyn11_output_loss: 0.9052 - s1_output_loss: 0.0772 - t2_output_loss: 0.7664 - nu21_output_loss: 25.2587 - nu22_output_loss: 23.5291 - dyn21_output_loss: 1.0543 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2495 - m2_21_output_loss: 1.2608 - t1_output_mae: 0.5832 - nu11_output_mae: 1.8893 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2382 - t2_output_mae: 0.5736 - nu21_output_mae: 1.8968 - nu22_output_mae: 1.8523 - dyn21_output_categorical_accuracy: 0.4487 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6747 - m2_21_output_mae: 0.6632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2b45d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a2b45d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2b45dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2b45dc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 21ms/step - loss: 78.8144 - t1_output_loss: 0.7757 - nu11_output_loss: 22.8123 - dyn11_output_loss: 0.9051 - s1_output_loss: 0.0772 - t2_output_loss: 0.7663 - nu21_output_loss: 25.2517 - nu22_output_loss: 23.5995 - dyn21_output_loss: 1.0543 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2496 - m2_21_output_loss: 1.2609 - t1_output_mae: 0.5831 - nu11_output_mae: 1.8890 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2382 - t2_output_mae: 0.5736 - nu21_output_mae: 1.8966 - nu22_output_mae: 1.8533 - dyn21_output_categorical_accuracy: 0.4487 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6747 - m2_21_output_mae: 0.6632 - val_loss: 82.5029 - val_t1_output_loss: 0.7750 - val_nu11_output_loss: 23.0432 - val_dyn11_output_loss: 0.9064 - val_s1_output_loss: 0.0779 - val_t2_output_loss: 0.9800 - val_nu21_output_loss: 23.1763 - val_nu22_output_loss: 28.7336 - val_dyn21_output_loss: 1.0550 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.4023 - val_m2_21_output_loss: 1.2936 - val_t1_output_mae: 0.6060 - val_nu11_output_mae: 2.0776 - val_dyn11_output_categorical_accuracy: 0.6319 - val_s1_output_mae: 0.2399 - val_t2_output_mae: 0.7153 - val_nu21_output_mae: 1.7512 - val_nu22_output_mae: 2.6892 - val_dyn21_output_categorical_accuracy: 0.4418 - val_dyn22_output_categorical_accuracy: 0.4449 - val_m2_12_output_mae: 0.7787 - val_m2_21_output_mae: 0.7129\n",
      "Epoch 75/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 79.4912 - t1_output_loss: 0.7703 - nu11_output_loss: 22.7790 - dyn11_output_loss: 0.9041 - s1_output_loss: 0.0770 - t2_output_loss: 0.7700 - nu21_output_loss: 25.2971 - nu22_output_loss: 24.2794 - dyn21_output_loss: 1.0540 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2475 - m2_21_output_loss: 1.2518 - t1_output_mae: 0.5799 - nu11_output_mae: 1.8731 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2377 - t2_output_mae: 0.5751 - nu21_output_mae: 1.9091 - nu22_output_mae: 1.8789 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6776 - m2_21_output_mae: 0.6610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469966a040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469966a040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d918f670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d918f670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 79.4686 - t1_output_loss: 0.7702 - nu11_output_loss: 22.7723 - dyn11_output_loss: 0.9041 - s1_output_loss: 0.0770 - t2_output_loss: 0.7700 - nu21_output_loss: 25.2891 - nu22_output_loss: 24.2721 - dyn21_output_loss: 1.0540 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2474 - m2_21_output_loss: 1.2516 - t1_output_mae: 0.5799 - nu11_output_mae: 1.8730 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2377 - t2_output_mae: 0.5751 - nu21_output_mae: 1.9088 - nu22_output_mae: 1.8787 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6775 - m2_21_output_mae: 0.6609 - val_loss: 92.3824 - val_t1_output_loss: 0.8659 - val_nu11_output_loss: 25.0191 - val_dyn11_output_loss: 0.9017 - val_s1_output_loss: 0.0762 - val_t2_output_loss: 1.0356 - val_nu21_output_loss: 26.2086 - val_nu22_output_loss: 33.4056 - val_dyn21_output_loss: 1.0543 - val_dyn22_output_loss: 1.0587 - val_m2_12_output_loss: 1.3658 - val_m2_21_output_loss: 1.3910 - val_t1_output_mae: 0.6173 - val_nu11_output_mae: 2.3621 - val_dyn11_output_categorical_accuracy: 0.6335 - val_s1_output_mae: 0.2368 - val_t2_output_mae: 0.5999 - val_nu21_output_mae: 2.4363 - val_nu22_output_mae: 2.9599 - val_dyn21_output_categorical_accuracy: 0.4418 - val_dyn22_output_categorical_accuracy: 0.4470 - val_m2_12_output_mae: 0.7911 - val_m2_21_output_mae: 0.6132\n",
      "Epoch 76/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 77.9673 - t1_output_loss: 0.7792 - nu11_output_loss: 22.5039 - dyn11_output_loss: 0.9043 - s1_output_loss: 0.0769 - t2_output_loss: 0.7729 - nu21_output_loss: 25.1334 - nu22_output_loss: 23.1888 - dyn21_output_loss: 1.0539 - dyn22_output_loss: 1.0616 - m2_12_output_loss: 1.2365 - m2_21_output_loss: 1.2560 - t1_output_mae: 0.5843 - nu11_output_mae: 1.8727 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2373 - t2_output_mae: 0.5754 - nu21_output_mae: 1.8889 - nu22_output_mae: 1.8565 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6725 - m2_21_output_mae: 0.6618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46caf4b160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46caf4b160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db849160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db849160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 78.0408 - t1_output_loss: 0.7793 - nu11_output_loss: 22.5069 - dyn11_output_loss: 0.9043 - s1_output_loss: 0.0769 - t2_output_loss: 0.7729 - nu21_output_loss: 25.2121 - nu22_output_loss: 23.1807 - dyn21_output_loss: 1.0539 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2364 - m2_21_output_loss: 1.2561 - t1_output_mae: 0.5844 - nu11_output_mae: 1.8727 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2373 - t2_output_mae: 0.5754 - nu21_output_mae: 1.8897 - nu22_output_mae: 1.8561 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6724 - m2_21_output_mae: 0.6618 - val_loss: 93.3682 - val_t1_output_loss: 0.9437 - val_nu11_output_loss: 23.9675 - val_dyn11_output_loss: 0.8990 - val_s1_output_loss: 0.0760 - val_t2_output_loss: 1.0747 - val_nu21_output_loss: 23.4931 - val_nu22_output_loss: 37.9888 - val_dyn21_output_loss: 1.0545 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 1.6011 - val_m2_21_output_loss: 1.2100 - val_t1_output_mae: 0.6085 - val_nu11_output_mae: 2.2600 - val_dyn11_output_categorical_accuracy: 0.6355 - val_s1_output_mae: 0.2364 - val_t2_output_mae: 0.6360 - val_nu21_output_mae: 1.7239 - val_nu22_output_mae: 3.5847 - val_dyn21_output_categorical_accuracy: 0.4426 - val_dyn22_output_categorical_accuracy: 0.4443 - val_m2_12_output_mae: 0.8251 - val_m2_21_output_mae: 0.7077\n",
      "Epoch 77/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 79.5597 - t1_output_loss: 0.7692 - nu11_output_loss: 23.5495 - dyn11_output_loss: 0.9041 - s1_output_loss: 0.0769 - t2_output_loss: 0.7705 - nu21_output_loss: 25.4361 - nu22_output_loss: 23.4587 - dyn21_output_loss: 1.0540 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2473 - m2_21_output_loss: 1.2320 - t1_output_mae: 0.5796 - nu11_output_mae: 1.8897 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2378 - t2_output_mae: 0.5754 - nu21_output_mae: 1.8966 - nu22_output_mae: 1.8698 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6736 - m2_21_output_mae: 0.6530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a04d04c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a04d04c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a04d01f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a04d01f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 21ms/step - loss: 79.5249 - t1_output_loss: 0.7695 - nu11_output_loss: 23.5465 - dyn11_output_loss: 0.9041 - s1_output_loss: 0.0769 - t2_output_loss: 0.7708 - nu21_output_loss: 25.4202 - nu22_output_loss: 23.4421 - dyn21_output_loss: 1.0540 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2474 - m2_21_output_loss: 1.2321 - t1_output_mae: 0.5797 - nu11_output_mae: 1.8896 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2378 - t2_output_mae: 0.5755 - nu21_output_mae: 1.8961 - nu22_output_mae: 1.8692 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6736 - m2_21_output_mae: 0.6530 - val_loss: 81.5941 - val_t1_output_loss: 0.7447 - val_nu11_output_loss: 24.4782 - val_dyn11_output_loss: 0.9059 - val_s1_output_loss: 0.0773 - val_t2_output_loss: 1.2126 - val_nu21_output_loss: 22.6044 - val_nu22_output_loss: 26.0686 - val_dyn21_output_loss: 1.0563 - val_dyn22_output_loss: 1.0605 - val_m2_12_output_loss: 2.0588 - val_m2_21_output_loss: 1.3269 - val_t1_output_mae: 0.5771 - val_nu11_output_mae: 1.9340 - val_dyn11_output_categorical_accuracy: 0.6319 - val_s1_output_mae: 0.2387 - val_t2_output_mae: 0.6496 - val_nu21_output_mae: 1.8984 - val_nu22_output_mae: 2.3207 - val_dyn21_output_categorical_accuracy: 0.4400 - val_dyn22_output_categorical_accuracy: 0.4428 - val_m2_12_output_mae: 0.7717 - val_m2_21_output_mae: 0.7326\n",
      "Epoch 78/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 78.3527 - t1_output_loss: 0.7723 - nu11_output_loss: 22.7813 - dyn11_output_loss: 0.9051 - s1_output_loss: 0.0771 - t2_output_loss: 0.7655 - nu21_output_loss: 25.0435 - nu22_output_loss: 23.4233 - dyn21_output_loss: 1.0535 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2362 - m2_21_output_loss: 1.2333 - t1_output_mae: 0.5817 - nu11_output_mae: 1.8732 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2378 - t2_output_mae: 0.5726 - nu21_output_mae: 1.8923 - nu22_output_mae: 1.8488 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6719 - m2_21_output_mae: 0.6549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f47007cc3a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f47007cc3a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db7e2160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46db7e2160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 66s 26ms/step - loss: 78.3903 - t1_output_loss: 0.7726 - nu11_output_loss: 22.7645 - dyn11_output_loss: 0.9051 - s1_output_loss: 0.0771 - t2_output_loss: 0.7653 - nu21_output_loss: 25.0407 - nu22_output_loss: 23.4802 - dyn21_output_loss: 1.0534 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2363 - m2_21_output_loss: 1.2334 - t1_output_mae: 0.5818 - nu11_output_mae: 1.8729 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2378 - t2_output_mae: 0.5726 - nu21_output_mae: 1.8925 - nu22_output_mae: 1.8499 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6720 - m2_21_output_mae: 0.6550 - val_loss: 80.7326 - val_t1_output_loss: 0.8314 - val_nu11_output_loss: 22.4259 - val_dyn11_output_loss: 0.9059 - val_s1_output_loss: 0.0772 - val_t2_output_loss: 0.8202 - val_nu21_output_loss: 25.7661 - val_nu22_output_loss: 24.9194 - val_dyn21_output_loss: 1.0552 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 1.4792 - val_m2_21_output_loss: 1.3922 - val_t1_output_mae: 0.6218 - val_nu11_output_mae: 1.9576 - val_dyn11_output_categorical_accuracy: 0.6321 - val_s1_output_mae: 0.2382 - val_t2_output_mae: 0.6247 - val_nu21_output_mae: 2.3105 - val_nu22_output_mae: 1.9215 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4443 - val_m2_12_output_mae: 0.8278 - val_m2_21_output_mae: 0.6412\n",
      "Epoch 79/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 78.9079 - t1_output_loss: 0.7670 - nu11_output_loss: 22.7144 - dyn11_output_loss: 0.9041 - s1_output_loss: 0.0767 - t2_output_loss: 0.7663 - nu21_output_loss: 25.3515 - nu22_output_loss: 23.7410 - dyn21_output_loss: 1.0540 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2339 - m2_21_output_loss: 1.2381 - t1_output_mae: 0.5788 - nu11_output_mae: 1.8781 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2373 - t2_output_mae: 0.5723 - nu21_output_mae: 1.9064 - nu22_output_mae: 1.8549 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6694 - m2_21_output_mae: 0.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c9419d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c9419d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a337b160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a337b160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 78.8915 - t1_output_loss: 0.7668 - nu11_output_loss: 22.7094 - dyn11_output_loss: 0.9041 - s1_output_loss: 0.0767 - t2_output_loss: 0.7663 - nu21_output_loss: 25.3440 - nu22_output_loss: 23.7375 - dyn21_output_loss: 1.0540 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2337 - m2_21_output_loss: 1.2379 - t1_output_mae: 0.5787 - nu11_output_mae: 1.8780 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2373 - t2_output_mae: 0.5723 - nu21_output_mae: 1.9062 - nu22_output_mae: 1.8549 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6693 - m2_21_output_mae: 0.6546 - val_loss: 88.5533 - val_t1_output_loss: 0.7732 - val_nu11_output_loss: 24.7768 - val_dyn11_output_loss: 0.9019 - val_s1_output_loss: 0.0756 - val_t2_output_loss: 0.8517 - val_nu21_output_loss: 22.5143 - val_nu22_output_loss: 33.9901 - val_dyn21_output_loss: 1.0538 - val_dyn22_output_loss: 1.0587 - val_m2_12_output_loss: 1.2727 - val_m2_21_output_loss: 1.2845 - val_t1_output_mae: 0.6155 - val_nu11_output_mae: 2.1869 - val_dyn11_output_categorical_accuracy: 0.6342 - val_s1_output_mae: 0.2360 - val_t2_output_mae: 0.6405 - val_nu21_output_mae: 1.8231 - val_nu22_output_mae: 3.0146 - val_dyn21_output_categorical_accuracy: 0.4420 - val_dyn22_output_categorical_accuracy: 0.4469 - val_m2_12_output_mae: 0.7326 - val_m2_21_output_mae: 0.6138\n",
      "Epoch 80/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 78.0233 - t1_output_loss: 0.7751 - nu11_output_loss: 22.6078 - dyn11_output_loss: 0.9048 - s1_output_loss: 0.0768 - t2_output_loss: 0.7677 - nu21_output_loss: 25.0833 - nu22_output_loss: 23.2160 - dyn21_output_loss: 1.0531 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2427 - m2_21_output_loss: 1.2346 - t1_output_mae: 0.5825 - nu11_output_mae: 1.8629 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2372 - t2_output_mae: 0.5732 - nu21_output_mae: 1.8772 - nu22_output_mae: 1.8435 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4437 - m2_12_output_mae: 0.6712 - m2_21_output_mae: 0.6537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8aaf0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d8aaf0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469dfb8040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469dfb8040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 21ms/step - loss: 78.0520 - t1_output_loss: 0.7751 - nu11_output_loss: 22.5959 - dyn11_output_loss: 0.9047 - s1_output_loss: 0.0768 - t2_output_loss: 0.7681 - nu21_output_loss: 25.1483 - nu22_output_loss: 23.1917 - dyn21_output_loss: 1.0531 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2423 - m2_21_output_loss: 1.2346 - t1_output_mae: 0.5825 - nu11_output_mae: 1.8623 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2372 - t2_output_mae: 0.5733 - nu21_output_mae: 1.8779 - nu22_output_mae: 1.8425 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6711 - m2_21_output_mae: 0.6537 - val_loss: 79.7153 - val_t1_output_loss: 1.1117 - val_nu11_output_loss: 23.0074 - val_dyn11_output_loss: 0.9015 - val_s1_output_loss: 0.0780 - val_t2_output_loss: 0.8717 - val_nu21_output_loss: 23.7482 - val_nu22_output_loss: 23.6548 - val_dyn21_output_loss: 1.0549 - val_dyn22_output_loss: 1.0598 - val_m2_12_output_loss: 2.9710 - val_m2_21_output_loss: 1.2562 - val_t1_output_mae: 0.8123 - val_nu11_output_mae: 1.8359 - val_dyn11_output_categorical_accuracy: 0.6353 - val_s1_output_mae: 0.2372 - val_t2_output_mae: 0.5423 - val_nu21_output_mae: 1.7045 - val_nu22_output_mae: 1.9687 - val_dyn21_output_categorical_accuracy: 0.4421 - val_dyn22_output_categorical_accuracy: 0.4444 - val_m2_12_output_mae: 1.1741 - val_m2_21_output_mae: 0.7063\n",
      "Epoch 81/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 79.1553 - t1_output_loss: 0.7660 - nu11_output_loss: 23.5418 - dyn11_output_loss: 0.9038 - s1_output_loss: 0.0768 - t2_output_loss: 0.7629 - nu21_output_loss: 25.2583 - nu22_output_loss: 23.2577 - dyn21_output_loss: 1.0532 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2394 - m2_21_output_loss: 1.2343 - t1_output_mae: 0.5785 - nu11_output_mae: 1.8951 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2373 - t2_output_mae: 0.5717 - nu21_output_mae: 1.8880 - nu22_output_mae: 1.8455 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6718 - m2_21_output_mae: 0.6535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d91b70d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d91b70d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0c0e5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a0c0e5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 79.1229 - t1_output_loss: 0.7664 - nu11_output_loss: 23.5392 - dyn11_output_loss: 0.9038 - s1_output_loss: 0.0768 - t2_output_loss: 0.7635 - nu21_output_loss: 25.2418 - nu22_output_loss: 23.2428 - dyn21_output_loss: 1.0532 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2396 - m2_21_output_loss: 1.2346 - t1_output_mae: 0.5786 - nu11_output_mae: 1.8951 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2373 - t2_output_mae: 0.5719 - nu21_output_mae: 1.8874 - nu22_output_mae: 1.8451 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6718 - m2_21_output_mae: 0.6535 - val_loss: 88.4268 - val_t1_output_loss: 0.7974 - val_nu11_output_loss: 24.7423 - val_dyn11_output_loss: 0.9020 - val_s1_output_loss: 0.0764 - val_t2_output_loss: 1.0185 - val_nu21_output_loss: 30.2574 - val_nu22_output_loss: 25.9151 - val_dyn21_output_loss: 1.0548 - val_dyn22_output_loss: 1.0606 - val_m2_12_output_loss: 1.5086 - val_m2_21_output_loss: 1.0935 - val_t1_output_mae: 0.6397 - val_nu11_output_mae: 1.7291 - val_dyn11_output_categorical_accuracy: 0.6319 - val_s1_output_mae: 0.2375 - val_t2_output_mae: 0.5918 - val_nu21_output_mae: 2.6718 - val_nu22_output_mae: 1.7639 - val_dyn21_output_categorical_accuracy: 0.4405 - val_dyn22_output_categorical_accuracy: 0.4426 - val_m2_12_output_mae: 0.6621 - val_m2_21_output_mae: 0.5642\n",
      "Epoch 82/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 77.9161 - t1_output_loss: 0.7726 - nu11_output_loss: 22.4842 - dyn11_output_loss: 0.9048 - s1_output_loss: 0.0770 - t2_output_loss: 0.7629 - nu21_output_loss: 24.9884 - nu22_output_loss: 23.3491 - dyn21_output_loss: 1.0531 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2355 - m2_21_output_loss: 1.2266 - t1_output_mae: 0.5812 - nu11_output_mae: 1.8752 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2375 - t2_output_mae: 0.5712 - nu21_output_mae: 1.8827 - nu22_output_mae: 1.8384 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6691 - m2_21_output_mae: 0.6508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469dc3c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469dc3c040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9887670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9887670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 61s 24ms/step - loss: 77.9809 - t1_output_loss: 0.7725 - nu11_output_loss: 22.4771 - dyn11_output_loss: 0.9047 - s1_output_loss: 0.0770 - t2_output_loss: 0.7628 - nu21_output_loss: 24.9842 - nu22_output_loss: 23.4256 - dyn21_output_loss: 1.0532 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2354 - m2_21_output_loss: 1.2266 - t1_output_mae: 0.5812 - nu11_output_mae: 1.8750 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2375 - t2_output_mae: 0.5712 - nu21_output_mae: 1.8828 - nu22_output_mae: 1.8396 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6691 - m2_21_output_mae: 0.6508 - val_loss: 79.8204 - val_t1_output_loss: 0.7473 - val_nu11_output_loss: 22.6963 - val_dyn11_output_loss: 0.9059 - val_s1_output_loss: 0.0788 - val_t2_output_loss: 1.3446 - val_nu21_output_loss: 23.3317 - val_nu22_output_loss: 24.9243 - val_dyn21_output_loss: 1.0557 - val_dyn22_output_loss: 1.0601 - val_m2_12_output_loss: 1.0623 - val_m2_21_output_loss: 2.6134 - val_t1_output_mae: 0.5697 - val_nu11_output_mae: 1.8065 - val_dyn11_output_categorical_accuracy: 0.6316 - val_s1_output_mae: 0.2417 - val_t2_output_mae: 0.7104 - val_nu21_output_mae: 1.8117 - val_nu22_output_mae: 2.1237 - val_dyn21_output_categorical_accuracy: 0.4412 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.5675 - val_m2_21_output_mae: 1.0575\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 78.7256 - t1_output_loss: 0.7677 - nu11_output_loss: 22.7695 - dyn11_output_loss: 0.9034 - s1_output_loss: 0.0768 - t2_output_loss: 0.7627 - nu21_output_loss: 25.1477 - nu22_output_loss: 23.7190 - dyn21_output_loss: 1.0533 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2297 - m2_21_output_loss: 1.2346 - t1_output_mae: 0.5794 - nu11_output_mae: 1.8761 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2373 - t2_output_mae: 0.5705 - nu21_output_mae: 1.9026 - nu22_output_mae: 1.8343 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6675 - m2_21_output_mae: 0.6514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469eb503a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469eb503a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469eb50040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469eb50040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 56s 22ms/step - loss: 78.7256 - t1_output_loss: 0.7677 - nu11_output_loss: 22.7695 - dyn11_output_loss: 0.9034 - s1_output_loss: 0.0768 - t2_output_loss: 0.7627 - nu21_output_loss: 25.1477 - nu22_output_loss: 23.7190 - dyn21_output_loss: 1.0533 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2297 - m2_21_output_loss: 1.2346 - t1_output_mae: 0.5794 - nu11_output_mae: 1.8761 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2373 - t2_output_mae: 0.5705 - nu21_output_mae: 1.9026 - nu22_output_mae: 1.8343 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6675 - m2_21_output_mae: 0.6514 - val_loss: 82.3244 - val_t1_output_loss: 0.6978 - val_nu11_output_loss: 28.2094 - val_dyn11_output_loss: 0.9040 - val_s1_output_loss: 0.0781 - val_t2_output_loss: 0.7440 - val_nu21_output_loss: 22.5081 - val_nu22_output_loss: 23.8022 - val_dyn21_output_loss: 1.0530 - val_dyn22_output_loss: 1.0587 - val_m2_12_output_loss: 1.6479 - val_m2_21_output_loss: 1.6211 - val_t1_output_mae: 0.5389 - val_nu11_output_mae: 2.9648 - val_dyn11_output_categorical_accuracy: 0.6350 - val_s1_output_mae: 0.2392 - val_t2_output_mae: 0.5340 - val_nu21_output_mae: 1.7943 - val_nu22_output_mae: 1.9890 - val_dyn21_output_categorical_accuracy: 0.4424 - val_dyn22_output_categorical_accuracy: 0.4471 - val_m2_12_output_mae: 0.7073 - val_m2_21_output_mae: 0.6570\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 77.7076 - t1_output_loss: 0.7747 - nu11_output_loss: 22.4888 - dyn11_output_loss: 0.9039 - s1_output_loss: 0.0768 - t2_output_loss: 0.7664 - nu21_output_loss: 24.9992 - nu22_output_loss: 23.1321 - dyn21_output_loss: 1.0531 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2285 - m2_21_output_loss: 1.2225 - t1_output_mae: 0.5813 - nu11_output_mae: 1.8545 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2371 - t2_output_mae: 0.5728 - nu21_output_mae: 1.8820 - nu22_output_mae: 1.8431 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6674 - m2_21_output_mae: 0.6512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d998ad30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d998ad30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8f90160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c8f90160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 60s 24ms/step - loss: 77.7076 - t1_output_loss: 0.7747 - nu11_output_loss: 22.4888 - dyn11_output_loss: 0.9039 - s1_output_loss: 0.0768 - t2_output_loss: 0.7664 - nu21_output_loss: 24.9992 - nu22_output_loss: 23.1321 - dyn21_output_loss: 1.0531 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2285 - m2_21_output_loss: 1.2225 - t1_output_mae: 0.5813 - nu11_output_mae: 1.8545 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2371 - t2_output_mae: 0.5728 - nu21_output_mae: 1.8820 - nu22_output_mae: 1.8431 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6674 - m2_21_output_mae: 0.6512 - val_loss: 85.2867 - val_t1_output_loss: 0.8135 - val_nu11_output_loss: 23.8182 - val_dyn11_output_loss: 0.8981 - val_s1_output_loss: 0.0791 - val_t2_output_loss: 1.2995 - val_nu21_output_loss: 25.0768 - val_nu22_output_loss: 27.6810 - val_dyn21_output_loss: 1.0537 - val_dyn22_output_loss: 1.0597 - val_m2_12_output_loss: 2.1766 - val_m2_21_output_loss: 1.3305 - val_t1_output_mae: 0.5980 - val_nu11_output_mae: 1.6648 - val_dyn11_output_categorical_accuracy: 0.6348 - val_s1_output_mae: 0.2382 - val_t2_output_mae: 0.6870 - val_nu21_output_mae: 1.6077 - val_nu22_output_mae: 2.5752 - val_dyn21_output_categorical_accuracy: 0.4416 - val_dyn22_output_categorical_accuracy: 0.4445 - val_m2_12_output_mae: 1.0175 - val_m2_21_output_mae: 0.6103\n",
      "Epoch 85/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 79.2220 - t1_output_loss: 0.7619 - nu11_output_loss: 23.6068 - dyn11_output_loss: 0.9033 - s1_output_loss: 0.0767 - t2_output_loss: 0.7604 - nu21_output_loss: 25.2704 - nu22_output_loss: 23.2790 - dyn21_output_loss: 1.0529 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2226 - m2_21_output_loss: 1.2266 - t1_output_mae: 0.5762 - nu11_output_mae: 1.9035 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2370 - t2_output_mae: 0.5703 - nu21_output_mae: 1.8785 - nu22_output_mae: 1.8478 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6669 - m2_21_output_mae: 0.6506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d80fd040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d80fd040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3916430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a3916430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 61s 24ms/step - loss: 79.2051 - t1_output_loss: 0.7619 - nu11_output_loss: 23.6064 - dyn11_output_loss: 0.9033 - s1_output_loss: 0.0767 - t2_output_loss: 0.7606 - nu21_output_loss: 25.2620 - nu22_output_loss: 23.2709 - dyn21_output_loss: 1.0529 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2226 - m2_21_output_loss: 1.2263 - t1_output_mae: 0.5762 - nu11_output_mae: 1.9034 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2370 - t2_output_mae: 0.5704 - nu21_output_mae: 1.8782 - nu22_output_mae: 1.8476 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6670 - m2_21_output_mae: 0.6505 - val_loss: 81.1817 - val_t1_output_loss: 0.8095 - val_nu11_output_loss: 24.0284 - val_dyn11_output_loss: 0.9021 - val_s1_output_loss: 0.0788 - val_t2_output_loss: 0.9972 - val_nu21_output_loss: 22.6391 - val_nu22_output_loss: 25.7603 - val_dyn21_output_loss: 1.0548 - val_dyn22_output_loss: 1.0603 - val_m2_12_output_loss: 2.9155 - val_m2_21_output_loss: 0.9358 - val_t1_output_mae: 0.6418 - val_nu11_output_mae: 1.7506 - val_dyn11_output_categorical_accuracy: 0.6321 - val_s1_output_mae: 0.2410 - val_t2_output_mae: 0.7320 - val_nu21_output_mae: 1.9189 - val_nu22_output_mae: 1.7724 - val_dyn21_output_categorical_accuracy: 0.4405 - val_dyn22_output_categorical_accuracy: 0.4435 - val_m2_12_output_mae: 1.1733 - val_m2_21_output_mae: 0.5536\n",
      "Epoch 86/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 77.3240 - t1_output_loss: 0.7658 - nu11_output_loss: 22.4335 - dyn11_output_loss: 0.9043 - s1_output_loss: 0.0769 - t2_output_loss: 0.7579 - nu21_output_loss: 24.8958 - nu22_output_loss: 22.9292 - dyn21_output_loss: 1.0529 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2253 - m2_21_output_loss: 1.2206 - t1_output_mae: 0.5794 - nu11_output_mae: 1.8638 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2376 - t2_output_mae: 0.5690 - nu21_output_mae: 1.8765 - nu22_output_mae: 1.8271 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6661 - m2_21_output_mae: 0.6495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a35ff040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a35ff040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c99af5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c99af5e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 54s 21ms/step - loss: 77.3535 - t1_output_loss: 0.7661 - nu11_output_loss: 22.4175 - dyn11_output_loss: 0.9043 - s1_output_loss: 0.0769 - t2_output_loss: 0.7578 - nu21_output_loss: 24.8868 - nu22_output_loss: 22.9831 - dyn21_output_loss: 1.0529 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2256 - m2_21_output_loss: 1.2206 - t1_output_mae: 0.5794 - nu11_output_mae: 1.8633 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2376 - t2_output_mae: 0.5690 - nu21_output_mae: 1.8761 - nu22_output_mae: 1.8278 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6663 - m2_21_output_mae: 0.6496 - val_loss: 101.3077 - val_t1_output_loss: 0.7365 - val_nu11_output_loss: 22.6853 - val_dyn11_output_loss: 0.9118 - val_s1_output_loss: 0.0789 - val_t2_output_loss: 0.8533 - val_nu21_output_loss: 45.6296 - val_nu22_output_loss: 25.2239 - val_dyn21_output_loss: 1.0555 - val_dyn22_output_loss: 1.0603 - val_m2_12_output_loss: 1.9699 - val_m2_21_output_loss: 1.1027 - val_t1_output_mae: 0.5717 - val_nu11_output_mae: 1.8144 - val_dyn11_output_categorical_accuracy: 0.6313 - val_s1_output_mae: 0.2414 - val_t2_output_mae: 0.5518 - val_nu21_output_mae: 4.2804 - val_nu22_output_mae: 1.7773 - val_dyn21_output_categorical_accuracy: 0.4412 - val_dyn22_output_categorical_accuracy: 0.4435 - val_m2_12_output_mae: 0.9746 - val_m2_21_output_mae: 0.6086\n",
      "Epoch 87/100\n",
      "2497/2500 [============================>.] - ETA: 0s - loss: 78.2299 - t1_output_loss: 0.7650 - nu11_output_loss: 22.3801 - dyn11_output_loss: 0.9029 - s1_output_loss: 0.0767 - t2_output_loss: 0.7648 - nu21_output_loss: 25.2028 - nu22_output_loss: 23.5733 - dyn21_output_loss: 1.0528 - dyn22_output_loss: 1.0611 - m2_12_output_loss: 1.2286 - m2_21_output_loss: 1.2220 - t1_output_mae: 0.5779 - nu11_output_mae: 1.8630 - dyn11_output_categorical_accuracy: 0.6309 - s1_output_mae: 0.2370 - t2_output_mae: 0.5717 - nu21_output_mae: 1.8951 - nu22_output_mae: 1.8405 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6677 - m2_21_output_mae: 0.6491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46daeb5ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46daeb5ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da570280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46da570280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 65s 26ms/step - loss: 78.1809 - t1_output_loss: 0.7648 - nu11_output_loss: 22.3700 - dyn11_output_loss: 0.9028 - s1_output_loss: 0.0766 - t2_output_loss: 0.7648 - nu21_output_loss: 25.1776 - nu22_output_loss: 23.5601 - dyn21_output_loss: 1.0528 - dyn22_output_loss: 1.0611 - m2_12_output_loss: 1.2283 - m2_21_output_loss: 1.2222 - t1_output_mae: 0.5779 - nu11_output_mae: 1.8630 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2370 - t2_output_mae: 0.5718 - nu21_output_mae: 1.8942 - nu22_output_mae: 1.8405 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6676 - m2_21_output_mae: 0.6491 - val_loss: 86.9324 - val_t1_output_loss: 0.7814 - val_nu11_output_loss: 29.4418 - val_dyn11_output_loss: 0.9000 - val_s1_output_loss: 0.0763 - val_t2_output_loss: 0.8628 - val_nu21_output_loss: 23.2781 - val_nu22_output_loss: 26.2115 - val_dyn21_output_loss: 1.0529 - val_dyn22_output_loss: 1.0586 - val_m2_12_output_loss: 2.1662 - val_m2_21_output_loss: 1.1026 - val_t1_output_mae: 0.6284 - val_nu11_output_mae: 3.1689 - val_dyn11_output_categorical_accuracy: 0.6345 - val_s1_output_mae: 0.2377 - val_t2_output_mae: 0.5522 - val_nu21_output_mae: 2.1398 - val_nu22_output_mae: 2.3038 - val_dyn21_output_categorical_accuracy: 0.4423 - val_dyn22_output_categorical_accuracy: 0.4470 - val_m2_12_output_mae: 0.9786 - val_m2_21_output_mae: 0.5595\n",
      "Epoch 88/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 77.5026 - t1_output_loss: 0.7696 - nu11_output_loss: 22.5192 - dyn11_output_loss: 0.9029 - s1_output_loss: 0.0767 - t2_output_loss: 0.7693 - nu21_output_loss: 24.8234 - nu22_output_loss: 23.0860 - dyn21_output_loss: 1.0529 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2129 - m2_21_output_loss: 1.2283 - t1_output_mae: 0.5786 - nu11_output_mae: 1.8573 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2371 - t2_output_mae: 0.5739 - nu21_output_mae: 1.8688 - nu22_output_mae: 1.8428 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6623 - m2_21_output_mae: 0.6521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46db145ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46db145ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9f94160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46d9f94160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 61s 24ms/step - loss: 77.5797 - t1_output_loss: 0.7696 - nu11_output_loss: 22.5260 - dyn11_output_loss: 0.9029 - s1_output_loss: 0.0767 - t2_output_loss: 0.7694 - nu21_output_loss: 24.9014 - nu22_output_loss: 23.0776 - dyn21_output_loss: 1.0529 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2128 - m2_21_output_loss: 1.2288 - t1_output_mae: 0.5786 - nu11_output_mae: 1.8574 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2371 - t2_output_mae: 0.5739 - nu21_output_mae: 1.8697 - nu22_output_mae: 1.8425 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6622 - m2_21_output_mae: 0.6522 - val_loss: 90.2186 - val_t1_output_loss: 0.7380 - val_nu11_output_loss: 23.1362 - val_dyn11_output_loss: 0.8987 - val_s1_output_loss: 0.0754 - val_t2_output_loss: 1.2349 - val_nu21_output_loss: 27.9942 - val_nu22_output_loss: 32.2997 - val_dyn21_output_loss: 1.0538 - val_dyn22_output_loss: 1.0600 - val_m2_12_output_loss: 0.8844 - val_m2_21_output_loss: 0.8433 - val_t1_output_mae: 0.5735 - val_nu11_output_mae: 1.8048 - val_dyn11_output_categorical_accuracy: 0.6350 - val_s1_output_mae: 0.2349 - val_t2_output_mae: 0.8572 - val_nu21_output_mae: 2.7602 - val_nu22_output_mae: 2.8079 - val_dyn21_output_categorical_accuracy: 0.4415 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.5542 - val_m2_21_output_mae: 0.5206\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 78.5305 - t1_output_loss: 0.7570 - nu11_output_loss: 23.4390 - dyn11_output_loss: 0.9030 - s1_output_loss: 0.0766 - t2_output_loss: 0.7594 - nu21_output_loss: 24.8636 - nu22_output_loss: 23.1959 - dyn21_output_loss: 1.0527 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2096 - m2_21_output_loss: 1.2124 - t1_output_mae: 0.5746 - nu11_output_mae: 1.8851 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2370 - t2_output_mae: 0.5698 - nu21_output_mae: 1.8776 - nu22_output_mae: 1.8416 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6625 - m2_21_output_mae: 0.6471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d9e1d0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d9e1d0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46caa16ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46caa16ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 53s 21ms/step - loss: 78.5305 - t1_output_loss: 0.7570 - nu11_output_loss: 23.4390 - dyn11_output_loss: 0.9030 - s1_output_loss: 0.0766 - t2_output_loss: 0.7594 - nu21_output_loss: 24.8636 - nu22_output_loss: 23.1959 - dyn21_output_loss: 1.0527 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2096 - m2_21_output_loss: 1.2124 - t1_output_mae: 0.5746 - nu11_output_mae: 1.8851 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2370 - t2_output_mae: 0.5698 - nu21_output_mae: 1.8776 - nu22_output_mae: 1.8416 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6625 - m2_21_output_mae: 0.6471 - val_loss: 81.6829 - val_t1_output_loss: 0.8161 - val_nu11_output_loss: 24.2699 - val_dyn11_output_loss: 0.9444 - val_s1_output_loss: 0.0775 - val_t2_output_loss: 0.8821 - val_nu21_output_loss: 22.7757 - val_nu22_output_loss: 25.6602 - val_dyn21_output_loss: 1.0545 - val_dyn22_output_loss: 1.0601 - val_m2_12_output_loss: 0.9665 - val_m2_21_output_loss: 3.1757 - val_t1_output_mae: 0.6399 - val_nu11_output_mae: 1.7579 - val_dyn11_output_categorical_accuracy: 0.6317 - val_s1_output_mae: 0.2399 - val_t2_output_mae: 0.6525 - val_nu21_output_mae: 1.5879 - val_nu22_output_mae: 2.1348 - val_dyn21_output_categorical_accuracy: 0.4409 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.5823 - val_m2_21_output_mae: 1.1638\n",
      "Epoch 90/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 77.4604 - t1_output_loss: 0.7621 - nu11_output_loss: 22.3323 - dyn11_output_loss: 0.9040 - s1_output_loss: 0.0767 - t2_output_loss: 0.7571 - nu21_output_loss: 24.8488 - nu22_output_loss: 23.2281 - dyn21_output_loss: 1.0523 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2271 - m2_21_output_loss: 1.2100 - t1_output_mae: 0.5770 - nu11_output_mae: 1.8589 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2371 - t2_output_mae: 0.5684 - nu21_output_mae: 1.8868 - nu22_output_mae: 1.8315 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6666 - m2_21_output_mae: 0.6470"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a38820d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a38820d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a27f9430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a27f9430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 65s 26ms/step - loss: 77.5229 - t1_output_loss: 0.7620 - nu11_output_loss: 22.3260 - dyn11_output_loss: 0.9040 - s1_output_loss: 0.0767 - t2_output_loss: 0.7570 - nu21_output_loss: 24.8441 - nu22_output_loss: 23.3020 - dyn21_output_loss: 1.0523 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2270 - m2_21_output_loss: 1.2099 - t1_output_mae: 0.5770 - nu11_output_mae: 1.8588 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2371 - t2_output_mae: 0.5683 - nu21_output_mae: 1.8867 - nu22_output_mae: 1.8326 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6665 - m2_21_output_mae: 0.6470 - val_loss: 78.8922 - val_t1_output_loss: 0.8054 - val_nu11_output_loss: 22.7497 - val_dyn11_output_loss: 0.8999 - val_s1_output_loss: 0.0802 - val_t2_output_loss: 1.1543 - val_nu21_output_loss: 23.5490 - val_nu22_output_loss: 23.7427 - val_dyn21_output_loss: 1.0543 - val_dyn22_output_loss: 1.0603 - val_m2_12_output_loss: 2.4784 - val_m2_21_output_loss: 1.3179 - val_t1_output_mae: 0.6138 - val_nu11_output_mae: 2.1174 - val_dyn11_output_categorical_accuracy: 0.6326 - val_s1_output_mae: 0.2435 - val_t2_output_mae: 0.6221 - val_nu21_output_mae: 1.9344 - val_nu22_output_mae: 1.7754 - val_dyn21_output_categorical_accuracy: 0.4409 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 1.1065 - val_m2_21_output_mae: 0.6697\n",
      "Epoch 91/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 78.5404 - t1_output_loss: 0.7588 - nu11_output_loss: 22.6173 - dyn11_output_loss: 0.9024 - s1_output_loss: 0.0765 - t2_output_loss: 0.7581 - nu21_output_loss: 25.2584 - nu22_output_loss: 23.6412 - dyn21_output_loss: 1.0524 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2115 - m2_21_output_loss: 1.2027 - t1_output_mae: 0.5753 - nu11_output_mae: 1.8634 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2366 - t2_output_mae: 0.5682 - nu21_output_mae: 1.8904 - nu22_output_mae: 1.8378 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 0.6636 - m2_21_output_mae: 0.6455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca472ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46ca472ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469adf3ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f469adf3ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 56s 22ms/step - loss: 78.5015 - t1_output_loss: 0.7586 - nu11_output_loss: 22.6038 - dyn11_output_loss: 0.9024 - s1_output_loss: 0.0765 - t2_output_loss: 0.7579 - nu21_output_loss: 25.2426 - nu22_output_loss: 23.6329 - dyn21_output_loss: 1.0524 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.2111 - m2_21_output_loss: 1.2023 - t1_output_mae: 0.5752 - nu11_output_mae: 1.8630 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2366 - t2_output_mae: 0.5682 - nu21_output_mae: 1.8901 - nu22_output_mae: 1.8380 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6634 - m2_21_output_mae: 0.6453 - val_loss: 82.0051 - val_t1_output_loss: 1.0236 - val_nu11_output_loss: 25.8564 - val_dyn11_output_loss: 0.9017 - val_s1_output_loss: 0.0765 - val_t2_output_loss: 1.1349 - val_nu21_output_loss: 22.9388 - val_nu22_output_loss: 24.1857 - val_dyn21_output_loss: 1.0520 - val_dyn22_output_loss: 1.0587 - val_m2_12_output_loss: 1.5204 - val_m2_21_output_loss: 2.2566 - val_t1_output_mae: 0.7198 - val_nu11_output_mae: 2.5357 - val_dyn11_output_categorical_accuracy: 0.6348 - val_s1_output_mae: 0.2368 - val_t2_output_mae: 0.6142 - val_nu21_output_mae: 1.9352 - val_nu22_output_mae: 2.0553 - val_dyn21_output_categorical_accuracy: 0.4428 - val_dyn22_output_categorical_accuracy: 0.4466 - val_m2_12_output_mae: 0.6637 - val_m2_21_output_mae: 0.8976\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 77.2102 - t1_output_loss: 0.7631 - nu11_output_loss: 22.4638 - dyn11_output_loss: 0.9027 - s1_output_loss: 0.0765 - t2_output_loss: 0.7616 - nu21_output_loss: 24.7157 - nu22_output_loss: 22.9937 - dyn21_output_loss: 1.0525 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2125 - m2_21_output_loss: 1.2066 - t1_output_mae: 0.5779 - nu11_output_mae: 1.8519 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2365 - t2_output_mae: 0.5706 - nu21_output_mae: 1.8605 - nu22_output_mae: 1.8332 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6615 - m2_21_output_mae: 0.6468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469ae051f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469ae051f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a22f5ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a22f5ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 58s 23ms/step - loss: 77.2102 - t1_output_loss: 0.7631 - nu11_output_loss: 22.4638 - dyn11_output_loss: 0.9027 - s1_output_loss: 0.0765 - t2_output_loss: 0.7616 - nu21_output_loss: 24.7157 - nu22_output_loss: 22.9937 - dyn21_output_loss: 1.0525 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2125 - m2_21_output_loss: 1.2066 - t1_output_mae: 0.5779 - nu11_output_mae: 1.8519 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2365 - t2_output_mae: 0.5706 - nu21_output_mae: 1.8605 - nu22_output_mae: 1.8332 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6615 - m2_21_output_mae: 0.6468 - val_loss: 77.0763 - val_t1_output_loss: 0.7840 - val_nu11_output_loss: 22.8954 - val_dyn11_output_loss: 0.8969 - val_s1_output_loss: 0.0780 - val_t2_output_loss: 0.7980 - val_nu21_output_loss: 23.5339 - val_nu22_output_loss: 24.0859 - val_dyn21_output_loss: 1.0536 - val_dyn22_output_loss: 1.0599 - val_m2_12_output_loss: 0.9088 - val_m2_21_output_loss: 0.9819 - val_t1_output_mae: 0.5673 - val_nu11_output_mae: 1.8264 - val_dyn11_output_categorical_accuracy: 0.6346 - val_s1_output_mae: 0.2382 - val_t2_output_mae: 0.5981 - val_nu21_output_mae: 1.6768 - val_nu22_output_mae: 2.1584 - val_dyn21_output_categorical_accuracy: 0.4412 - val_dyn22_output_categorical_accuracy: 0.4439 - val_m2_12_output_mae: 0.5825 - val_m2_21_output_mae: 0.5427\n",
      "Epoch 93/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 78.5601 - t1_output_loss: 0.7551 - nu11_output_loss: 23.4092 - dyn11_output_loss: 0.9022 - s1_output_loss: 0.0762 - t2_output_loss: 0.7612 - nu21_output_loss: 25.0239 - nu22_output_loss: 23.1186 - dyn21_output_loss: 1.0525 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2024 - m2_21_output_loss: 1.1974 - t1_output_mae: 0.5737 - nu11_output_mae: 1.8880 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2362 - t2_output_mae: 0.5706 - nu21_output_mae: 1.8754 - nu22_output_mae: 1.8392 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6607 - m2_21_output_mae: 0.6442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a22f5e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a22f5e50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4703926af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f4703926af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 63s 25ms/step - loss: 78.5433 - t1_output_loss: 0.7551 - nu11_output_loss: 23.4086 - dyn11_output_loss: 0.9023 - s1_output_loss: 0.0762 - t2_output_loss: 0.7614 - nu21_output_loss: 25.0154 - nu22_output_loss: 23.1110 - dyn21_output_loss: 1.0525 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.2024 - m2_21_output_loss: 1.1972 - t1_output_mae: 0.5737 - nu11_output_mae: 1.8879 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2362 - t2_output_mae: 0.5707 - nu21_output_mae: 1.8751 - nu22_output_mae: 1.8390 - dyn21_output_categorical_accuracy: 0.4471 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6608 - m2_21_output_mae: 0.6442 - val_loss: 81.8713 - val_t1_output_loss: 1.1213 - val_nu11_output_loss: 23.9981 - val_dyn11_output_loss: 0.9079 - val_s1_output_loss: 0.0803 - val_t2_output_loss: 0.7931 - val_nu21_output_loss: 25.6150 - val_nu22_output_loss: 25.0657 - val_dyn21_output_loss: 1.0536 - val_dyn22_output_loss: 1.0604 - val_m2_12_output_loss: 1.2797 - val_m2_21_output_loss: 0.8962 - val_t1_output_mae: 0.8222 - val_nu11_output_mae: 1.9667 - val_dyn11_output_categorical_accuracy: 0.6313 - val_s1_output_mae: 0.2405 - val_t2_output_mae: 0.5813 - val_nu21_output_mae: 2.2386 - val_nu22_output_mae: 2.0836 - val_dyn21_output_categorical_accuracy: 0.4406 - val_dyn22_output_categorical_accuracy: 0.4437 - val_m2_12_output_mae: 0.6701 - val_m2_21_output_mae: 0.5559\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 77.3838 - t1_output_loss: 0.7595 - nu11_output_loss: 22.4488 - dyn11_output_loss: 0.9031 - s1_output_loss: 0.0766 - t2_output_loss: 0.7538 - nu21_output_loss: 24.7435 - nu22_output_loss: 23.1852 - dyn21_output_loss: 1.0520 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2112 - m2_21_output_loss: 1.1882 - t1_output_mae: 0.5745 - nu11_output_mae: 1.8600 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2368 - t2_output_mae: 0.5669 - nu21_output_mae: 1.8668 - nu22_output_mae: 1.8278 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6621 - m2_21_output_mae: 0.6390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46997b5040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46997b5040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c806fca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c806fca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 55s 22ms/step - loss: 77.3838 - t1_output_loss: 0.7595 - nu11_output_loss: 22.4488 - dyn11_output_loss: 0.9031 - s1_output_loss: 0.0766 - t2_output_loss: 0.7538 - nu21_output_loss: 24.7435 - nu22_output_loss: 23.1852 - dyn21_output_loss: 1.0520 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2112 - m2_21_output_loss: 1.1882 - t1_output_mae: 0.5745 - nu11_output_mae: 1.8600 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2368 - t2_output_mae: 0.5669 - nu21_output_mae: 1.8668 - nu22_output_mae: 1.8278 - dyn21_output_categorical_accuracy: 0.4485 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6621 - m2_21_output_mae: 0.6390 - val_loss: 76.9426 - val_t1_output_loss: 0.8914 - val_nu11_output_loss: 22.1803 - val_dyn11_output_loss: 0.9035 - val_s1_output_loss: 0.0776 - val_t2_output_loss: 1.0615 - val_nu21_output_loss: 22.7248 - val_nu22_output_loss: 24.9013 - val_dyn21_output_loss: 1.0540 - val_dyn22_output_loss: 1.0602 - val_m2_12_output_loss: 1.1425 - val_m2_21_output_loss: 0.9455 - val_t1_output_mae: 0.6576 - val_nu11_output_mae: 1.8061 - val_dyn11_output_categorical_accuracy: 0.6327 - val_s1_output_mae: 0.2390 - val_t2_output_mae: 0.6231 - val_nu21_output_mae: 1.6276 - val_nu22_output_mae: 2.2093 - val_dyn21_output_categorical_accuracy: 0.4411 - val_dyn22_output_categorical_accuracy: 0.4441 - val_m2_12_output_mae: 0.6885 - val_m2_21_output_mae: 0.5316\n",
      "Epoch 95/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 77.5577 - t1_output_loss: 0.7594 - nu11_output_loss: 22.3294 - dyn11_output_loss: 0.9021 - s1_output_loss: 0.0762 - t2_output_loss: 0.7554 - nu21_output_loss: 24.8442 - nu22_output_loss: 23.3795 - dyn21_output_loss: 1.0524 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.1984 - m2_21_output_loss: 1.1996 - t1_output_mae: 0.5751 - nu11_output_mae: 1.8569 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2361 - t2_output_mae: 0.5656 - nu21_output_mae: 1.8837 - nu22_output_mae: 1.8369 - dyn21_output_categorical_accuracy: 0.4477 - dyn22_output_categorical_accuracy: 0.4445 - m2_12_output_mae: 0.6601 - m2_21_output_mae: 0.6443"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a3a7f0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46a3a7f0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c95fcca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c95fcca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 59s 23ms/step - loss: 77.5189 - t1_output_loss: 0.7591 - nu11_output_loss: 22.3145 - dyn11_output_loss: 0.9020 - s1_output_loss: 0.0762 - t2_output_loss: 0.7554 - nu21_output_loss: 24.8290 - nu22_output_loss: 23.3718 - dyn21_output_loss: 1.0524 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.1981 - m2_21_output_loss: 1.1993 - t1_output_mae: 0.5750 - nu11_output_mae: 1.8564 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2361 - t2_output_mae: 0.5656 - nu21_output_mae: 1.8833 - nu22_output_mae: 1.8368 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6600 - m2_21_output_mae: 0.6441 - val_loss: 82.8623 - val_t1_output_loss: 0.7238 - val_nu11_output_loss: 24.4267 - val_dyn11_output_loss: 0.8972 - val_s1_output_loss: 0.0753 - val_t2_output_loss: 1.2758 - val_nu21_output_loss: 23.3182 - val_nu22_output_loss: 25.0262 - val_dyn21_output_loss: 1.0520 - val_dyn22_output_loss: 1.0589 - val_m2_12_output_loss: 3.4689 - val_m2_21_output_loss: 1.5393 - val_t1_output_mae: 0.5477 - val_nu11_output_mae: 2.1913 - val_dyn11_output_categorical_accuracy: 0.6351 - val_s1_output_mae: 0.2357 - val_t2_output_mae: 0.6936 - val_nu21_output_mae: 2.0361 - val_nu22_output_mae: 2.2543 - val_dyn21_output_categorical_accuracy: 0.4426 - val_dyn22_output_categorical_accuracy: 0.4464 - val_m2_12_output_mae: 1.2997 - val_m2_21_output_mae: 0.6516\n",
      "Epoch 96/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 76.8515 - t1_output_loss: 0.7675 - nu11_output_loss: 22.6082 - dyn11_output_loss: 0.9023 - s1_output_loss: 0.0766 - t2_output_loss: 0.7596 - nu21_output_loss: 24.4725 - nu22_output_loss: 22.7450 - dyn21_output_loss: 1.0522 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2069 - m2_21_output_loss: 1.1990 - t1_output_mae: 0.5779 - nu11_output_mae: 1.8563 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2366 - t2_output_mae: 0.5694 - nu21_output_mae: 1.8563 - nu22_output_mae: 1.8336 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6603 - m2_21_output_mae: 0.6445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c8763040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c8763040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c95fcc10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c95fcc10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 76.9225 - t1_output_loss: 0.7676 - nu11_output_loss: 22.6102 - dyn11_output_loss: 0.9024 - s1_output_loss: 0.0766 - t2_output_loss: 0.7597 - nu21_output_loss: 24.5495 - nu22_output_loss: 22.7364 - dyn21_output_loss: 1.0522 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.2069 - m2_21_output_loss: 1.1996 - t1_output_mae: 0.5779 - nu11_output_mae: 1.8562 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2366 - t2_output_mae: 0.5695 - nu21_output_mae: 1.8571 - nu22_output_mae: 1.8331 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6603 - m2_21_output_mae: 0.6445 - val_loss: 77.8785 - val_t1_output_loss: 0.7263 - val_nu11_output_loss: 22.9605 - val_dyn11_output_loss: 0.8976 - val_s1_output_loss: 0.0791 - val_t2_output_loss: 1.0281 - val_nu21_output_loss: 23.2301 - val_nu22_output_loss: 23.2711 - val_dyn21_output_loss: 1.0529 - val_dyn22_output_loss: 1.0595 - val_m2_12_output_loss: 0.9925 - val_m2_21_output_loss: 2.5808 - val_t1_output_mae: 0.5699 - val_nu11_output_mae: 2.0477 - val_dyn11_output_categorical_accuracy: 0.6350 - val_s1_output_mae: 0.2395 - val_t2_output_mae: 0.6025 - val_nu21_output_mae: 1.6652 - val_nu22_output_mae: 1.8434 - val_dyn21_output_categorical_accuracy: 0.4416 - val_dyn22_output_categorical_accuracy: 0.4444 - val_m2_12_output_mae: 0.5482 - val_m2_21_output_mae: 0.9883\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 77.8912 - t1_output_loss: 0.7565 - nu11_output_loss: 23.1885 - dyn11_output_loss: 0.9021 - s1_output_loss: 0.0765 - t2_output_loss: 0.7553 - nu21_output_loss: 24.8263 - nu22_output_loss: 22.8764 - dyn21_output_loss: 1.0525 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.1962 - m2_21_output_loss: 1.1996 - t1_output_mae: 0.5742 - nu11_output_mae: 1.8763 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2367 - t2_output_mae: 0.5680 - nu21_output_mae: 1.8675 - nu22_output_mae: 1.8334 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6575 - m2_21_output_mae: 0.6422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469fffcdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f469fffcdc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9f26670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c9f26670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 55s 22ms/step - loss: 77.8912 - t1_output_loss: 0.7565 - nu11_output_loss: 23.1885 - dyn11_output_loss: 0.9021 - s1_output_loss: 0.0765 - t2_output_loss: 0.7553 - nu21_output_loss: 24.8263 - nu22_output_loss: 22.8764 - dyn21_output_loss: 1.0525 - dyn22_output_loss: 1.0612 - m2_12_output_loss: 1.1962 - m2_21_output_loss: 1.1996 - t1_output_mae: 0.5742 - nu11_output_mae: 1.8763 - dyn11_output_categorical_accuracy: 0.6311 - s1_output_mae: 0.2367 - t2_output_mae: 0.5680 - nu21_output_mae: 1.8675 - nu22_output_mae: 1.8334 - dyn21_output_categorical_accuracy: 0.4472 - dyn22_output_categorical_accuracy: 0.4441 - m2_12_output_mae: 0.6575 - m2_21_output_mae: 0.6422 - val_loss: 78.8767 - val_t1_output_loss: 0.8222 - val_nu11_output_loss: 23.7766 - val_dyn11_output_loss: 0.9002 - val_s1_output_loss: 0.0780 - val_t2_output_loss: 0.8066 - val_nu21_output_loss: 23.7169 - val_nu22_output_loss: 24.5612 - val_dyn21_output_loss: 1.0534 - val_dyn22_output_loss: 1.0607 - val_m2_12_output_loss: 1.1112 - val_m2_21_output_loss: 0.9896 - val_t1_output_mae: 0.6491 - val_nu11_output_mae: 1.8341 - val_dyn11_output_categorical_accuracy: 0.6303 - val_s1_output_mae: 0.2386 - val_t2_output_mae: 0.6110 - val_nu21_output_mae: 2.0322 - val_nu22_output_mae: 1.8340 - val_dyn21_output_categorical_accuracy: 0.4403 - val_dyn22_output_categorical_accuracy: 0.4433 - val_m2_12_output_mae: 0.5825 - val_m2_21_output_mae: 0.5836\n",
      "Epoch 98/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 76.8512 - t1_output_loss: 0.7610 - nu11_output_loss: 22.3184 - dyn11_output_loss: 0.9028 - s1_output_loss: 0.0764 - t2_output_loss: 0.7487 - nu21_output_loss: 24.3621 - nu22_output_loss: 23.1594 - dyn21_output_loss: 1.0524 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2107 - m2_21_output_loss: 1.1974 - t1_output_mae: 0.5753 - nu11_output_mae: 1.8614 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2362 - t2_output_mae: 0.5649 - nu21_output_mae: 1.8539 - nu22_output_mae: 1.8276 - dyn21_output_categorical_accuracy: 0.4487 - dyn22_output_categorical_accuracy: 0.4428 - m2_12_output_mae: 0.6600 - m2_21_output_mae: 0.6413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d992b0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46d992b0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a25935e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a25935e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 64s 26ms/step - loss: 76.9080 - t1_output_loss: 0.7609 - nu11_output_loss: 22.3107 - dyn11_output_loss: 0.9027 - s1_output_loss: 0.0764 - t2_output_loss: 0.7486 - nu21_output_loss: 24.3559 - nu22_output_loss: 23.2306 - dyn21_output_loss: 1.0524 - dyn22_output_loss: 1.0618 - m2_12_output_loss: 1.2105 - m2_21_output_loss: 1.1974 - t1_output_mae: 0.5752 - nu11_output_mae: 1.8612 - dyn11_output_categorical_accuracy: 0.6302 - s1_output_mae: 0.2362 - t2_output_mae: 0.5648 - nu21_output_mae: 1.8539 - nu22_output_mae: 1.8286 - dyn21_output_categorical_accuracy: 0.4486 - dyn22_output_categorical_accuracy: 0.4427 - m2_12_output_mae: 0.6599 - m2_21_output_mae: 0.6413 - val_loss: 87.7390 - val_t1_output_loss: 0.7132 - val_nu11_output_loss: 22.1288 - val_dyn11_output_loss: 0.9013 - val_s1_output_loss: 0.0759 - val_t2_output_loss: 1.3511 - val_nu21_output_loss: 22.8110 - val_nu22_output_loss: 34.2891 - val_dyn21_output_loss: 1.0528 - val_dyn22_output_loss: 1.0602 - val_m2_12_output_loss: 2.2600 - val_m2_21_output_loss: 1.0955 - val_t1_output_mae: 0.5384 - val_nu11_output_mae: 2.0063 - val_dyn11_output_categorical_accuracy: 0.6329 - val_s1_output_mae: 0.2367 - val_t2_output_mae: 0.7238 - val_nu21_output_mae: 1.6633 - val_nu22_output_mae: 3.1835 - val_dyn21_output_categorical_accuracy: 0.4417 - val_dyn22_output_categorical_accuracy: 0.4440 - val_m2_12_output_mae: 1.0477 - val_m2_21_output_mae: 0.6299\n",
      "Epoch 99/100\n",
      "2499/2500 [============================>.] - ETA: 0s - loss: 77.7244 - t1_output_loss: 0.7561 - nu11_output_loss: 22.4417 - dyn11_output_loss: 0.9014 - s1_output_loss: 0.0762 - t2_output_loss: 0.7538 - nu21_output_loss: 24.7815 - nu22_output_loss: 23.5084 - dyn21_output_loss: 1.0518 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.1934 - m2_21_output_loss: 1.1989 - t1_output_mae: 0.5732 - nu11_output_mae: 1.8592 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2361 - t2_output_mae: 0.5668 - nu21_output_mae: 1.8806 - nu22_output_mae: 1.8408 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6546 - m2_21_output_mae: 0.6442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f470077b0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f470077b0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2f49040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46a2f49040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 59s 24ms/step - loss: 77.7048 - t1_output_loss: 0.7559 - nu11_output_loss: 22.4347 - dyn11_output_loss: 0.9014 - s1_output_loss: 0.0762 - t2_output_loss: 0.7538 - nu21_output_loss: 24.7734 - nu22_output_loss: 23.5045 - dyn21_output_loss: 1.0518 - dyn22_output_loss: 1.0610 - m2_12_output_loss: 1.1931 - m2_21_output_loss: 1.1989 - t1_output_mae: 0.5732 - nu11_output_mae: 1.8590 - dyn11_output_categorical_accuracy: 0.6310 - s1_output_mae: 0.2361 - t2_output_mae: 0.5669 - nu21_output_mae: 1.8803 - nu22_output_mae: 1.8407 - dyn21_output_categorical_accuracy: 0.4478 - dyn22_output_categorical_accuracy: 0.4444 - m2_12_output_mae: 0.6545 - m2_21_output_mae: 0.6442 - val_loss: 84.6609 - val_t1_output_loss: 0.7243 - val_nu11_output_loss: 25.1371 - val_dyn11_output_loss: 0.8957 - val_s1_output_loss: 0.0760 - val_t2_output_loss: 0.6418 - val_nu21_output_loss: 26.5263 - val_nu22_output_loss: 24.5025 - val_dyn21_output_loss: 1.0519 - val_dyn22_output_loss: 1.0588 - val_m2_12_output_loss: 1.4997 - val_m2_21_output_loss: 2.5468 - val_t1_output_mae: 0.5486 - val_nu11_output_mae: 2.4813 - val_dyn11_output_categorical_accuracy: 0.6355 - val_s1_output_mae: 0.2367 - val_t2_output_mae: 0.5148 - val_nu21_output_mae: 2.4455 - val_nu22_output_mae: 2.1246 - val_dyn21_output_categorical_accuracy: 0.4423 - val_dyn22_output_categorical_accuracy: 0.4463 - val_m2_12_output_mae: 0.6644 - val_m2_21_output_mae: 0.9143\n",
      "Epoch 100/100\n",
      "2498/2500 [============================>.] - ETA: 0s - loss: 76.6234 - t1_output_loss: 0.7614 - nu11_output_loss: 22.2290 - dyn11_output_loss: 0.9025 - s1_output_loss: 0.0764 - t2_output_loss: 0.7591 - nu21_output_loss: 24.4941 - nu22_output_loss: 22.9159 - dyn21_output_loss: 1.0518 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.1884 - m2_21_output_loss: 1.1833 - t1_output_mae: 0.5757 - nu11_output_mae: 1.8542 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2362 - t2_output_mae: 0.5675 - nu21_output_mae: 1.8497 - nu22_output_mae: 1.8287 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6530 - m2_21_output_mae: 0.6394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c85704c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f46c85704c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c85705e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f46c85705e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2500/2500 [==============================] - 54s 22ms/step - loss: 76.6789 - t1_output_loss: 0.7615 - nu11_output_loss: 22.2224 - dyn11_output_loss: 0.9025 - s1_output_loss: 0.0764 - t2_output_loss: 0.7593 - nu21_output_loss: 24.5645 - nu22_output_loss: 22.9067 - dyn21_output_loss: 1.0517 - dyn22_output_loss: 1.0615 - m2_12_output_loss: 1.1886 - m2_21_output_loss: 1.1836 - t1_output_mae: 0.5757 - nu11_output_mae: 1.8540 - dyn11_output_categorical_accuracy: 0.6306 - s1_output_mae: 0.2363 - t2_output_mae: 0.5676 - nu21_output_mae: 1.8504 - nu22_output_mae: 1.8284 - dyn21_output_categorical_accuracy: 0.4473 - dyn22_output_categorical_accuracy: 0.4436 - m2_12_output_mae: 0.6531 - m2_21_output_mae: 0.6394 - val_loss: 77.8436 - val_t1_output_loss: 0.6998 - val_nu11_output_loss: 23.7950 - val_dyn11_output_loss: 0.9128 - val_s1_output_loss: 0.0763 - val_t2_output_loss: 0.6850 - val_nu21_output_loss: 23.5128 - val_nu22_output_loss: 23.2786 - val_dyn21_output_loss: 1.0532 - val_dyn22_output_loss: 1.0593 - val_m2_12_output_loss: 1.8392 - val_m2_21_output_loss: 0.9315 - val_t1_output_mae: 0.5537 - val_nu11_output_mae: 1.6664 - val_dyn11_output_categorical_accuracy: 0.6345 - val_s1_output_mae: 0.2357 - val_t2_output_mae: 0.5338 - val_nu21_output_mae: 1.5732 - val_nu22_output_mae: 1.8592 - val_dyn21_output_categorical_accuracy: 0.4410 - val_dyn22_output_categorical_accuracy: 0.4448 - val_m2_12_output_mae: 0.9198 - val_m2_21_output_mae: 0.5392\n"
     ]
    }
   ],
   "source": [
    "init_lr = 1e-4\n",
    "epochs = 100\n",
    "opt = Adam(learning_rate=init_lr, decay=init_lr / epochs)\n",
    "model.compile(optimizer=opt, \n",
    "              loss={\n",
    "                  f\"{var.name}_output\": \"mse\" if not isinstance(var, gadma.DynamicVariable) else \"categorical_crossentropy\"\n",
    "                  for var in model_2_1.variables\n",
    "              },\n",
    "              metrics={\n",
    "                  f\"{var.name}_output\": \"mae\" if not isinstance(var, gadma.DynamicVariable) else \"categorical_accuracy\"\n",
    "                  for var in model_2_1.variables\n",
    "              })\n",
    "\n",
    "batch_size = 32\n",
    "valid_batch_size = 32\n",
    "train_gen = data_generator.generate_images(X_train_CNN, y_train_CNN, is_training=True, batch_size=batch_size)\n",
    "valid_gen = data_generator.generate_images(X_val_CNN, y_val_CNN, is_training=True, batch_size=valid_batch_size)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(X_train)//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(X_test)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JicyR4Uj-gK0"
   },
   "source": [
    "- OR load saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UR27tjpH-gK0"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"model_cnn_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpV60YdK-gK0"
   },
   "source": [
    "- Get measures on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Ux5UccmB-gK0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f46da92d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f46da92d310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "625/625 [==============================] - 4s 5ms/step\n",
      "Convolutional neural network with independent branches.\n",
      "Mean squared error: 8.93617170301409\n",
      "Mean accuracy score: 0.5061\n"
     ]
    }
   ],
   "source": [
    "X_test_resized = np.array([np.reshape(np.array(x), (-1, 6, 1)) for x in X_test])\n",
    "y_pred = model.predict(X_test_resized)\n",
    "y_pred = convert_cnn_output_to_rf_output(y_pred)\n",
    "\n",
    "print(\"Convolutional neural network with independent branches.\")\n",
    "print_measures(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQbouEe5-gK0"
   },
   "source": [
    "- Test prediction for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "mz6Pn7-j-gK0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 686ms/step\n",
      "Best known parameters:\n",
      "{'t1': 1.0, 'nu11': 1.0, 'dyn11': 'Sud', 's1': 0.5, 't2': 0.05, 'nu21': 1.0, 'nu22': 0.1, 'dyn21': 'Sud', 'dyn22': 'Sud', 'm2_12': 5.0, 'm2_21': 2.5}\n",
      "Best known log-likelihood:\n",
      "-1310.9310340005\n",
      "\n",
      "Predicted parameters:\n",
      "{'t1': 0.4538623, 'nu11': 1.2582624, 'dyn11': 'Sud', 's1': 0.5809103, 't2': 0.272153, 'nu21': 1.8804532, 'nu22': 0.21437056, 'dyn21': 'Sud', 'dyn22': 'Sud', 'm2_12': 4.303458, 'm2_21': 0.8473885}\n",
      "Log-likelihood:\n",
      "-6813.690614199338\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(np.array([np.reshape(test_x, (6, 6, 1))]))\n",
    "y = convert_cnn_output_to_rf_output(y)\n",
    "y = dynamics2classes(y, back=True)[0]\n",
    "\n",
    "print(\"Best known parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best known log-likelihood:\")\n",
    "print(best_ll)\n",
    "\n",
    "print(\"\\nPredicted parameters:\")\n",
    "y_pred = {var.name: value for var, value in zip(model_2_1.variables, y)}\n",
    "print(y_pred)\n",
    "print(\"Log-likelihood:\")\n",
    "print(engine.evaluate(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Owp_6BvJ0S2X"
   },
   "outputs": [],
   "source": [
    "# save model weights\n",
    "model.save_weights(\"model_cnn_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZrZFkM7mHqS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_models_and_train_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
